import streamlit as st, traceback

# ã¾ãšå¿…ãšä½œã£ã¦ãŠãï¼ˆNameErrorå›é¿ï¼‰
_SEM_OK: bool = False
_SEM_ERR = None  # (err_name, err_msg, traceback_text)

# ---- semopy äº’æ›ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ—§/æ–°APIä¸¡å¯¾å¿œï¼‰----
try:
    from semopy import ModelMeans, Optimizer
    from semopy.inspector import inspect
    try:
        from semopy.report import gather_statistics          # æ—§API
    except ImportError:
        from semopy.inspector import inspect as gather_statistics  # æ–°APIã‚’ã‚¨ã‚¤ãƒªã‚¢ã‚¹
    _SEM_OK = True
except Exception as e:
    _SEM_OK = False
    _SEM_ERR = (type(e).__name__, str(e), "".join(traceback.format_exc()))
# ---------------------------------------------------------


import importlib.util, sys, subprocess
if importlib.util.find_spec("semopy") is None:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "semopy==2.3.11"])
import streamlit as st
import pandas as pd
from io import StringIO, BytesIO
from scipy.optimize import curve_fit
from sklearn.metrics import r2_score  # æ±ºå®šä¿‚æ•°è¨ˆç®—ç”¨
import matplotlib.pyplot as plt
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import RidgeCV
from sklearn.model_selection import KFold
from statsmodels.miscmodels.ordinal_model import OrderedModel
import numpy as np
from PIL import Image
import textwrap
import matplotlib.pyplot as plt
import io
import base64
from semopy import Model



logo = Image.open("app/LOGO.png")
st.sidebar.image(logo, use_column_width=True)

st.markdown("""
<style>

/* =====================================
      ã‚«ãƒ¼ãƒ‰å…¨ä½“ã®ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆèƒŒæ™¯ï¼ç·‘ã€æ–‡å­—ï¼ç™½ï¼‰
===================================== */
.card {
    background-color: #2e7d32;       /* MORIPIEã‚°ãƒªãƒ¼ãƒ³ */
    padding: 2rem;
    margin-top: 1.5rem;
    border-radius: 12px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    line-height: 1.6;
    color: #ffffff !important;

    /* ğŸ”¥ ã‚«ãƒ¼ãƒ‰ã‚’ã»ã¼å…¨å¹…ã«åºƒã’ã‚‹ */
    width: 100%;
    max-width: 1800px; /* 1500ã€œ2000ãŒé»„é‡‘æ¯” */
    margin-left: auto;
    margin-right: auto;
}

/* ã‚«ãƒ¼ãƒ‰å†…ã™ã¹ã¦ã®æ–‡å­—ã‚’ç™½ */
.card, .card * {
    color: #ffffff !important;
}

/* h2 ã‚¿ã‚¤ãƒˆãƒ« */
.card h2 {
    margin-top: 0;
    font-weight: 600;
    color: #ffffff !important;
}

/* h3 è¦‹å‡ºã— */
.card h3 {
    margin-top: 1.4rem;
    margin-bottom: 0.5rem;
    font-weight: 500;
    color: #e8f5e9 !important;
}

/* ãƒªã‚¹ãƒˆ */
.card ul {
    padding-left: 1.4rem;
}
.card li {
    margin-bottom: 0.4rem;
    color: #ffffff !important;
}

/* å¤ªå­— */
.card b {
    color: #ffffff !important;
}

/* h4 ã‚‚ç™½ã« */
.card h4, .card h4 * {
    color: #ffffff !important;
}

/* codeï¼ˆä¾‹: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼‰ */
.card code {
    background-color: #ffffff22 !important;
    color: #000000 !important;
    padding: 2px 6px;
    border-radius: 4px;
    font-size: 0.9rem;
}

/* ãƒ†ãƒ¼ãƒ–ãƒ« */
.card table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 1rem;
    background-color: rgba(255,255,255,0.1);
}
.card th, .card td {
    border: 1px solid rgba(255,255,255,0.3);
    padding: 0.5rem 0.8rem;
    color: #ffffff !important;
}
.card th {
    font-weight: bold;
    background-color: rgba(255,255,255,0.2);
}

/* ğŸ”¥ ãƒšãƒ¼ã‚¸è‡ªä½“ã®æœ€å¤§å¹…ï¼ˆé‡è¦ï¼‰ */
main .block-container {
    max-width: 2500px;
    padding-left: 2rem;
    padding-right: 2rem;
}

</style>

""", unsafe_allow_html=True)



st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700&display=swap');

/* å…¨ä½“ã®ãƒ•ã‚©ãƒ³ãƒˆã«é©ç”¨ */
html, body, div, span, input, textarea, button, p, h1, h2, h3, h4, h5, h6 {
    font-family: 'Noto Sans JP', sans-serif !important;
}

/* Streamlit å†…éƒ¨ã‚¯ãƒ©ã‚¹ã‚‚ä¸Šæ›¸ã */
[class^="css"], [class*="css"] {
    font-family: 'Noto Sans JP', sans-serif !important;
}
</style>
""", unsafe_allow_html=True)

def show_card(content_html: str):
    html = textwrap.dedent(content_html)
    st.markdown(
        f"""<div class="card">{html}</div>""",
        unsafe_allow_html=True
    )

st.markdown("""
<style>
/* ãƒšãƒ¼ã‚¸å…¨ä½“ã®èƒŒæ™¯ã‚’é»’ã« */
html, body, .stApp {
    background-color: #000000 !important;
}

/* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯ã‚‚é»’ã« */
section[data-testid="stSidebar"] {
    background-color: #000000 !important;
}

/* ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…éƒ¨ï¼ˆè¦ç´ ã®èƒŒæ™¯ï¼‰ã‚‚é»’ã« */
section[data-testid="stSidebar"] .css-1d391kg, 
section[data-testid="stSidebar"] .css-1v3fvcr {
    background-color: #000000 !important;
}

/* Streamlit ã®ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ï¼ˆå³ä¸Šã® Share, GitHub ãªã©ï¼‰*/
header[data-testid="stHeader"] {
    background-color: #000000 !important;
}

/* ãƒ˜ãƒƒãƒ€ãƒ¼å†…éƒ¨ã®èƒŒæ™¯ï¼ˆä½™ç™½éƒ¨åˆ†ã‚‚é»’ã«ï¼‰ */
header[data-testid="stHeader"] div {
    background-color: #000000 !important;
}

/* ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã‚³ãƒ³ãƒ†ãƒŠ */
div[data-testid="stToolbar"] {
    background-color: #000000 !important;
}

/* ã‚¢ã‚¤ã‚³ãƒ³ã®è‰²ã‚‚ç·‘ or ç™½ã«ã—ãŸã„å ´åˆï¼š */
div[data-testid="stToolbar"] * {
    color: #ffffff !important;
}

/* ã‚«ãƒ¼ãƒ‰ã¨ã®ä½™ç™½ã‚’ç¢ºä¿ */
.block-container {
    padding-top: 2rem;
    padding-bottom: 2rem;
}
            
</style>
""", unsafe_allow_html=True)

st.markdown("""

<style>

/* ============================================
   0. Streamlit å…¨ä½“ã¯ç™½æ–‡å­—ï¼ˆåŸºæœ¬ï¼‰
   ============================================ */
.stApp * {
    color: #ffffff !important;
}

/* ============================================
   1. ç™½èƒŒæ™¯ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é»’æ–‡å­—ãƒ«ãƒ¼ãƒ«
   ============================================ */

/* FileUploader */
[data-testid="stFileUploader"],
[data-testid="stFileUploader"] *,
[data-testid="stFileUploaderDropzoneInstructions"] {
    color: #000 !important;
}

/* TextInput / TextArea */
input, input *, textarea, textarea * {
    color: #000 !important;
    -webkit-text-fill-color: #000 !important;
}

/* TextArea ã‚³ãƒ³ãƒ†ãƒŠãã®ã‚‚ã® */
.stTextArea, .stTextArea * {
    color: #000 !important;
}

/* Buttonsï¼ˆç™½èƒŒæ™¯ãªã‚‰é»’æ–‡å­—ï¼‰ */
button, button * {
    color: #000 !important;
}

/* ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ */
textarea::placeholder {
    color: #555 !important;
}

/* ============================================
   2. ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆãƒ­ã‚°ã‚¢ã‚¦ãƒˆç­‰ï¼‰ã¯é»’æ–‡å­—
   ============================================ */
header[data-testid="stHeader"] *,
[data-testid="stToolbar"] * {
    color: #000 !important;
}

/* ============================================
   3. h1ï¼ˆå¤§è¦‹å‡ºã—ï¼‰ã¯ç™½æ–‡å­—å›ºå®š
   ============================================ */
h1, h1 * {
    color: #fff !important;
}

/* Markdown ã® h1 */
[data-testid="stMarkdownContainer"] h1,
[data-testid="stMarkdownContainer"] h1 * {
    color: #fff !important;
}

/* ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ */
.element-container h1, .element-container h1 * {
    color: #fff !important;
}
.element-container input, .element-container textarea {
    color: #000 !important;
}

/* ============================================
   4. Markdown ã® code / pre ãƒ–ãƒ­ãƒƒã‚¯ ã‚’é»’æ–‡å­—ã«å¼·åˆ¶
   ï¼ˆâ†ä»Šå›è¦‹ãˆãªã‹ã£ãŸæ ¹æœ¬åŸå› ï¼‰
   ============================================ */
code,
code *,
pre,
pre *,
.stMarkdown code,
.stMarkdown pre {
    color: #000000 !important;
    -webkit-text-fill-color: #000000 !important;
}

/* code ãƒ–ãƒ­ãƒƒã‚¯ã®èƒŒæ™¯ãŒç™½ãªã®ã§æ–‡å­—ãŒèª­ã‚ã‚‹ */
pre, code {
    background: #f5f5f5 !important;
}

/* ============================================
   5. Sidebar ã¯ç™½æ–‡å­—
   ============================================ */
[data-testid="stSidebar"],
[data-testid="stSidebar"] * {
    color: #ffffff !important;
}

/* ============================================
   6. Spinnerï¼ˆã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ï¼‰ã¯ç·‘è‰²
   ============================================ */
svg[role="img"],
div[role="status"] svg,
[data-testid="stStatusWidget"] svg {
    color: #00ff88 !important;
    stroke: #00ff88 !important;
    stroke-width: 2px !important;
}
/* =========================================================
   â˜… ãƒœã‚¿ãƒ³å†…éƒ¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å¿…ãšé»’ã«ã™ã‚‹ï¼ˆæœ€å„ªå…ˆï¼‰
   ========================================================= */
button *, button p, button div, button span {
    color: #000000 !important;
    -webkit-text-fill-color: #000000 !important; /* Safari å¯¾ç­– */
}

</style>



""", unsafe_allow_html=True)

def latex_to_png_base64(latex_str):
    fig = plt.figure(figsize=(0.01, 0.01))
    fig.patch.set_facecolor("none")
    plt.axis("off")

    # LaTeX ã‚’æç”»
    plt.text(0.5, 0.5, f"${latex_str}$", fontsize=22, ha="center", va="center")

    buf = io.BytesIO()
    plt.savefig(buf, format="png", dpi=300, transparent=True, bbox_inches="tight", pad_inches=0.1)
    plt.close(fig)
    buf.seek(0)

    return base64.b64encode(buf.read()).decode("utf-8")

try:
    from causalimpact import CausalImpact
    _CAUSALIMPACT_OK = True
except Exception:
    _CAUSALIMPACT_OK = False


# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆï¼ˆå®Ÿéš›ã«ã¯å®‰å…¨ãªæ–¹æ³•ã§ä¿å­˜ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
user_data = {
    'yomiko_mcc':'admin4035',
    'user1': 'password1',
    'user2': 'password2',
    # ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
}

def func_fit(x, a, b, K):
    y = K / (1 + (a * x ** b))
    return y

def convert_df(df):
    return df.to_csv().encode('utf-8')

def download(df):
    df = convert_df(df)
    st.download_button(
        label="Download data as CSV",
        data=df,
        file_name='output.csv',
        mime='text/csv',
    )

# Excelãƒ‡ãƒ¼ã‚¿ä½œæˆé–¢æ•°
def create_excel_file():
    output = BytesIO()  # ãƒ¡ãƒ¢ãƒªä¸Šã«ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        fin_data.to_excel(writer, sheet_name='programÃ—brand', index=True)
        allocated_program_data.to_excel(writer, sheet_name='allocated_program_data', index=True)
        view_track.to_excel(writer, sheet_name='view_track', index=True)
        fin_view_rate_list.to_excel(writer, sheet_name='fin_view_rate_list', index=True)
        allocated_brand_data.to_excel(writer, sheet_name='allocated_brand_cost', index=True)
    output.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
    return output

def login():
    if 'logged_in' not in st.session_state:
        st.session_state.logged_in = False

    if st.session_state.logged_in:
        return True

    st.title("ãƒ­ã‚°ã‚¤ãƒ³")
    username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type='password')

    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if username in user_data and user_data[username] == password:
            st.session_state.logged_in = True
            st.session_state.username = username  # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ç§»å‹•
        else:
            st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
    return False


def tab_PCA():
    # ======= ã‚«ãƒ¼ãƒ‰UIï¼šèª¬æ˜ãƒ–ãƒ­ãƒƒã‚¯ =======
    show_card(
"""
<h2>ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰</h2>

<h3>ç›®çš„</h3>
<ul>
    <li>å¤šæ•°ã®èª¬æ˜å¤‰æ•°ã«æ½œã‚€å…±é€šå› å­ã‚’æŠ½å‡ºã—ã€æ¬¡å…ƒåœ§ç¸®ã—ã¦å…¨ä½“æ§‹é€ ã‚’æŠŠæ¡ã™ã‚‹ã€‚</li>
</ul>

<h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
<ul>
    <li><b>å¤šå¤‰é‡ã®è¦ç´„</b>ï¼šåª’ä½“æ¥è§¦ã‚„å±æ€§ãŒå¤šã„ã¨ãã«ã€å°‘æ•°ã®æŒ‡æ¨™ï¼ˆä¸»æˆåˆ†ï¼‰ã¸è¦ç´„ã€‚</li>
    <li><b>å¯è¦–åŒ–</b>ï¼š2æ¬¡å…ƒã«åœ§ç¸®ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿å‚¾å‘ãƒ»å¤–ã‚Œå€¤ã‚’æŠŠæ¡ã€‚</li>
    <li><b>å‰å‡¦ç†</b>ï¼šå›å¸°ã‚„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å‰ã«å¤šé‡å…±ç·šæ€§ã‚’ç·©å’Œã€‚</li>
</ul>

<h3>inputãƒ‡ãƒ¼ã‚¿</h3>
<ul>
    <li>1åˆ—ç›®ï¼š<b>IDï¼ˆyï¼‰</b></li>
    <li>2åˆ—ç›®ä»¥é™ï¼š<b>èª¬æ˜å¤‰æ•°ï¼ˆXï¼‰</b>ï¼ˆæ•°å€¤åˆ—ï¼‰</li>
    <li>â€»Excel/CSVå¯¾å¿œã€‚Excelã¯ <b>A_å…¥åŠ›</b> ã‚·ãƒ¼ãƒˆãŒã‚ã‚Œã°å„ªå…ˆã€ç„¡ã‘ã‚Œã°å…ˆé ­ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ã€‚</li>
</ul>

<h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
<ul>
    <li><b>å›ºæœ‰å€¤ãƒ»å¯„ä¸ç‡ãƒ»ç´¯ç©å¯„ä¸ç‡</b>ï¼šã©ã®ä¸»æˆåˆ†ãŒã©ã‚Œã ã‘åˆ†æ•£ã‚’èª¬æ˜ã™ã‚‹ã‹ã€‚</li>
    <li><b>æˆåˆ†è² è·é‡ï¼ˆloadingsï¼‰</b>ï¼šå„å¤‰æ•°ãŒä¸»æˆåˆ†ã¸ã©ã‚Œã ã‘å¯„ä¸ã™ã‚‹ã‹ã€‚</li>
    <li><b>ã‚¹ã‚³ã‚¢ï¼ˆscoresï¼‰</b>ï¼šå„ã‚µãƒ³ãƒ—ãƒ«ã®ä¸»æˆåˆ†ç©ºé–“ä¸Šã®åº§æ¨™ã€‚</li>
    <li><b>ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ</b> ã¨ <b>ãƒã‚¤ãƒ—ãƒ­ãƒƒãƒˆï¼ˆPC1Ã—PC2ï¼‰</b> ã‚’è¡¨ç¤ºã€‚</li>
    <li><b>CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</b>ï¼šæˆåˆ†è² è·é‡ãƒ»ã‚¹ã‚³ã‚¢ã‚’ä¿å­˜å¯èƒ½ã€‚</li>
</ul>
"""
    )
    
     # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/ä¸»æˆåˆ†ORå› å­åˆ†æ.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="ä¸»æˆåˆ†ORå› å­åˆ†æ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # === ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ› ===
    up = st.file_uploader("PCAç”¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSV / XLSXï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv", "xlsx"], key="pca_file")
    if up is None:
        return

    # === èª­ã¿è¾¼ã¿ ===
    try:
        if up.name.lower().endswith(".xlsx"):
            bytes_data = up.read()
            xls = pd.ExcelFile(BytesIO(bytes_data))
            sheet = "A_å…¥åŠ›" if "A_å…¥åŠ›" in xls.sheet_names else xls.sheet_names[0]
            df = pd.read_excel(BytesIO(bytes_data), sheet_name=sheet)
        else:
            try:
                df = pd.read_csv(up)
            except UnicodeDecodeError:
                up.seek(0)
                df = pd.read_csv(up, encoding="shift-jis")
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    if df.shape[1] < 2:
        st.error("å°‘ãªãã¨ã‚‚2åˆ—ï¼ˆ1åˆ—ç›®=IDã€2åˆ—ç›®ä»¥é™=è©•ä¾¡é …ç›®ãƒ»ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®ï¼‰ãŒå¿…è¦ã§ã™ã€‚")
        return

    st.write("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
    st.dataframe(df.head())

    # === y / X åˆ†å‰²ï¼ˆ1åˆ—ç›®=ID, 2åˆ—ç›®ä»¥é™=èª¬æ˜å¤‰æ•°ï¼‰ ===
    y = df.iloc[:, 0]
    X_raw = df.iloc[:, 1:].copy()

    # æ•°å€¤åˆ—ã®ã¿åˆ©ç”¨ï¼ˆéæ•°å€¤ã¯é™¤å¤–ï¼‰
    X_num = X_raw.select_dtypes(include=[np.number])
    dropped = [c for c in X_raw.columns if c not in X_num.columns]
    if dropped:
        st.warning(f"æ•°å€¤ã§ãªã„åˆ—ã‚’é™¤å¤–ã—ã¾ã—ãŸ: {', '.join(map(str, dropped))}")

    # æ¬ æå€¤å‡¦ç†
    na_opt = st.radio("æ¬ æå€¤ã®æ‰±ã„", ["è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰", "åˆ—å¹³å‡ã§è£œå®Œ"], index=0, horizontal=True)
    if na_opt == "è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰":
        data = pd.concat([y, X_num], axis=1).dropna()
        y = data.iloc[:, 0]
        X_num = data.iloc[:, 1:]
    else:
        X_num = X_num.fillna(X_num.mean())

    if X_num.shape[1] == 0 or X_num.shape[0] < 2:
        st.error("æœ‰åŠ¹ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆå¹³å‡0, åˆ†æ•£1ï¼‰
    scaler = StandardScaler()
    X_std = scaler.fit_transform(X_num)

    # === æˆåˆ†æ•°ã®æŒ‡å®šæ–¹æ³• ===
    st.subheader("æˆåˆ†æ•°ã®æŒ‡å®š")
    mode = st.radio("é¸æŠ", ["å€‹æ•°ã‚’æŒ‡å®š", "ç´¯ç©å¯„ä¸ç‡ã§è‡ªå‹•"], index=1, horizontal=True)

    if mode == "å€‹æ•°ã‚’æŒ‡å®š":
        k_max = min(X_num.shape[1], 20)
        n_components = st.slider("ä¸»æˆåˆ†ã®å€‹æ•°", min_value=1, max_value=k_max, value=min(2, k_max), step=1)
        pca = PCA(n_components=n_components, random_state=0)
    else:
        thr = st.slider("ç´¯ç©å¯„ä¸ç‡ï¼ˆä¾‹ï¼š0.80ã€œ0.99ï¼‰", min_value=0.50, max_value=0.99, value=0.90, step=0.01)
        pca = PCA(n_components=thr, random_state=0)

    # === PCA å®Ÿè¡Œ ===
    try:
        scores = pca.fit_transform(X_std)
    except Exception as e:
        st.error(f"PCAå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return

    comps = pca.components_                  # å½¢çŠ¶: [n_components, n_features]
    expvar = pca.explained_variance_ratio_   # å„æˆåˆ†ã®å¯„ä¸ç‡
    cumexp = np.cumsum(expvar)

    # === ãƒ†ãƒ¼ãƒ–ãƒ«é¡ ===
    pc_names = [f"PC{i+1}" for i in range(len(expvar))]
    loadings = pd.DataFrame(comps.T, index=X_num.columns, columns=pc_names)
    loadings_abs = loadings.abs().sort_values(pc_names[0], ascending=False)

    scores_df = pd.DataFrame(scores, columns=pc_names, index=X_num.index)
    scores_df.insert(0, y.name if hasattr(y, "name") and y.name is not None else "target", y.loc[scores_df.index].values)

    exp_table = pd.DataFrame({
        "PC": pc_names,
        "explained_variance_ratio": expvar,
        "cumulative_ratio": cumexp
    })

    st.subheader("å¯„ä¸ç‡")
    st.dataframe(exp_table)

    st.subheader("æˆåˆ†è² è·é‡ï¼ˆloadingsï¼‰")
    st.caption("â€»æ•°å€¤ã®çµ¶å¯¾å€¤ãŒå¤§ãã„ã»ã©ã€ãã®å¤‰æ•°ãŒè©²å½“ä¸»æˆåˆ†ã«å¼·ãå¯„ä¸")
    st.dataframe(loadings_abs)

    st.subheader("ã‚¹ã‚³ã‚¢ï¼ˆå„ã‚µãƒ³ãƒ—ãƒ«ã®PCåº§æ¨™ï¼‰")
    st.dataframe(scores_df.head())

    # === ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ===
    st.download_button(
        "æˆåˆ†è² è·é‡CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=loadings.to_csv(index=True).encode("utf-8"),
        file_name="pca_loadings.csv",
        mime="text/csv"
    )
    st.download_button(
        "ã‚¹ã‚³ã‚¢CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=scores_df.to_csv(index=True).encode("utf-8"),
        file_name="pca_scores.csv",
        mime="text/csv"
    )

    # === ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ ===
    st.subheader("ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå¯„ä¸ç‡ï¼‰")
    fig1, ax1 = plt.subplots(figsize=(8, 4))
    ax1.plot(range(1, len(expvar) + 1), expvar, marker='o', label='Explained variance ratio')
    ax1.plot(range(1, len(cumexp) + 1), cumexp, marker='o', linestyle='--', label='Cumulative')
    ax1.set_xlabel("Principal Component")
    ax1.set_ylabel("Ratio")
    ax1.set_xticks(range(1, len(expvar) + 1))
    ax1.legend()
    st.pyplot(fig1)

    # === ãƒã‚¤ãƒ—ãƒ­ãƒƒãƒˆï¼ˆPC1Ã—PC2ï¼‰ ===
    if len(pc_names) >= 2:
        st.subheader("ãƒã‚¤ãƒ—ãƒ­ãƒƒãƒˆï¼ˆPC1 Ã— PC2ï¼‰")
        fig2, ax2 = plt.subplots(figsize=(6, 6))

        # ã‚¹ã‚³ã‚¢æ•£å¸ƒ
        ax2.scatter(scores_df["PC1"], scores_df["PC2"], alpha=0.6)
        ax2.set_xlabel("PC1")
        ax2.set_ylabel("PC2")
        ax2.axhline(0, linewidth=0.5)
        ax2.axvline(0, linewidth=0.5)

        # çŸ¢å°ï¼ˆå¤‰æ•°ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ï¼šæˆåˆ†è² è·é‡ã‚’å¯è¦–åŒ–
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆè¦‹ã‚„ã™ã•èª¿æ•´ï¼‰
        arrow_scale = 1.0
        load2 = loadings[["PC1", "PC2"]].values * arrow_scale

        for i, var in enumerate(X_num.columns):
            ax2.arrow(0, 0, load2[i, 0], load2[i, 1], head_width=0.02, length_includes_head=True)
            ax2.text(load2[i, 0]*1.07, load2[i, 1]*1.07, var, fontsize=9)

        ax2.set_title("Biplot")
        st.pyplot(fig2)
    else:
        st.info("PCãŒ1ã¤ã®ãŸã‚ã€ãƒã‚¤ãƒ—ãƒ­ãƒƒãƒˆã¯è¡¨ç¤ºã—ã¾ã›ã‚“ã€‚")



def tab_Logistic():

    show_card(
    """
    <h2>Logisticå›å¸°</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>ã‚ã‚‹ç‰¹å®šã®äº‹è±¡ãŒèµ·ãã‚‹ç¢ºç‡ã‚’åˆ†æã—ã€çµæœã‚’äºˆæ¸¬ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>èª¿æŸ»çµæœã®å€‹ç¥¨ãƒ‡ãƒ¼ã‚¿è§£æ: èª¬æ˜å¤‰æ•°ã¨ã—ã¦å„ãƒ¡ãƒ‡ã‚£ã‚¢ã®æ¥è§¦æœ‰ç„¡ï¼ˆ0,1ãƒ‡ãƒ¼ã‚¿ï¼‰ã€ç›®çš„å¤‰æ•°ã¨ã—ã¦èªçŸ¥ãªã©ã®KPIæœ‰ç„¡ï¼ˆ0,1ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å„ãƒ¡ãƒ‡ã‚£ã‚¢ã®æ¥è§¦ãŒKPIã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚Googleãƒˆãƒ¬ãƒ³ãƒ‰ã‚„DS.INSIGHTãªã©ã‹ã‚‰KWãƒœãƒªãƒ¥ãƒ¼ãƒ ã®éå»å‚¾å‘ã‚’åˆ†æã—ã€å­£ç¯€æ€§ã‚„é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ç¢ºèªã€‚</li>
        <li>CVèµ·ç‚¹ã§ã®CPè©•ä¾¡: IDãƒ™ãƒ¼ã‚¹ã«ã€CPã”ã¨ã«FQã—ãŸã‹ã©ã†ã‹ã‚’èª¬æ˜å¤‰æ•°ã¨ã—ã¦ï¼ˆ0,1ãƒ‡ãƒ¼ã‚¿ï¼‰ã€ã‚ã‚‹æŒ‡å®šæœŸé–“å†…ã«CVã—ãŸã‹ã©ã†ã‹ã‚’ç›®çš„å¤‰æ•°ã¨ã—ãŸã¨ãã«ï¼ˆ0,1ãƒ‡ãƒ¼ã‚¿ï¼‰ã€éå»è“„ç©åŠ¹æœãŒã‚ã£ãŸã®ã‹ç¢ºèªã™ã‚‹ã€‚</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li>1åˆ—ç›®ï¼šID</li>
        <li>2åˆ—ç›®ï¼šç›®çš„å¤‰æ•°ï¼ˆ0or1ï¼‰</li>
        <li>3åˆ—ç›®ä»¥é™ï¼šèª¬æ˜å¤‰æ•°ï¼ˆæ•°å€¤åˆ—ï¼‰</li>
    </ul>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li><b>â˜…importance</b>: èª¬æ˜å¤‰æ•°ï¼ˆå„ãƒ¡ãƒ‡ã‚£ã‚¢æ¥è§¦æœ‰ç„¡ï¼‰ãŒç›®çš„å¤‰æ•°ï¼ˆKPIï¼‰ã«ä¸ãˆã‚‹è²¢çŒ®åº¦ã‚’ã¯ã‹ã‚‹ãŸã‚ã®æŒ‡æ¨™ã€‚</li>
        <li><b>odds</b>: ã‚ªãƒƒã‚ºæ¯”ã€‚importanceã¨å¤§å°é–¢ä¿‚ã¯åŸºæœ¬åŒã˜ã€‚1ã‚ˆã‚Šå¤§ãã„ãªã‚‰KPIã«å¯¾ã—ã¦ï¼‹ã«åƒãã€1ã‚ˆã‚Šä½ã„ãªã‚‰ï¼ã«åƒãã€‚</li>
        <li><b>P>|z|</b>ï¼šPå€¤ã€‚æœ‰æ„æ°´æº–0.05ã‚’ä¸‹å›ã‚Œã°ãã®èª¬æ˜å¤‰æ•°ã¯æœ‰æ„ãªåå›å¸°ä¿‚æ•°ã§ã‚ã‚‹ã“ã¨ãŒè¨€ãˆã‚‹ã€‚</li>
        <li>inputãƒ‡ãƒ¼ã‚¿ã®ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã®å…¥åŠ›ä½ç½®ã«æ³¨æ„ã€‚</li>
    </ul>
    """
    )

    # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/Logistic.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="Logistic.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    uploaded_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv", "xlsx"])

    if uploaded_file is not None:
        try:
            st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«:")
            if uploaded_file.type == "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet":
                bytes_data = uploaded_file.read()
                df = pd.read_excel(BytesIO(bytes_data))
            else:
                stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
                df = pd.read_csv(stringio, encoding="shift-jis")

            # === èª­ã¿è¾¼ã¿ã¯ãã®ã¾ã¾ï¼ˆdf ãŒã§ãã¦ã„ã‚‹å‰æï¼‰ ===
            st.write(df)

            # 1åˆ—ç›®=ç›®çš„å¤‰æ•°ã€2åˆ—ç›®ä»¥é™=èª¬æ˜å¤‰æ•°ï¼ˆâ€»0å§‹ã¾ã‚Šã«æ³¨æ„ï¼‰
            y = df.iloc[:, 0]
            X = df.iloc[:, 1:].copy()

            # æ•°å€¤åŒ–ï¼ˆæ–‡å­—ãŒæ··ã–ã£ã¦ã„ãŸã‚‰ NaNâ†’é™¤å¤–/è£œå®Œï¼‰
            X = X.apply(pd.to_numeric, errors='coerce')
            drop_na_opt = st.radio("æ¬ æã®æ‰±ã„", ["è¡Œå‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰", "åˆ—å¹³å‡ã§è£œå®Œ"], index=0, horizontal=True)
            if drop_na_opt == "è¡Œå‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰":
                data = pd.concat([y, X], axis=1).dropna()
                y = data.iloc[:, 0]
                X = data.iloc[:, 1:]
            else:
                X = X.fillna(X.mean())
                ok_idx = y.notna()
                y = y[ok_idx]
                X = X.loc[ok_idx]

            # ç›®çš„å¤‰æ•°ã¯0/1ã«æƒãˆã‚‹ï¼ˆã™ã§ã«0/1ãªã‚‰ãã®ã¾ã¾ï¼‰
            try:
                y = pd.to_numeric(y, errors='raise')
            except Exception:
                y = y.map({True: 1, False: 0})
            y = (y > 0).astype(int)  # 0/1ã«æ­£è¦åŒ–

            # åˆ—åï¼ˆç‰¹å¾´é‡åï¼‰ã‚’å¾Œã§ä½¿ã†ã®ã§ä¿æŒ
            name_list = list(X.columns)

            # å®šæ•°é …ã‚’ä»˜ä¸
            import statsmodels.api as sm
            X_const = sm.add_constant(X, has_constant='add')

            # === ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆGLM, Binomialï¼‰: ãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ©ã‚’ä½¿ã‚ãªã„ ===
            logistic = sm.GLM(y, X_const, family=sm.families.Binomial()).fit()

            # é‡è¦åº¦ã®ç®—å‡ºç”¨ã«ã€Œ1å€‹ã ã‘1ã€ä»–0ã€ã®è¡Œåˆ—ï¼ˆå®šæ•°é …=1ï¼‰ã‚’ä½œã‚‹
            import numpy as np
            num = len(name_list)
            eye = np.zeros((num, num))
            np.fill_diagonal(eye, 1)

            df_dict = pd.DataFrame(eye, columns=name_list)
            df_dict.insert(0, 'const', 1.0)  # å®šæ•°é …

            # äºˆæ¸¬å€¤ï¼ˆeach feature = 1, others = 0 ã®æ™‚ã®ç¢ºç‡ï¼‰
            pred = logistic.predict(df_dict)

            # ã‚ªãƒƒã‚ºæ¯”ã¨på€¤
            import numpy as np
            media_list = []
            odds_list = []
            p_values_list = []
            for i, col in enumerate(name_list):
                media_list.append(col)
                coef = logistic.params.get(col, np.nan)
                odds_list.append(np.exp(coef) if pd.notna(coef) else np.nan)
                p_values_list.append(logistic.pvalues.get(col, np.nan))

            df_odds = pd.DataFrame({
                "media": media_list,
                "importance": pred,   # ã€Œãã®å¤‰æ•°ã ã‘1ã€ã®ã¨ãã®äºˆæ¸¬ç¢ºç‡
                "odds": odds_list,
                "p_values": p_values_list
            })

            st.write(df_odds.head())
            download(df_odds)



        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€éš›ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def tab_LogisticNum():

    show_card(
    """
    <h2>é †åºLogisticå›å¸°</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>æ®µéšçš„ï¼ˆé †åºã‚ã‚Šï¼‰ãªç›®çš„å¤‰æ•°ã‚’ã€èª¬æ˜å¤‰æ•°ã§èª¬æ˜ãƒ»äºˆæ¸¬ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>æº€è¶³åº¦1ã€œ5ã€è©•ä¾¡A/B/C ãªã©ã® <b>é †åºã‚ã‚Šã‚«ãƒ†ã‚´ãƒª</b> ã‚’æ‰±ã„ãŸã„ã¨ãã€‚</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li>1åˆ—ç›®ï¼šID</li>
        <li>2åˆ—ç›®ï¼šç›®çš„å¤‰æ•°ï¼ˆé †åºã‚«ãƒ†ã‚´ãƒª or æ•°å€¤/ãƒ©ãƒ™ãƒ«ï¼‰</li>
        <li>3åˆ—ç›®ä»¥é™ï¼šèª¬æ˜å¤‰æ•°ï¼ˆæ•°å€¤åˆ—ï¼‰</li>
    </ul>
    """
    )

    # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/é †åºLogistic.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="é †åºLogistic.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


    up = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSV / XLSXï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "xlsx"], key="ordlogit_file")
    if up is None:
        return

    # --- èª­ã¿è¾¼ã¿ ---
    try:
        if up.name.lower().endswith(".xlsx"):
            bytes_data = up.read()
            xls = pd.ExcelFile(BytesIO(bytes_data))
            sheet = "A_å…¥åŠ›" if "A_å…¥åŠ›" in xls.sheet_names else xls.sheet_names[0]
            df = pd.read_excel(BytesIO(bytes_data), sheet_name=sheet)
        else:
            try:
                df = pd.read_csv(up)
            except UnicodeDecodeError:
                up.seek(0)
                df = pd.read_csv(up, encoding="shift-jis")
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    if df.shape[1] < 3:
        st.error("å°‘ãªãã¨ã‚‚3åˆ—ï¼ˆ1åˆ—ç›®=IDã€2åˆ—ç›®=ç›®çš„ã€3åˆ—ç›®ä»¥é™=èª¬æ˜å¤‰æ•°ï¼‰ãŒå¿…è¦ã§ã™ã€‚")
        return

    st.write("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
    st.dataframe(df.head())

    # --- y / X ---
    y_raw = df.iloc[:, 1]
    X = df.iloc[:, 2:].copy()
    X = X.apply(pd.to_numeric, errors='coerce')  # éæ•°å€¤â†’NaN

    # æ¬ æå‡¦ç†
    na_opt = st.radio("æ¬ æå€¤ã®æ‰±ã„", ["è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰", "åˆ—å¹³å‡ã§è£œå®Œ"], index=0, horizontal=True)
    if na_opt == "è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰":
        data = pd.concat([y_raw, X], axis=1).dropna()
        y_raw = data.iloc[:, 0]
        X = data.iloc[:, 1:]
    else:
        X = X.fillna(X.mean())
        ok = y_raw.notna()
        y_raw = y_raw[ok]
        X = X.loc[ok]

    # ç›®çš„ã®é †åºï¼ˆè‡ªå‹•æ¨å®šï¼‰
    uniq = pd.Index(pd.Series(y_raw).dropna().unique())
    try:
        uniq_sorted = pd.Index(sorted(pd.to_numeric(uniq, errors="raise")))
    except Exception:
        uniq_sorted = pd.Index(sorted(uniq.astype(str)))

    st.subheader("ç›®çš„å¤‰æ•°ã®é †åº")
    st.caption("â€»è‡ªå‹•ï¼ˆæ˜‡é †ï¼‰ã‚’æ¨å¥¨ã€‚å¿…è¦ãªã‚‰é€†é †ã«åˆ‡ã‚Šæ›¿ãˆã€‚")
    reverse = st.checkbox("é †åºã‚’é€†è»¢ã™ã‚‹", value=False)
    categories = list(uniq_sorted[::-1] if reverse else uniq_sorted)

    # ã‚«ãƒ†ã‚´ãƒªå‹ï¼ˆé †åºã‚ã‚Šï¼‰ã¸
    cat_type = pd.api.types.CategoricalDtype(categories=categories, ordered=True)
    y = y_raw.astype(cat_type)

    # æ¨™æº–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    do_std = st.checkbox("èª¬æ˜å¤‰æ•°ã‚’æ¨™æº–åŒ–ï¼ˆå¹³å‡0, åˆ†æ•£1ï¼‰", value=True)
    if do_std:
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_std = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)
    else:
        X_std = X

    # --- ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆè¡Œåˆ—æŒ‡å®šãªã®ã§åˆ—åã«è¨˜å·ãŒã‚ã£ã¦ã‚‚OKï¼‰ ---
    try:
        model = OrderedModel(y, X_std, distr="logit")
        res = model.fit(method="bfgs", disp=False)
    except Exception as e:
        st.error(f"å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # statsmodels ã®ç‰ˆå·®ã‚’å¸åã—ã¦ã‚«ãƒ†ã‚´ãƒªåã‚’å–ã‚‹
    def get_categories_safe():
        try:
            return list(res.model.endog.categories)   # æ–°ã—ã‚
        except Exception:
            pass
        try:
            return list(y.cat.categories)             # æ‰‹å…ƒã®yã‹ã‚‰
        except Exception:
            pass
        try:
            k = res.predict(X_std.iloc[:1], which="prob").shape[1]
        except Exception:
            k = 2
        return [str(i) for i in range(k)]

    cats = [str(c) for c in get_categories_safe()]

    st.subheader("æ¨å®šçµæœã‚µãƒãƒª")
    st.text(res.summary().as_text())

    # ä¿‚æ•°ã¨på€¤ï¼ˆcutç‚¹ã¯å¾Œã§ï¼‰
    coef = res.params.reindex(X_std.columns, fill_value=np.nan)
    pvals = res.pvalues.reindex(X_std.columns, fill_value=np.nan)
    odds = np.exp(coef)
    coef_df = pd.DataFrame({
        "coef": coef,
        "odds_ratio(å˜ä½å¢—åŠ )": odds,
        "p_value": pvals
    }).sort_values("p_value")
    st.subheader("ä¿‚æ•°ãƒ»ã‚ªãƒƒã‚ºæ¯”ãƒ»på€¤ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰")
    st.dataframe(coef_df)

    # === æ®µéšåˆ¥ã®â€œå¯„ä¸â€ï¼ˆÎ”ç¢ºç‡ï¼‰ ===
    st.subheader("æ®µéšã”ã¨ã®å¯„ä¸ï¼ˆå¤‰æ•°ã‚’å‹•ã‹ã—ãŸã¨ãã®Î”äºˆæ¸¬ç¢ºç‡ï¼‰")

    X_base = X_std.mean().to_frame().T  # ä»–å¤‰æ•°ã¯å¹³å‡ï¼ˆæ¨™æº–åŒ–ONãªã‚‰0ï¼‰

    def probs_at(dfrow):
        p = res.predict(dfrow, which="prob")
        # ndarray or DataFrame -> 1D ãƒ™ã‚¯ãƒˆãƒ«
        if hasattr(p, "values"):
            p = p.values
        return np.ravel(p)

    base_p = probs_at(X_base)

    rows = []
    for col in X_std.columns:
        x1 = X_base.copy()
        unique_vals = pd.unique(X[col].dropna())
        if set(unique_vals).issubset({0, 1}):
            # ãƒ€ãƒŸãƒ¼: 0â†’1
            x0 = X_base.copy()
            x0[col] = 0.0
            x1[col] = 1.0
            p0 = probs_at(x0)
            p1 = probs_at(x1)
            dp = p1 - p0
            step_desc = "0â†’1"
        else:
            # é€£ç¶š: +1æ¨™æº–åŒ–å˜ä½ï¼ˆéæ¨™æº–åŒ–ãªã‚‰ +1Ïƒï¼‰
            step = 1.0 if do_std else X[col].std(ddof=0)
            x1[col] = X_base[col].iloc[0] + step
            p1 = probs_at(x1)
            dp = p1 - base_p
            step_desc = f"+{('1Ïƒ' if not do_std else '1(æ¨™æº–åŒ–å˜ä½)')}"

        for c, d in zip(cats, dp):
            rows.append({"variable": col, "category": str(c), "delta_prob": float(d), "change": step_desc})

    effect_df = pd.DataFrame(rows).sort_values(["variable", "category"])
    st.dataframe(effect_df)

    st.subheader("Î”äºˆæ¸¬ç¢ºç‡ï¼ˆãƒ”ãƒœãƒƒãƒˆè¡¨ç¤ºï¼‰")
    pivot_df = effect_df.pivot(index="variable", columns="category", values="delta_prob").fillna(0.0)
    st.dataframe(pivot_df.style.format("{:+.3f}"))

    # cutç‚¹ï¼ˆã‚«ãƒ†ã‚´ãƒªé–“ã®ã—ãã„å€¤ï¼‰
    cut_df = res.params.drop(index=X_std.columns, errors="ignore").to_frame(name="threshold")
    st.subheader("ã—ãã„å€¤ï¼ˆã‚«ãƒ†ã‚´ãƒªé–“ã®cutï¼‰")
    st.dataframe(cut_df)

    # ===== äºˆæ¸¬ç¢ºç‡ï¼ˆå…¨è¡Œï¼‰ =====
    proba = res.predict(X_std, which="prob")   # ndarray or DataFrame
    # ç¢ºå®Ÿã« float ã® numpy é…åˆ—ã¸
    proba = np.asarray(proba, dtype=float)

    # ãƒ¢ãƒ‡ãƒ«ã®ã‚«ãƒ†ã‚´ãƒªé †ã§åˆ—ã‚’ä»˜ä¸
    prob = pd.DataFrame(proba,
                        columns=[f"P({c})" for c in cats],
                        index=X_std.index)

    # äºˆæ¸¬ã‚«ãƒ†ã‚´ãƒª
    pred_class = prob.idxmax(axis=1).str.replace("P(", "", regex=False).str.replace(")", "", regex=False)

    out = pd.concat([
        y_raw.reset_index(drop=True).rename("y_true"),
        pred_class.reset_index(drop=True).rename("y_pred"),
        prob.reset_index(drop=True)
    ], axis=1)

    st.subheader("äºˆæ¸¬çµæœï¼ˆä¸Šä½è¡¨ç¤ºï¼‰")
    st.dataframe(out.head().style.format({col: "{:.3f}" for col in prob.columns}))

    # ä¸€è‡´ç‡
    acc = (out["y_true"].astype(str) == out["y_pred"].astype(str)).mean()
    st.write(f"**Accuracyï¼ˆå˜ç´”ä¸€è‡´ç‡ï¼‰:** {acc:.3f}")


    # ===== åŠ¹æœãƒ—ãƒ­ãƒƒãƒˆï¼ˆé¸æŠå¤‰æ•° vs äºˆæ¸¬ç¢ºç‡ï¼‰ =====
    if len(X_std.columns) >= 1:
        st.subheader("åŠ¹æœãƒ—ãƒ­ãƒƒãƒˆï¼ˆé¸æŠå¤‰æ•° vs äºˆæ¸¬ç¢ºç‡ï¼‰")
        target_var = st.selectbox("å¤‰æ•°ã‚’é¸æŠ", list(X_std.columns))
        ngrid = 50
        x_min, x_max = X_std[target_var].min(), X_std[target_var].max()
        grid = np.linspace(x_min, x_max, ngrid)

        X_base = X_std.mean().to_frame().T
        X_plot = pd.DataFrame(np.repeat(X_base.values, ngrid, axis=0), columns=X_std.columns)
        X_plot[target_var] = grid

        proba_plot = res.predict(X_plot, which="prob")
        proba_plot = np.asarray(proba_plot, dtype=float)

        p_plot = pd.DataFrame(proba_plot, columns=[str(c) for c in cats])

        fig, ax = plt.subplots(figsize=(7, 4))
        for c in p_plot.columns:
            ax.plot(grid, p_plot[c].values, label=c)
        ax.set_xlabel(f"{target_var}ï¼ˆæ¨™æº–åŒ–å¾Œï¼‰" if do_std else target_var)
        ax.set_ylabel("äºˆæ¸¬ç¢ºç‡")
        ax.legend(title="ã‚«ãƒ†ã‚´ãƒª")
        st.pyplot(fig)

def tab_MultipleRegression():
    show_card(
    """
    <h2>é‡å›å¸°ï¼ˆè‡ªå‹•å¤‰æ•°é¸æŠï¼‰</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>å¤šæ•°ã®èª¬æ˜å¤‰æ•°ã®ä¸­ã‹ã‚‰ <b>æœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’è‡ªå‹•ã§æ¢ç´¢</b> ã—ã€æœ€ã‚‚äºˆæ¸¬ç²¾åº¦ãŒé«˜ã„å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚</li>
        <li>äººæ‰‹ã§ã¯å›°é›£ãª <b>å¤‰æ•°é¸æŠãƒ»ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆfeature selectionï¼‰</b> ã‚’ CVï¼ˆã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚„æƒ…å ±é‡åŸºæº–ï¼ˆAIC/BICï¼‰ã§è‡ªå‹•åŒ–ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>å¤šãã®èª¬æ˜å¤‰æ•°ã®ä¸­ã‹ã‚‰ <b>ã©ã‚ŒãŒæœ¬å½“ã«åŠ¹ã„ã¦ã„ã‚‹ã®ã‹</b> ã‚’çŸ¥ã‚ŠãŸã„</li>
        <li>å¤šé‡å…±ç·šæ€§ãŒç–‘ã‚ã‚Œã€<b>å¤‰æ•°ã‚’æœ€é©ã«æ¸›ã‚‰ã—ãŸã„</b></li>
        <li>CVï¼ˆæ±åŒ–æ€§èƒ½ï¼‰ã‚’è¦‹ãªãŒã‚‰ <b>éå­¦ç¿’ã—ãªã„ãƒ¢ãƒ‡ãƒ«</b> ã‚’ä½œã‚ŠãŸã„</li>
        <li>åºƒå‘Šãƒ»åª’ä½“åˆ¥ã® <b>å½±éŸ¿åº¦ã‚·ã‚§ã‚¢ï¼ˆå¯„ä¸ï¼‰ã®ç®—å‡º</b> ã‚’è¡Œã„ãŸã„</li>
        <li>å£²ä¸Šã‚„æŒ‡æ¨™ã® <b>ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æï¼ˆDriver Analysisï¼‰</b> ã‚’ã—ãŸã„</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li><b>1åˆ—ç›®ï¼šæ—¥ä»˜ï¼ˆyï¼‰</b>ï¼ˆæ—¥ã«ã¡ã€é€±ãªã©ï¼‰</li>
        <li><b>2åˆ—ç›®ï¼šç›®çš„å¤‰æ•°ï¼ˆyï¼‰</b>ï¼ˆå£²ä¸Šã€èªçŸ¥å¾—ç‚¹ã€CVæ•°ãªã©ï¼‰</li>
        <li><b>3åˆ—ç›®ä»¥é™ï¼šèª¬æ˜å¤‰æ•°ï¼ˆx1, x2, ...ï¼‰</b>ï¼ˆåª’ä½“è²»ç”¨ã€æ¥è§¦æŒ‡æ¨™ã€å±æ€§ãªã©ï¼‰</li>
        <li>CSV / Excelï¼ˆ<code>A_å…¥åŠ›</code> ã‚·ãƒ¼ãƒˆãŒã‚ã‚Œã°å„ªå…ˆï¼‰</li>
        <li>æ•°å€¤åˆ—ã®ã¿è‡ªå‹•æŠ½å‡ºã—ã€éæ•°å€¤åˆ—ã¯é™¤å¤–</li>
        <li>æ¬ æå€¤å‡¦ç†ã¯ä»¥ä¸‹ã‹ã‚‰é¸æŠï¼š</li>
        <ul>
            <li>è¡Œã”ã¨å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰</li>
            <li>åˆ—å¹³å‡è£œå®Œ</li>
        </ul>
    </ul>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li><b>é¸æŠã•ã‚ŒãŸæœ€é©ãƒ¢ãƒ‡ãƒ«ï¼ˆä½¿ç”¨ã•ã‚ŒãŸèª¬æ˜å¤‰æ•°ï¼‰</b></li>
        <li><b>ä¿‚æ•°ï¼ˆå…ƒã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã—ã¦å‡ºåŠ›ï¼‰</b></li>
        <li>æ¨™æº–åŒ–ã‚ã‚Š/ãªã—ã‚’é¸æŠå¯èƒ½</li>
        <li><b>ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™</b></li>
        <ul>
            <li>CV-RÂ²</li>
            <li>CV-RMSE</li>
            <li>AIC / BIC</li>
            <li>èª¿æ•´RÂ²</li>
        </ul>
        <li><b>å¯„ä¸åˆ†è§£ï¼ˆContribution Tableï¼‰</b></li>
        <ul>
            <li>å¤‰æ•°ã”ã¨ã®å¯„ä¸é‡ï¼ˆimpactï¼‰</li>
            <li>å¹³å‡å¯„ä¸ã‚·ã‚§ã‚¢ï¼ˆã©ã®å¤‰æ•°ãŒé‡è¦ã‹ï¼‰</li>
        </ul>
        <li><b>CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</b></li>
        <ul>
            <li>ä¿‚æ•°è¡¨</li>
            <li>äºˆæ¸¬å€¤ãƒ»å¯„ä¸åˆ†è§£è¡¨</li>
        </ul>
    </ul>
    """
    )

    # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/é‡å›å¸°åˆ†æ.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="é‡å›å¸°åˆ†æ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    up = st.file_uploader("CSV / XLSX ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "xlsx"], key="regsel_file")
    if up is None:
        return

    # --- èª­ã¿è¾¼ã¿ ---
    try:
        if up.name.lower().endswith(".xlsx"):
            bytes_data = up.read()
            xls = pd.ExcelFile(BytesIO(bytes_data))
            sheet = "A_å…¥åŠ›" if "A_å…¥åŠ›" in xls.sheet_names else xls.sheet_names[0]
            df = pd.read_excel(BytesIO(bytes_data), sheet_name=sheet)
        else:
            try:
                df = pd.read_csv(up)
            except UnicodeDecodeError:
                up.seek(0)
                df = pd.read_csv(up, encoding="shift-jis")
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    if df.shape[1] < 3:
        st.error("å°‘ãªãã¨ã‚‚3åˆ—ï¼ˆç›®çš„+èª¬æ˜å¤‰æ•°ï¼‰ãŒå¿…è¦ã§ã™ã€‚")
        return

    st.write("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
    st.dataframe(df.head())

    # --- åˆ—ã®æ•´ç† ---
    y = pd.to_numeric(df.iloc[:, 1], errors="coerce")
    X_raw = df.iloc[:, 2:].copy()
    X_num = X_raw.apply(pd.to_numeric, errors="coerce")
    dropped = [c for c in X_raw.columns if c not in X_num.columns]
    if dropped:
        st.warning("æ•°å€¤åŒ–ã§ããªã„åˆ—ã‚’é™¤å¤–: " + ", ".join(map(str, dropped)))

    # æ¬ æå‡¦ç†
    na_opt = st.radio("æ¬ æã®æ‰±ã„", ["è¡Œå‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰", "åˆ—å¹³å‡ã§è£œå®Œ"], index=0, horizontal=True)
    if na_opt == "è¡Œå‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰":
        data = pd.concat([y, X_num], axis=1).dropna()
        y = data.iloc[:, 1].values.astype(float)
        X = data.iloc[:, 2:].copy()
    else:
        X = X_num.fillna(X_num.mean())
        ok = y.notna()
        y = y[ok].values.astype(float)
        X = X.loc[ok]

    feature_names = list(X.columns)
    p = len(feature_names)
    if p == 0:
        st.error("æœ‰åŠ¹ãªèª¬æ˜å¤‰æ•°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.subheader("æ¢ç´¢è¨­å®š")
    col1, col2, col3 = st.columns(3)

    with col1:
        criterion = st.selectbox(
            "æœ€é©åŒ–åŸºæº–",
            ["CV-RMSE(æœ€å°)", "CV-R2(æœ€å¤§)", "AIC(æœ€å°)", "BIC(æœ€å°)", "èª¿æ•´R2(æœ€å¤§)"],
            index=0,
            help="""
            â–¼æœ€é©åŒ–åŸºæº–
            CV-RMSEï¼šäºˆæ¸¬èª¤å·®ãŒæœ€å°ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆæ¨å¥¨ï¼‰
            CV-R2ï¼šèª¬æ˜åŠ›ãŒæœ€å¤§ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
            AIC/BICï¼šãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
            èª¿æ•´R2ï¼šèª¬æ˜å¤‰æ•°ã®æ•°ã‚’è€ƒæ…®ã—ãŸR2ï¼ˆåˆ†ã‹ã‚Šã‚„ã™ã„æŒ‡æ¨™ï¼‰
            """
        )

    with col2:
        kfold = st.number_input(
            "CV åˆ†å‰²æ•°",
            min_value=3, max_value=10, value=5,
            help="""
            â–¼CVåˆ†å‰²æ•°
            ãƒ‡ãƒ¼ã‚¿ã‚’ä½•åˆ†å‰²ã—ã¦äº¤å·®æ¤œè¨¼ã‚’è¡Œã†ã‹ã®æŒ‡å®šã€‚
            5ï½10 ãŒä¸€èˆ¬çš„ã§ã€å€¤ãŒå¤§ãã„ã»ã©æ±åŒ–æ€§èƒ½ãŒå®‰å®šã—ã¾ã™ã€‚
            """
        )

    with col3:
        max_vars = st.number_input(
            "æœ€å¤§ä½¿ç”¨å¤‰æ•°æ•°ï¼ˆè¨ˆç®—æŠ‘åˆ¶ç”¨ï¼‰",
            min_value=1, max_value=min(p, 15), value=min(10, p),
            help="""
            â–¼æœ€å¤§ä½¿ç”¨å¤‰æ•°æ•°
            ãƒ¢ãƒ‡ãƒ«ãŒæ¡ç”¨ã™ã‚‹èª¬æ˜å¤‰æ•°ã®ä¸Šé™ã€‚
            éå­¦ç¿’ã‚’é˜²ãã€è¨ˆç®—è² è·ã‚’æŠ‘ãˆã‚‹ãŸã‚ã®è¨­å®šã§ã™ã€‚
            """
        )

    method = st.radio(
        "æ¢ç´¢æ³•",
        ["å‰é€²é¸æŠï¼ˆé«˜é€Ÿï¼‰", "ãƒ™ã‚¹ãƒˆã‚µãƒ–ã‚»ãƒƒãƒˆï¼ˆä¸Šé™kã¾ã§ï¼‰"],
        index=0,
        horizontal=True,
        help="""
        â–¼æ¢ç´¢æ³•
        â— å‰é€²é¸æŠï¼šä¸€ã¤ãšã¤å¤‰æ•°ã‚’è¿½åŠ ã—ã¦æœ€é©ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ç´¢ï¼ˆé«˜é€Ÿï¼‰
        â— ãƒ™ã‚¹ãƒˆã‚µãƒ–ã‚»ãƒƒãƒˆï¼šå…¨ã¦ã®å¤‰æ•°çµ„ã¿åˆã‚ã›ã‹ã‚‰æœ€é©ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ç´¢ï¼ˆæ­£ç¢ºã ãŒè¨ˆç®—é‡ã„ï¼‰
        """
    )

    std_on = st.checkbox(
        "èª¬æ˜å¤‰æ•°ã‚’æ¨™æº–åŒ–ã—ã¦å­¦ç¿’ï¼ˆæ¨å¥¨ï¼‰",
        value=True,
        help="""
        â–¼æ¨™æº–åŒ–
        èª¬æ˜å¤‰æ•°ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æƒãˆã‚‹ã“ã¨ã§ã€é‡å›å¸°ã®ä¿‚æ•°æ¯”è¼ƒã‚„
        å¤‰æ•°é¸æŠã®å®‰å®šæ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚ï¼ˆæ¨å¥¨è¨­å®šï¼‰
        """
    )

    # --- è£œåŠ©é–¢æ•° ---
    def kfold_indices(n, k, seed=42):
        rng = np.random.default_rng(seed)
        idx = np.arange(n)
        rng.shuffle(idx)
        return np.array_split(idx, k)

    def fit_ols(Xm, yv):
        Xm_const = sm.add_constant(Xm, has_constant='add')
        model = sm.OLS(yv, Xm_const)
        res = model.fit()
        return res

    def cv_scores(cols):
        idx_folds = kfold_indices(len(y), int(kfold))
        r2s, rmses = [], []
        for val_idx in idx_folds:
            tr_idx = np.setdiff1d(np.arange(len(y)), val_idx)
            Xtr, ytr = X.iloc[tr_idx][cols], y[tr_idx]
            Xva, yva = X.iloc[val_idx][cols], y[val_idx]

            if std_on:
                mu = Xtr.mean(axis=0)
                sd = Xtr.std(axis=0).replace(0, 1e-9)
                Xtrz = (Xtr - mu) / sd
                Xvaz = (Xva - mu) / sd
                res = fit_ols(Xtrz, ytr)
                yhat = res.predict(sm.add_constant(Xvaz, has_constant='add'))
            else:
                res = fit_ols(Xtr, ytr)
                yhat = res.predict(sm.add_constant(Xva, has_constant='add'))

            yva = np.asarray(yva, dtype=float)
            yhat = np.asarray(yhat, dtype=float)
            ss_res = np.sum((yva - yhat)**2)
            ss_tot = np.sum((yva - np.mean(yva))**2) + 1e-12
            r2s.append(1 - ss_res/ss_tot)
            rmses.append(np.sqrt(np.mean((yva - yhat)**2)))
        return float(np.mean(r2s)), float(np.mean(rmses))

    def info_scores(res, nobs, kparams):
        aic = res.aic
        bic = res.bic
        r2 = res.rsquared
        adjr2 = 1 - (1-r2)*(nobs-1)/(nobs-kparams-1)
        return aic, bic, adjr2

    # --- ãƒ™ã‚¹ãƒˆä¿æŒï¼ˆâ€»mu/sdã‚‚ä¿å­˜ï¼‰ ---
    best = {"cols": [], "score": None, "res": None, "cv_r2": None, "cv_rmse": None,
            "aic": None, "bic": None, "adjr2": None, "mu": None, "sd": None}

    def evaluate(cols):
        Xsub = X[cols]
        if std_on:
            mu = Xsub.mean(axis=0)
            sd = Xsub.std(axis=0).replace(0, 1e-9)
            Xz = (Xsub - mu) / sd
            res = fit_ols(Xz, y)
        else:
            mu, sd = None, None
            res = fit_ols(Xsub, y)
        aic, bic, adjr2 = info_scores(res, res.nobs, len(cols)+1)
        cv_r2, cv_rmse = cv_scores(cols)

        if criterion == "CV-RMSE(æœ€å°)":
            score = -cv_rmse
        elif criterion == "CV-R2(æœ€å¤§)":
            score = cv_r2
        elif criterion == "AIC(æœ€å°)":
            score = -aic
        elif criterion == "BIC(æœ€å°)":
            score = -bic
        else:
            score = adjr2
        return score, res, cv_r2, cv_rmse, aic, bic, adjr2, mu, sd

    import itertools

    if method == "å‰é€²é¸æŠï¼ˆé«˜é€Ÿï¼‰":
        remaining = feature_names.copy()
        selected = []
        last_score = -1e18
        while remaining and len(selected) < max_vars:
            cand_best = None
            for c in remaining:
                cols = selected + [c]
                score, *rest = evaluate(cols)
                if (cand_best is None) or (score > cand_best[0]):
                    cand_best = (score, cols, rest)
            if cand_best and cand_best[0] > last_score + 1e-9:
                last_score = cand_best[0]
                selected = cand_best[1]
                r = cand_best[2]
                best.update({
                    "cols": selected.copy(),
                    "score": cand_best[0],
                    "res": r[0],
                    "cv_r2": r[1],
                    "cv_rmse": r[2],
                    "aic": r[3],
                    "bic": r[4],
                    "adjr2": r[5],
                    "mu": r[6],
                    "sd": r[7],
                })
                remaining = [c for c in remaining if c not in selected]
            else:
                break
    else:  # ãƒ™ã‚¹ãƒˆã‚µãƒ–ã‚»ãƒƒãƒˆ
        for k in range(1, int(max_vars)+1):
            for cols in itertools.combinations(feature_names, k):
                cols = list(cols)
                score, *rest = evaluate(cols)
                if (best["res"] is None) or (score > best["score"]):
                    best.update({
                        "cols": cols.copy(),
                        "score": score,
                        "res": rest[0],
                        "cv_r2": rest[1],
                        "cv_rmse": rest[2],
                        "aic": rest[3],
                        "bic": rest[4],
                        "adjr2": rest[5],
                        "mu": rest[6],
                        "sd": rest[7],
                    })

    # --- æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ï¼ˆå…ƒã‚¹ã‚±ãƒ¼ãƒ«ã¸æˆ»ã™ï¼‰ ---
    cols = best["cols"]
    if best["res"] is None or len(cols) == 0:
        st.error("é©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    if std_on:
        beta_std = best["res"].params.copy()      # index: const + cols
        intercept_std = beta_std.loc["const"]
        coef_std = beta_std.drop(index="const")

        mu = best["mu"].reindex(cols)
        sd = best["sd"].reindex(cols).replace(0, 1e-9)

        coef_orig = (coef_std / sd).rename(index=dict(zip(coef_std.index, cols)))
        intercept_orig = float(intercept_std - np.sum((coef_std * mu / sd).values))
    else:
        params = best["res"].params.copy()
        intercept_orig = float(params.loc["const"])
        coef_orig = params.drop(index="const")
        coef_orig.index = cols

    coef_tbl = pd.DataFrame({
        "variable": ["(Intercept)"] + cols,
        "coef": [intercept_orig] + [coef_orig[c] for c in cols]
    })
    st.subheader("é¸æŠã•ã‚ŒãŸå¤‰æ•°ã¨ä¿‚æ•°ï¼ˆå…ƒã‚¹ã‚±ãƒ¼ãƒ«ï¼‰")
    st.dataframe(coef_tbl.style.format({"coef": "{:.6g}"}))

    st.caption(f"CV-R2={best['cv_r2']:.3f} / CV-RMSE={best['cv_rmse']:.3g} / AIC={best['aic']:.1f} / BIC={best['bic']:.1f} / èª¿æ•´R2={best['adjr2']:.3f}")

    # --- å¯„ä¸ï¼ˆè²¢çŒ®åº¦ï¼‰ ---
    Xm = X[cols].copy()
    contrib = pd.DataFrame({c: coef_orig[c] * Xm[c].values for c in cols}, index=Xm.index)
    contrib["intercept"] = intercept_orig
    contrib["y_hat"] = contrib.sum(axis=1)

    st.subheader("å¯„ä¸åˆ†è§£ï¼ˆä¸Šä½è¡¨ç¤ºï¼‰")
    st.dataframe(contrib.head().style.format("{:.3g}"))

    # å¹³å‡å¯„ä¸ã¨ã‚·ã‚§ã‚¢
    avg_contrib = contrib[cols].mean().rename("avg_contrib")
    total = np.sum(np.abs(avg_contrib.values)) + 1e-12
    share = (np.abs(avg_contrib) / total).rename("share_abs")
    contrib_summary = pd.concat([avg_contrib, share], axis=1).sort_values("share_abs", ascending=False)
    st.subheader("å¹³å‡å¯„ä¸ã¨ã‚·ã‚§ã‚¢ï¼ˆ|å¹³å‡å¯„ä¸|ãƒ™ãƒ¼ã‚¹ï¼‰")
    st.dataframe(contrib_summary.style.format({"avg_contrib": "{:.3g}", "share_abs": "{:.1%}"}))

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.download_button("ä¿‚æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=coef_tbl.to_csv(index=False).encode("utf-8-sig"),
        file_name="reg_selected_coefs.csv", mime="text/csv")

    out_df = pd.concat([pd.Series(y, name="y_true"), contrib], axis=1)
    st.download_button("å¯„ä¸åˆ†è§£ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=out_df.to_csv(index=False).encode("utf-8-sig"),
        file_name="reg_contributions.csv", mime="text/csv")

def tab_SEM():
    import streamlit as st
    import pandas as pd
    import numpy as np
    from io import BytesIO

    show_card(
    """
    <h2>å…±åˆ†æ•£æ§‹é€ åˆ†æï¼ˆSEMï¼‰</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li><b>ä»®èª¬ãƒ¢ãƒ‡ãƒ«</b>ï¼ˆå› æœé–¢ä¿‚ã‚’å«ã‚€æ§‹é€ ï¼‰ã¨ <b>æ¸¬å®šãƒ¢ãƒ‡ãƒ«</b>ï¼ˆæ½œåœ¨å› å­ã¨è¦³æ¸¬å¤‰æ•°ã®é–¢ä¿‚ï¼‰ã‚’åŒæ™‚ã«æ¨å®šã—ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ¢ãƒ‡ãƒ«ã«ã©ã‚Œã ã‘é©åˆã—ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ã€‚</li>
        <li>å›å¸°ã§ã¯è¡¨ç¾ã§ããªã„ <b>è¤‡é›‘ãªå› æœãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</b> ã‚„ <b>æ½œåœ¨å¤‰æ•°ï¼ˆå¿ƒç†æŒ‡æ¨™ãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰å› å­ï¼‰</b> ã‚’æ‰±ãˆã‚‹ç‚¹ãŒç‰¹å¾´ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>ã€ŒèªçŸ¥ â†’ å¥½æ„ â†’ è¡Œå‹•æ„å›³ã€ã®ã‚ˆã†ãª <b>æ®µéšãƒ¢ãƒ‡ãƒ«ï¼ˆAISAS ç­‰ï¼‰</b> ã‚’æ¤œè¨¼ã—ãŸã„</li>
        <li>ãƒ–ãƒ©ãƒ³ãƒ‰ã‚¤ãƒ¡ãƒ¼ã‚¸ã®è¤‡æ•°é …ç›®ã‹ã‚‰æ½œåœ¨å› å­ï¼ˆä¾‹ï¼šå®‰å¿ƒæ€§ãƒ»é©æ–°æ€§ï¼‰ã‚’å®šç¾©ã—ã€ãã‚ŒãŒ <b>KPI ã«ã©ã†åŠ¹ãã‹</b> ã‚’åˆ†æã—ãŸã„</li>
        <li>å®Ÿé¨“ãƒ»æ–½ç­–ã«ãŠã‘ã‚‹ <b>ãƒ¡ãƒ‡ã‚£ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆåª’ä»‹åˆ†æï¼‰</b> ã‚’è¡Œã„ãŸã„</li>
        <li>å›å¸°åˆ†æã‚ˆã‚Šã‚‚ <b>ç†è«–ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ˜ç¢ºã«ç¤ºã—ãŸã„å ´åˆ</b>ï¼ˆãƒ¬ãƒãƒ¼ãƒˆãƒ»ãƒ—ãƒ¬ã‚¼ãƒ³ã«å¼·ã„ï¼‰</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li><b>1åˆ—ç›®ï¼šç›®çš„å¤‰æ•°ï¼ˆyï¼‰</b></li>
        <li><b>2åˆ—ç›®ä»¥é™ï¼šèª¬æ˜å¤‰æ•°ï¼ˆx1, x2, ...ï¼‰</b></li>
        <li>1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆåˆ—åï¼‰</li>
        <li>æ•°å€¤åˆ—ã®ã¿ã‚’å¯¾è±¡ï¼ˆæ½œåœ¨å¤‰æ•°ã‚’æ¸¬ã‚‹è³ªå•é …ç›®ãªã©ï¼‰</li>
        <li>Excel ã®å ´åˆã¯ <b>A_å…¥åŠ›</b> ã‚·ãƒ¼ãƒˆãŒã‚ã‚‹ã¨å„ªå…ˆã—ã¦èª­ã¿è¾¼ã‚€</li>
    </ul>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li><b>ãƒ‘ã‚¹ä¿‚æ•°ï¼ˆregression pathsï¼‰</b>ï¼šå¤‰æ•°é–“ã®å› æœçš„å½±éŸ¿ã®å¼·ã•</li>
        <li><b>å› å­è² è·é‡ï¼ˆloadingsï¼‰</b>ï¼šè¦³æ¸¬å¤‰æ•°ãŒæ½œåœ¨å› å­ã‚’ã©ã‚Œã ã‘åæ˜ ã—ã¦ã„ã‚‹ã‹</li>
        <li><b>æ¨™æº–åŒ–ä¿‚æ•°ï¼ˆstd_estï¼‰</b>ï¼šå˜ä½ã®ç•°ãªã‚‹æŒ‡æ¨™ã‚’æ¯”è¼ƒã—ã‚„ã™ã„</li>
        <li><b>é©åˆåº¦æŒ‡æ¨™ï¼ˆFit indicesï¼‰</b>
            <ul>
                <li><b>CFI / TLI</b>ï¼ˆ0.90ä»¥ä¸ŠãŒç›®å®‰ï¼‰</li>
                <li><b>RMSEA</b>ï¼ˆ0.08ä»¥ä¸‹ãŒè‰¯ã„ï¼‰</li>
                <li><b>SRMR</b>ï¼ˆ0.08ä»¥ä¸‹ãŒè‰¯ã„ï¼‰</li>
                <li><b>AIC / BIC</b>ï¼ˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã«ä½¿ç”¨ï¼‰</li>
            </ul>
        </li>
        <li><b>CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½</b>ï¼ˆä¿‚æ•°è¡¨ãƒ»é©åˆåº¦ãƒ»æ¨™æº–åŒ–è§£ï¼‰</li>
    </ul>
    """)

    # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/SEM.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="SEM.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    if not _SEM_OK:
        st.error("semopy ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
        if _SEM_ERR:
            name, msg, tb = _SEM_ERR
            st.write(f"Import error: {name}: {msg}")
            st.code(tb)
        st.stop()

    up = st.file_uploader("CSV / XLSX ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv","xlsx"], key="sem_file")
    if up is None: 
        return

    # --- èª­ã¿è¾¼ã¿ ---
    try:
        if up.name.lower().endswith(".xlsx"):
            bytes_data = up.read()
            xls = pd.ExcelFile(BytesIO(bytes_data))
            sheet = "A_å…¥åŠ›" if "A_å…¥åŠ›" in xls.sheet_names else xls.sheet_names[0]
            df = pd.read_excel(BytesIO(bytes_data), sheet_name=sheet)
        else:
            try:
                df = pd.read_csv(up)
            except UnicodeDecodeError:
                up.seek(0)
                df = pd.read_csv(up, encoding="shift-jis")
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    if df.shape[1] < 2:
        st.error("å°‘ãªãã¨ã‚‚2åˆ—ï¼ˆ1åˆ—ç›®=ç›®çš„ã€2åˆ—ç›®ä»¥é™=èª¬æ˜å¤‰æ•°ï¼‰ãŒå¿…è¦ã§ã™ã€‚")
        return

    st.write("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
    st.dataframe(df.head())

    # y / X
    y_name = df.columns[0]
    X_names = list(df.columns[1:])
    # æ•°å€¤åŒ–ãƒ»æ¬ æå‡¦ç†
    y = pd.to_numeric(df.iloc[:, 0], errors="coerce")
    X = df.iloc[:, 1:].apply(pd.to_numeric, errors="coerce")
    na_opt = st.radio("æ¬ æå€¤ã®æ‰±ã„", ["è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰", "åˆ—å¹³å‡ã§è£œå®Œ"], index=0, horizontal=True)
    if na_opt == "è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰":
        data = pd.concat([y, X], axis=1).dropna()
    else:
        X = X.fillna(X.mean())
        data = pd.concat([y, X], axis=1).dropna(subset=[y_name])

    data.columns = [y_name] + X_names  # å®‰å…¨ã«åˆ—åæƒãˆ

    st.markdown("### ãƒ¢ãƒ‡ãƒ«æŒ‡å®šï¼ˆlavaan é¢¨ï¼‰")
    st.caption("ä¾‹ï¼‰æ½œåœ¨å› å­F1ã‚’x1+x2ã§æ¸¬å®šã—ã€yã¯F1ã¨x3ã‹ã‚‰èª¬æ˜ï¼š  `F1 =~ x1 + x2`  /  `y ~ F1 + x3`")
    default_syntax = f"""# æ¸¬å®šãƒ¢ãƒ‡ãƒ«ï¼ˆå¿…è¦ãªã‚‰ï¼‰
# F1 =~ {(' + '.join(X_names[:2])) if len(X_names)>=2 else ''}

# æ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ãƒ¢ãƒ‡ãƒ«ã¯ä¸‹ã®ãƒã‚§ãƒƒã‚¯ã§ä½œã‚Œã¾ã™ï¼‰
{y_name} ~ {' + '.join(X_names)}
"""
    use_auto = st.checkbox("è‡ªå‹•ãƒ¢ãƒ‡ãƒ«ï¼ˆè¦³æ¸¬å¤‰æ•°â†’ç›®çš„å¤‰æ•°ã®ãƒ‘ã‚¹ã®ã¿ï¼‰ã‚’ä½¿ã†", value=True)
    syntax = st.text_area("ãƒ¢ãƒ‡ãƒ«å¼ï¼ˆsemopy å½¢å¼ï¼‰", value=default_syntax, height=160)

    if use_auto:
        syntax = f"{y_name} ~ " + " + ".join(X_names)

    st.code(syntax, language="markdown")

    if st.button("æ¨å®šã‚’å®Ÿè¡Œ"):
        try:
            # å¹³å‡æ§‹é€ ã‚ã‚Šï¼ˆåˆ‡ç‰‡æ¨å®šï¼‰
            model = ModelMeans(syntax)
            model.fit(data)
        except Exception as e:
            st.error(f"æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return

        # ä¿‚æ•°ï¼ˆæ¨å®šå€¤ãƒ»SEãƒ»zãƒ»pï¼‰
        try:
            # ã‚‚ã£ã¨ã‚‚äº’æ›æ€§ãŒé«˜ã„
            est = inspect(model)  
        except Exception:
            # å¤ã„ semopy ç”¨
            try:
                est = model.parameters_dataframe()
            except Exception:
                est = model.inspect()

        st.subheader("æ¨å®šçµæœï¼ˆä¿‚æ•°ï¼‰")
        st.dataframe(est)

        # é©åˆåº¦æŒ‡æ¨™
        try:
            stats = get_sem_stats(model, data)
            fit_df = pd.DataFrame({
                "metric": ["CFI","TLI","RMSEA","SRMR","AIC","BIC","DOF","n_params"],
                "value": [stats.get("CFI"), stats.get("TLI"), stats.get("RMSEA"),
                          stats.get("SRMR"), stats.get("AIC"), stats.get("BIC"),
                          stats.get("DoF"), stats.get("n_params")]
            })
            st.subheader("é©åˆåº¦æŒ‡æ¨™")
            st.dataframe(fit_df)
            st.caption("ç›®å®‰ï¼šCFI/TLIâ‰¥0.90ã€RMSEAâ‰¤0.08ã€SRMRâ‰¤0.08ï¼ˆæ–‡è„ˆä¾å­˜ï¼‰")
        except Exception:
            st.info("é©åˆåº¦çµ±è¨ˆã®ç®—å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        # æ¨™æº–åŒ–è§£ï¼ˆæ¨å¥¨ï¼šè§£é‡ˆã—ã‚„ã™ã„ï¼‰
        try:
            std_est = inspect(model, std_est=True)
            st.subheader("æ¨™æº–åŒ–è§£ï¼ˆæ¨™æº–åŒ–ä¿‚æ•°ï¼‰")
            st.dataframe(std_est)
        except Exception:
            pass

        # äºˆæ¸¬ãƒ»æ®‹å·®ï¼ˆyã®ã¿è¡¨ç¤ºï¼‰
        try:
            y_pred = model.predict_factors(data)  # æ½œåœ¨å› å­æ¨å®š
        except Exception:
            y_pred = pd.DataFrame()

        try:
            implied = model.implied_covariance  # æš—é»™ã®å…±åˆ†æ•£
        except Exception:
            implied = None

        # å‡ºåŠ›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        @st.cache_data
        def _csv_bytes(df_):
            return df_.to_csv(index=False).encode("utf-8-sig")

        st.download_button("ä¿‚æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                           data=_csv_bytes(est), file_name="sem_params.csv", mime="text/csv")

        if 'std_est' in locals():
            st.download_button("æ¨™æº–åŒ–è§£ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                               data=_csv_bytes(std_est), file_name="sem_std_params.csv", mime="text/csv")


def tab_MMM():
    show_card("""
    <h2>MMMï¼ˆè»½é‡ç‰ˆï¼‰</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>åºƒå‘ŠæŠ•è³‡é¡ï¼ˆTVãƒ»Webãƒ»OOH ãªã©ï¼‰ãŒ <b>KPIï¼ˆå£²ä¸Šãƒ»CVãƒ»æŒ‡æ¨™ï¼‰ã«ã©ã‚Œã ã‘å¯„ä¸ã—ã¦ã„ã‚‹ã‹</b> ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚</li>
        <li><b>ã‚¢ãƒ‰ã‚¹ãƒˆãƒƒã‚¯ï¼ˆåºƒå‘Šã®é…åŠ¹æ€§ï¼‰</b> ã¨ <b>é£½å’Œï¼ˆé€“æ¸›åŠ¹æœï¼‰</b> ã‚’è€ƒæ…®ã—ã€  
        ã‚ˆã‚Šç¾å®Ÿçš„ãªåå¿œæ›²ç·šã‚’æ¨å®šã—ã€åª’ä½“åˆ¥ã® <b>çœŸã®åŠ¹æœé‡ï¼ˆè²¢çŒ®åº¦ / ROIï¼‰</b> ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</li>
        <li>éå»ã®æŠ•è³‡å®Ÿç¸¾ã‹ã‚‰ã€<b>æœ€é©ãªæŠ•ä¸‹é…åˆ†</b> ã‚„ <b>è¿½åŠ æŠ•è³‡ã®é™ç•ŒåŠ¹æœï¼ˆé™ç•ŒåŠ¹ç”¨ï¼‰</b> ã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚</li>
    </ul>
    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>è¤‡æ•°åª’ä½“ã®æŠ•è³‡é¡ã¨KPIã‚’ä½¿ã„ã€<b>åª’ä½“åˆ¥ROI</b> ã‚’æ±‚ã‚ãŸã„</li>
        <li>æŠ•è³‡ã‚’å¢—æ¸›ã—ãŸéš›ã® <b>äºˆæ¸¬ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ</b> ã‚’è¦‹ãŸã„ï¼ˆä¾‹ï¼š10%å¢—ãªã‚‰ã©ã‚Œã ã‘ä¼¸ã³ã‚‹ï¼Ÿï¼‰</li>
        <li>åºƒå‘Šä¸»ãƒ¬ãƒãƒ¼ãƒˆã§ä¸€èˆ¬çš„ãª <b>å¯„ä¸åˆ†è§£ï¼ˆcontribution analysisï¼‰</b> ã‚’è¡Œã„ãŸã„</li>
        <li>åºƒå‘ŠåŠ¹æœã® <b>é…åŠ¹æ€§ï¼ˆç¿Œé€±ãƒ»ç¿Œæœˆã«åŠ¹ãï¼‰</b> ã‚’ãƒ¢ãƒ‡ãƒ«ã«å…¥ã‚ŒãŸã„</li>
        <li><b>äºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</b>ï¼ˆä»Šå¾Œã®æŠ•è³‡é…åˆ†ã®å‚è€ƒï¼‰ã«ã‚‚ä½¿ã„ãŸã„</li>
    </ul>
    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li><b>1åˆ—ç›®ï¼šdateï¼ˆæ—¥ä»˜ / é€±æ¬¡ / æœˆæ¬¡ï¼‰</b></li>
        <li><b>2åˆ—ç›®ï¼šyï¼ˆKPIï¼šå£²ä¸Šãƒ»CVãƒ»æ¤œç´¢æ•°ãªã©ï¼‰</b></li>
        <li><b>3åˆ—ç›®ä»¥é™ï¼šåª’ä½“è²»ç”¨ï¼ˆtv_spend / web_spend / sns_spend â€¦ï¼‰</b></li>
        <li>ä¾‹ï¼š</li>
    </ul>
    <table>
    <tr><th>date</th><th>y</th><th>tv_spend</th><th>web_spend</th><th>sns_spend</th></tr>
    <tr><td>2024-01-01</td><td>1200</td><td>300</td><td>200</td><td>150</td></tr>
    </table>
    <ul>
        <li>CSV / Excel ã«å¯¾å¿œ</li>
        <li>æ¬ æå€¤ã¯è‡ªå‹•é™¤å¤– or å¹³å‡è£œå®Œ</li>
        <li>æ•°å€¤åˆ—ä»¥å¤–ã¯è‡ªå‹•é™¤å¤–</li>
    </ul>
    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li><b>æ¨å®šãƒ¢ãƒ‡ãƒ«ï¼ˆåå¿œæ›²ç·šï¼‰</b></li>
        <ul>
            <li>ã‚¢ãƒ‰ã‚¹ãƒˆãƒƒã‚¯å‡¦ç†ï¼šåºƒå‘Šã®è“„ç©åŠ¹æœã‚’å†ç¾</li>
            <li>Hillå¼ï¼šè²»ç”¨å¢—åŠ ã«ä¼´ã†é£½å’Œï¼ˆä¼¸ã³ã«ãã•ï¼‰ã‚’å†ç¾</li>
        </ul>
        <li><b>åª’ä½“åˆ¥ã®ä¿‚æ•°ï¼ˆå½±éŸ¿åº¦ï¼‰</b>ï¼šå¤‰æ›å¾Œç‰¹å¾´é‡ã®ä¿‚æ•°</li>
        <li><b>å¯„ä¸åˆ†è§£ï¼ˆContributionï¼‰</b></li>
        <ul>
            <li>å„åª’ä½“ãŒ y ã«ä¸ãˆãŸå¯„ä¸é¡</li>
            <li>å¹³å‡å¯„ä¸ã‚·ã‚§ã‚¢ï¼ˆæœ€ã‚‚è²¢çŒ®ã—ãŸåª’ä½“ã¯ï¼Ÿï¼‰</li>
        </ul>
        <li><b>åå¿œæ›²ç·šï¼ˆResponse Curveï¼‰</b></li>
        <ul>
            <li>æŠ•å…¥é¡ã«å¿œã˜ã¦ KPI ãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹</li>
        </ul>
        <li><b>é™ç•ŒåŠ¹ç”¨ï¼ˆdROIï¼‰</b></li>
        <ul>
            <li>è¿½åŠ æŠ•è³‡1å˜ä½ã‚ãŸã‚Šã®å¢—åŠ åŠ¹æœ</li>
            <li>æœ€é©æŠ•è³‡ã®æ¤œè¨ã«å¿…é ˆ</li>
        </ul>
        <li><b>äºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</b></li>
        <ul>
            <li>ç·äºˆç®—ã‚’ Â±â—‹% å¤‰ãˆãŸå ´åˆã® KPI å¤‰åŒ–ã‚’è‡ªå‹•è¨ˆç®—</li>
        </ul>
        <li><b>CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</b></li>
        <ul>
            <li>å¯„ä¸åˆ†è§£è¡¨</li>
            <li>ä¿‚æ•°è¡¨</li>
            <li>äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿</li>
        </ul>
    </ul>
    """
    )
            # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/MMM.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="MMM.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


    up = st.file_uploader("CSV / XLSX ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "xlsx"], key="mmm_lite_file")
    if up is None:
        return

    # --- èª­ã¿è¾¼ã¿ ---
    try:
        if up.name.lower().endswith(".xlsx"):
            bytes_data = up.read()
            xls = pd.ExcelFile(BytesIO(bytes_data))
            sheet = "A_å…¥åŠ›" if "A_å…¥åŠ›" in xls.sheet_names else xls.sheet_names[0]
            df = pd.read_excel(BytesIO(bytes_data), sheet_name=sheet)
        else:
            try:
                df = pd.read_csv(up)
            except UnicodeDecodeError:
                up.seek(0)
                df = pd.read_csv(up, encoding="shift-jis")
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # åˆ—åæ•´å½¢
    df.columns = pd.Index(df.columns).map(str)
    if df.shape[1] < 3:
        st.error("åˆ—ã¯æœ€ä½3åˆ—ï¼ˆdate, y, spend...ï¼‰ãŒå¿…è¦ã§ã™ã€‚")
        return

    # åŸºæœ¬æ•´å½¢
    date_col = df.columns[0]
    y_col = df.columns[1]
    spend_cols = list(df.columns[2:])

    # å‹å¤‰æ›
    try:
        df[date_col] = pd.to_datetime(df[date_col])
    except Exception:
        st.warning("date åˆ—ã‚’æ—¥ä»˜ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ–‡å­—åˆ—ã®ã¾ã¾ã§å‡¦ç†ã—ã¾ã™ã€‚")

    y = pd.to_numeric(df[y_col], errors="coerce")
    X_spend = df[spend_cols].apply(pd.to_numeric, errors="coerce")
    data = pd.concat([y, X_spend], axis=1).dropna()
    y = data.iloc[:, 0].values.astype(float)
    X_spend = data.iloc[:, 1:].copy()
    spend_cols = list(X_spend.columns)

    st.write("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
    st.dataframe(pd.concat([pd.Series(y, name=y_col), X_spend], axis=1).head())

        # --- ãƒã‚¤ãƒ‘ãƒ©è¨­å®šï¼ˆUIã¯ãã®ã¾ã¾ä½¿ãˆã‚‹ï¼‰ ---
    with st.expander("ãƒã‚¤ãƒ‘ãƒ©è¨­å®šï¼ˆå¿…è¦ãªã‚‰å¤‰æ›´ï¼‰", expanded=False):
        alphas = st.multiselect("ã‚¢ãƒ‰ã‚¹ãƒˆãƒƒã‚¯æ¸›è¡° Î± å€™è£œï¼ˆ0ï½0.99ã€‚é«˜ã„ã»ã©é•·ã„é…åŠ¹ï¼‰",
                                [0.3, 0.5, 0.7, 0.85, 0.9], default=[0.5, 0.7, 0.85])
        betas = st.multiselect("é£½å’Œï¼ˆHillï¼‰ Î² å€™è£œï¼ˆ>0ã€‚å°ã•ã„ã»ã©æ—©ãé£½å’Œï¼‰",
                               [0.5, 1.0, 2.0, 3.0], default=[1.0, 2.0])
        lam_grid = st.multiselect("Ridge Î±ï¼ˆæ­£å‰‡åŒ–å¼·ã•ï¼‰", [0.1, 1.0, 3.0, 10.0, 30.0], default=[1.0, 3.0, 10.0])
        kfold = st.number_input("CVåˆ†å‰²æ•°", min_value=3, max_value=10, value=5)

    if not alphas or not betas:
        st.error("Î±, Î² ã®å€™è£œã¯1ã¤ä»¥ä¸Šé¸ã‚“ã§ãã ã•ã„ã€‚")
        return

    # --- å¤‰æ›é–¢æ•° ---
    def adstock_geometric(x, alpha):
        out = np.zeros_like(x, dtype=float)
        carry = 0.0
        for t, val in enumerate(np.asarray(x, dtype=float)):
            out[t] = val + alpha * carry
            carry = out[t]
        return out

    def hill_saturation(x, beta):
        x = np.asarray(x, dtype=float)
        if np.nanmax(x) == np.nanmin(x):
            return np.zeros_like(x)
        x_norm = (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x) + 1e-9)
        return x_norm ** (1.0 / beta)

    # --- NumPyç‰ˆ RidgeCVï¼ˆåˆ‡ç‰‡ã¯è‡ªå‰ã§æ‰±ã†ï¼‰ ---
    def r2_score(y_true, y_pred):
        y_true = np.asarray(y_true, dtype=float)
        y_pred = np.asarray(y_pred, dtype=float)
        ss_res = np.sum((y_true - y_pred) ** 2)
        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2) + 1e-12
        return 1.0 - ss_res / ss_tot

    def ridge_fit_predict(X_tr, y_tr, X_te, lam):
        # æ¨™æº–åŒ–ï¼ˆè¨“ç·´çµ±è¨ˆé‡ã§ï¼‰
        mu = X_tr.mean(axis=0, keepdims=True)
        sd = X_tr.std(axis=0, keepdims=True) + 1e-9
        Xz_tr = (X_tr - mu) / sd
        Xz_te = (X_te - mu) / sd

        # ä¸­å¿ƒåŒ–ã—ã¦åˆ‡ç‰‡åˆ†é›¢
        y_mu = y_tr.mean()
        y_center = y_tr - y_mu

        # (X^T X + lam I)Î² = X^T y
        XtX = Xz_tr.T @ Xz_tr
        p = XtX.shape[0]
        beta = np.linalg.solve(XtX + lam * np.eye(p), Xz_tr.T @ y_center)
        intercept = y_mu  # æ¨™æº–åŒ–å¾Œã®ç‰¹å¾´é‡ã¯å¹³å‡0

        y_pred_tr = Xz_tr @ beta + intercept
        y_pred_te = Xz_te @ beta + intercept
        return beta, intercept, mu, sd, y_pred_tr, y_pred_te

    def kfold_indices(n, k, seed=42):
        rng = np.random.default_rng(seed)
        idx = np.arange(n)
        rng.shuffle(idx)
        folds = np.array_split(idx, k)
        return folds

    # --- ãƒã‚¤ãƒ‘ãƒ©æ¢ç´¢ï¼ˆå„ãƒãƒ£ãƒãƒ«ã§åŒä¸€ Î±/Î² ã‚’æ¡ç”¨ã™ã‚‹ç°¡æ˜“ç‰ˆï¼‰ ---
    best_score = -np.inf
    best_cfg = None
    best_X = None

    for a in alphas:
        # ã‚¢ãƒ‰ã‚¹ãƒˆãƒƒã‚¯
        X_ads = np.column_stack([adstock_geometric(X_spend[c].values, a) for c in spend_cols])

        for b in betas:
            # é£½å’Œ
            X_sat = np.column_stack([hill_saturation(X_ads[:, i], b) for i in range(X_ads.shape[1])])

            # ã“ã“ã§ã¯ CV å†…ã§æ¨™æº–åŒ–ã™ã‚‹ã®ã§ã€ä»Šã¯ãã®ã¾ã¾
            n = len(y)
            folds = kfold_indices(n, int(kfold), seed=42)

            best_lam = None
            best_cv = -np.inf
            best_fit = None

            for lam in lam_grid:
                scores = []
                for vi in range(len(folds)):
                    val_idx = folds[vi]
                    tr_idx = np.setdiff1d(np.arange(n), val_idx, assume_unique=False)

                    X_tr, y_tr = X_sat[tr_idx], y[tr_idx]
                    X_va, y_va = X_sat[val_idx], y[val_idx]

                    beta, intercept, mu, sd, y_pred_tr, y_pred_va = ridge_fit_predict(X_tr, y_tr, X_va, lam)
                    scores.append(r2_score(y_va, y_pred_va))

                cv_mean = float(np.mean(scores))
                if cv_mean > best_cv:
                    best_cv = cv_mean
                    best_lam = lam

            # ãƒ™ã‚¹ãƒˆ lam ã§å…¨ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚£ãƒƒãƒˆï¼ˆæœ€çµ‚ãƒ¢ãƒ‡ãƒ«ï¼‰
            beta, intercept, mu, sd, y_pred_tr, _ = ridge_fit_predict(X_sat, y, X_sat, best_lam)

            if best_cv > best_score:
                best_score = best_cv
                best_cfg = (a, b, best_lam, mu, sd, beta, intercept)
                # æœ€çµ‚ã®æ¨™æº–åŒ–ç‰¹å¾´é‡
                X_trans = (X_sat - mu) / sd
                best_X = X_trans

    a_star, b_star, lam_star, mu_star, sd_star, coef_star, intercept_star = best_cfg
    st.success(f"Best CV RÂ² = {best_score:.3f} | alpha={a_star} / beta={b_star} / ridge={lam_star}")

    # --- å­¦ç¿’æ¸ˆã¿ã§å¯„ä¸åˆ†è§£ ---
    y_hat = best_X @ coef_star + intercept_star
    resid = y - y_hat

    # ãƒãƒ£ãƒãƒ«å¯„ä¸ï¼ˆåˆ†è§£ã¯ç·šå½¢ã®ãŸã‚ã€å„åˆ—Ã—ä¿‚æ•°ï¼‰
    contrib = best_X * coef_star  # shape [T, K]
    contrib_df = pd.DataFrame(contrib, columns=spend_cols)
    contrib_df["intercept"] = intercept_star
    contrib_df["residual"] = resid
    st.subheader("å¯„ä¸åˆ†è§£ï¼ˆheadï¼‰")
    st.dataframe(contrib_df.head().style.format("{:.3f}"))

    # --- åå¿œæ›²ç·š & é™ç•ŒåŠ¹ç‡ï¼ˆdROIï¼‰ ---
    st.subheader("åå¿œæ›²ç·šï¼ˆé€“æ¸›ï¼‰ã¨é™ç•ŒåŠ¹ç‡")

    # æ›²ç·šã¯ã€Œå˜ä¸€ãƒãƒ£ãƒãƒ«ã ã‘ã‚’å‹•ã‹ã™ã€å‰æã§ä½œå›³ï¼ˆä»–ã¯å¹³å‡ï¼‰
    ngrid = 50
    fig, axes = plt.subplots(len(spend_cols), 1, figsize=(7, 3*len(spend_cols)))
    if len(spend_cols) == 1:
        axes = [axes]

    for idx, ch in enumerate(spend_cols):
        base = X_spend.copy()
        x_raw = base[ch].values
        lo, hi = np.percentile(x_raw, [1, 99])
        grid = np.linspace(max(0, lo), hi, ngrid)

        # ä»–ãƒãƒ£ãƒãƒ«ã¯å¹³å‡å›ºå®šã€å¯¾è±¡ã ã‘ã‚’ grid ã«ç½®æ› â†’ å¤‰æ› â†’ æ¨™æº–åŒ– â†’ äºˆæ¸¬
        base_vals = base.mean().to_dict()
        curves = []
        drois = []

        for g in grid:
            tmp = base.copy()
            for c in spend_cols:
                tmp[c] = base_vals[c]
            tmp[ch] = g

            # adstock -> saturation -> standardize
            Xg_ads = np.column_stack([adstock_geometric(tmp[c].values, a_star) for c in spend_cols])
            Xg_sat = np.column_stack([hill_saturation(Xg_ads[:, i], b_star) for i in range(Xg_ads.shape[1])])
            Xg = (Xg_sat - mu_star) / sd_star

            y_pred = Xg @ coef_star + intercept_star
            curves.append(np.mean(y_pred))

        curves = np.array(curves)

        # æ•°å€¤å¾®åˆ†ã§é™ç•ŒåŠ¹ç‡ï¼ˆdROIç›¸å½“ï¼‰ã‚’ç®—å‡ºï¼ˆÎ”y / Î”spendï¼‰
        droi = np.gradient(curves, grid)

        ax = axes[idx]
        ax.plot(grid, curves, label=f"Response: {ch}")
        ax2 = ax.twinx()
        ax2.plot(grid, droi, linestyle="--", label="Marginal effect (dROI)")

        ax.set_xlabel(f"{ch}ï¼ˆæŠ•å…¥é¡ï¼‰")
        ax.set_ylabel("äºˆæ¸¬KPI")
        ax2.set_ylabel("é™ç•ŒåŠ¹ç‡")
        ax.legend(loc="upper left")
        ax2.legend(loc="upper right")

    st.pyplot(fig)

    # --- ä¿‚æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆè§£é‡ˆç”¨ï¼‰ ---
    st.dataframe(contrib_df.head().round(3))

    coef_tbl = pd.DataFrame({"channel": spend_cols, "coef_on_transformed": coef_star})
    st.subheader("ä¿‚æ•°ï¼ˆå¤‰æ›å¾Œç‰¹å¾´é‡ä¸Šï¼‰")
    st.dataframe(coef_tbl.assign(
        coef_on_transformed=lambda d: d["coef_on_transformed"].round(4)
    ))


    # --- äºˆç®—ã‚·ãƒŸãƒ¥ï¼ˆå…¨ä½“Ã—Â±x%ï¼‰ ---
    st.subheader("ç°¡æ˜“äºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    pct = st.slider("ç·äºˆç®—ã‚’ä½•%å¢—æ¸›ã™ã‚‹ã‹", min_value=-50, max_value=100, value=10, step=5)
    scale = 1.0 + pct/100.0
    spend_new = X_spend.mean() * scale

    tmp = X_spend.copy()
    for c in spend_cols:
        tmp[c] = spend_new[c]

    Xn_ads = np.column_stack([adstock_geometric(tmp[c].values, a_star) for c in spend_cols])
    Xn_sat = np.column_stack([hill_saturation(Xn_ads[:, i], b_star) for i in range(Xn_ads.shape[1])])
    Xn = (Xn_sat - mu_star) / sd_star
    y_pred_new = Xn @ coef_star + intercept_star

    st.write(f"å¹³å‡KPIï¼ˆç¾çŠ¶ï¼‰: {np.mean(y_hat):.3f} â†’ å¤‰æ›´å¾Œ: {np.mean(y_pred_new):.3f}ï¼ˆ{pct:+d}%äºˆç®—ï¼‰")



def tab_STL():
    show_card(
    """
    <h2>STLåˆ†è§£</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ <b>ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»å­£ç¯€æ€§ãƒ»æ®‹å·®</b> ã«åˆ†è§£ã—ã€  
            ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ï¼ˆå‘¨æœŸæ€§ãƒ»é•·æœŸå‚¾å‘ãƒ»ç•°å¸¸å€¤ãªã©ï¼‰ã‚’æŠŠæ¡ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>Googleãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»DS.INSIGHT ãªã©ã‹ã‚‰ KW ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®  
            <b>å­£ç¯€æ€§ã‚„é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰</b> ã‚’ç¢ºèªã—ãŸã„ã¨ã</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li><b>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿</b>ï¼ˆæœŸé–“ Ã— KW ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰ã‚’å…¥åŠ›</li>
        <li>é€±æ¬¡ãƒ»æœˆæ¬¡ã©ã¡ã‚‰ã§ã‚‚è‡ªå‹•åˆ¤åˆ¥ã—ã¦å‡¦ç†ã—ã¾ã™</li>
    </ul>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li><b>_raw</b>ï¼šå…ƒã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿</li>
        <li><b>_trend</b>ï¼šãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†ï¼ˆé•·æœŸçš„ãªå¢—æ¸›ï¼‰</li>
        <li><b>_seasonal</b>ï¼šå­£ç¯€æˆåˆ†ï¼ˆå‘¨æœŸçš„å¤‰å‹•ï¼‰</li>
        <li><b>_resid</b>ï¼šæ®‹å·®æˆåˆ†ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼‹å­£ç¯€æ€§ã‚’é™¤å»ã—ãŸå¾Œã®ãƒã‚¤ã‚ºï¼‰</li>
    </ul>

    <p>
    KW ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®éå»å‚¾å‘ã‚’æŠŠæ¡ã—ã€<b>å­£ç¯€æ€§ or é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰</b> ãŒ  
    ã©ã‚Œã»ã©å½±éŸ¿ã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ã§ãã¾ã™ã€‚  
    <strong>é€±æ¬¡ãƒ»æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã©ã¡ã‚‰ã«ã‚‚å¯¾å¿œ</strong>ã—ã€STLãŒè‡ªå‹•çš„ã«å‡¦ç†ã—ã¾ã™ã€‚
    </p>
    """
    )

        # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/STLåˆ†è§£.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="STLåˆ†è§£.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    if 'uploaded_file_tab2' not in st.session_state:
        st.session_state.uploaded_file_tab2 = None

    uploaded_file = st.file_uploader("STLåˆ†è§£ç”¨inputãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv", "xlsx"], key='tab2_uploader')

    if uploaded_file is not None:
        st.session_state.uploaded_file_tab2 = uploaded_file
        try:
            if uploaded_file.name.endswith("csv"):
                df = pd.read_csv(uploaded_file)
            elif uploaded_file.name.endswith("xlsx"):
                df = pd.read_excel(uploaded_file)
            
            st.write("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
            st.write(df.head())

            period_num = (df.iat[1, 0] - df.iat[0, 0]).days
            data_num = df.shape[1] - 1
            df_date = df.iloc[:, 0]
            df = df.set_index("date")
            df.head()

            ##â– å‘¨æœŸã®è¨­å®š##
            if period_num > 7:
                period = 12
            elif period_num == 7:
                period = 52
            elif period_num == 1:
                period = 365
            else:
                period = 0
                print("ä»»æ„ã®æœŸé–“ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

            print(period)

            ##â– åˆ†è§£##
            result = pd.DataFrame()

            # DataFrameå†…ã®å„åˆ—ã«å¯¾ã—ã¦ãƒ«ãƒ¼ãƒ—å‡¦ç†
            for i in range(data_num):
                stl = sm.tsa.seasonal_decompose(df.iloc[:, i], period=period)
                name = df.columns.values[i]

                tmp = pd.DataFrame()
                tmp[str(name) + "_raw"] = df.iloc[:, i]
                tmp[str(name) + "_trend"] = stl.trend
                tmp[str(name) + "_seasonal"] = stl.seasonal
                tmp[str(name) + "_resid"] = stl.resid

                result = pd.concat([result, tmp], axis=1)

                # ãã‚Œãã‚Œã®ç³»åˆ—ã”ã¨ã«ç‹¬ç«‹ã—ãŸã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹
                fig, ax = plt.subplots()
                for column in tmp.columns:
                    if "_raw" in column or "_trend" in column or "_seasonal" in column:
                        ax.plot(df.index, tmp[column], label=column)  # DataFrame ã® index ã‚’ Xè»¸ã«ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ

                ax.set_xlabel('Date')
                ax.set_ylabel('Value')
                ax.set_title('Decomposition of ' + str(name))  # ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«
                ax.legend()

                st.pyplot(fig)  # ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º

            st.write(result)
            download(result)

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€éš›ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")



def tab_TIME():
    show_card("""
    <h2>TIMEæœ€é©åŒ–</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>TIMEã®è¤‡æ•°ç´ æå‰²ã‚Šä»˜ã‘ã‚’æœ€é©åŒ–ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>è¤‡æ•°ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’ TIME ã§æ”¾æ˜ ã™ã‚‹å ´åˆ</li>
        <li>ãƒ¬ã‚®ãƒ¥ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ  / FTB / å˜ç™ºã‚¿ã‚¤ãƒ ãªã©å›ºå®šæ ãŒã‚ã‚‹å ´åˆ</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li>Aã€œDã‚·ãƒ¼ãƒˆã‚’ãã‚Œãã‚Œå…¥åŠ›</li>
    </ul>

    <p>
    <a href="https://hakuhodody.sharepoint.com/:f:/s/msteams_d8fd35/Eu6cDQ4W-t5KlsMGSjLhfQQBaYubS13B_Ge2FzODeaZO-A?e=lvq7tE" target="_blank">
    ğŸ”— å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’é–‹ã
    </a>
    </p>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li>ãƒ–ãƒ©ãƒ³ãƒ‰ã”ã¨ã®æœ€é©ç•ªçµ„ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³</li>
        <li>ç•ªçµ„è¿½åŠ ã«ã‚ˆã‚‹ç´¯ç©ãƒªãƒ¼ãƒ</li>
        <li>æœ€é©åŒ–å¾Œã®ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥äºˆç®—</li>
        <li>Aã‚·ãƒ¼ãƒˆã¨Cã‚·ãƒ¼ãƒˆã®ç•ªçµ„IDã¯ã€Œæ¼ã‚Œãªããƒ»ãƒ€ãƒ–ã‚Šãªãã€å‡¦ç†</li>
    </ul>
    """
    )

    # ---- ã“ã“ã‹ã‚‰ä¸‹ã¯å¾“æ¥ã®å‡¦ç†ï¼ˆãã®ã¾ã¾ã§OKï¼‰ ----

    st.title("ãƒ¢ãƒ¼ãƒ‰é¸æŠ")

    # ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³é¸æŠè‚¢
    options = ["reach cost", "reach", "target_cost"]
    mode = st.selectbox("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„", options, index=2)

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèª
    if "uploaded_file" not in st.session_state:
        st.session_state["uploaded_file"] = None

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])

    if uploaded_file is not None:
        try:
            st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨ã‚·ãƒ¼ãƒˆã‚’å–å¾—
            if uploaded_file.type == "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet":
                bytes_data = uploaded_file.read()
                sheets = pd.read_excel(BytesIO(bytes_data), sheet_name=None)

                # å„ã‚·ãƒ¼ãƒˆã‚’å–å¾—
                limit_data = sheets['A_Limit'].set_index(['Program_code', 'date'])
                brand_data = sheets['B_Brand'].set_index('Brand')
                view_data = sheets['C_View'].set_index('Sample')
                target_data = sheets['D_Target'].set_index('Brand')

                # ç¢ºèªã®ãŸã‚ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                st.write("### A_Limit ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
                st.dataframe(limit_data.head())

                st.write("### B_Brand ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
                st.dataframe(brand_data.head())

                st.write("### C_View ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
                st.dataframe(view_data.head())

                st.write("### D_Target ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
                st.dataframe(target_data.head())

            else:
                st.error("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯Excelå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

            st.write("èª­è¾¼çµ‚äº†")



            # ã€Œç„¡ã—ã€ã¨ã„ã†å€¤ã‚’ç©ºç™½ã«ç½®ãæ›ãˆã€å¿…é ˆç•ªçµ„ãƒ‡ãƒ¼ã‚¿ã¨é™¤å¤–ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            exc_data = limit_data.copy()
            must_data = limit_data.copy()

            values_to_replace_exc = [15, 30, 60, 120, 240]
            values_to_replace_must = ["ç„¡ã—"]
            exc_data.replace(values_to_replace_exc, '', inplace=True)  # é™¤å¤–ã®0-1ãƒ‡ãƒ¼ã‚¿
            must_data.replace(values_to_replace_must, '', inplace=True)  # å¿…é ˆç•ªçµ„ã®å‰²ã‚ŠæŒ¯ã‚Šç§’æ•°ãƒ‡ãƒ¼ã‚¿

            # ãƒ–ãƒ©ãƒ³ãƒ‰åã®ãƒªã‚¹ãƒˆã‚’å–å¾—
            brand_names = brand_data.index.tolist()
            #ãƒ–ãƒ©ãƒ³ãƒ‰ã®å‰²ã‚Šä»˜ã‘æƒ…å ±ãŒå…¥ã£ã¦ã‚‹
            temp_brand_data = limit_data.copy()
            temp_brand_data = temp_brand_data.drop(columns=[col for col in limit_data.columns if 'Cost/30' in col])
            temp_brand_data = temp_brand_data.drop(columns=[col for col in limit_data.columns if 'P_seconds' in col])
            temp_brand_data = temp_brand_data.drop(columns=[col for col in limit_data.columns if 'Program' in col])

            #ç•ªçµ„ã®ã‚³ã‚¹ãƒˆã¨ç§’æ•°
            temp_program_data = limit_data[['Cost/30', 'P_seconds']]

            # å„ãƒ–ãƒ©ãƒ³ãƒ‰ã®å½“åˆã®äºˆç®—ã‚’ä¿å­˜
            allocated_brand_data = brand_data.copy()  # å‰²ã‚Šä»˜ã‘ã«ä½¿ã†ãƒ–ãƒ©ãƒ³ãƒ‰ã”ã¨ã®äºˆç®—
            initial_brand_budget = allocated_brand_data.copy()  # å‰²ã‚Šä»˜ã‘å‰ã®åˆæœŸäºˆç®—
            used_brand_budget = pd.DataFrame(0, index=brand_names, columns=[120, 60, 30, 15])  # å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸäºˆç®—ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

            # è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹è¾æ›¸ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«åŸºã¥ãé•·ã•ã‚’è¨­å®šï¼‰
            brand_view_data = {}
            # target_dataãŒDataFrameã§ã‚ã‚‹ã“ã¨ã‚’ä»®å®š
            brand_target = target_data

            for brand_column in brand_names:
                # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹´é½¢ç¯„å›²ã¨æ€§åˆ¥ã‚’å–å¾—
                target_age_range = brand_target.loc[brand_column, ['Low', 'High']]  # å¹´é½¢ç¯„å›²
                target_gender = brand_target.loc[brand_column, 'Gender']  # æ€§åˆ¥

                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«ä¸€è‡´ã™ã‚‹è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã¿
                if target_gender == 'MF':
                    # ã€ŒMFã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å ´åˆã€æ€§åˆ¥ã«é–¢ä¿‚ãªãã™ã¹ã¦ã®è¦–è´è€…ã‚’é¸æŠ
                    filtered_view_data = view_data[
                        (view_data['Age'] >= target_age_range[0]) & 
                        (view_data['Age'] <= target_age_range[1])
                    ]
                else:
                    # æŒ‡å®šã•ã‚ŒãŸæ€§åˆ¥ã¨å¹´é½¢ç¯„å›²ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                    filtered_view_data = view_data[
                        (view_data['Age'] >= target_age_range[0]) & 
                        (view_data['Age'] <= target_age_range[1]) & 
                        (view_data['Gender'] == target_gender)
                    ]
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«ä¸€è‡´ã™ã‚‹è¦–è´ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é•·ã•ã‚’å–å¾—
                filtered_index = filtered_view_data.index
                print(len(filtered_index))
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«åŸºã¥ã„ã¦è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
                brand_view_data[brand_column] = pd.Series([False] * len(filtered_index), index=filtered_index)


            # å‰²ã‚Šå½“ã¦çµæœã‚’è¨˜éŒ²ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            allocated_program_data = pd.DataFrame(columns=['Program_code', 'Brand', 'Allocated_seconds', 'Allocated_cost', 'New_Viewers'])

            #ã‚¢ãƒ­ã‚±ã®ã—ãŸå¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ 
            fin_data = limit_data.copy()
            #====================================================

            st.write("è¨­å®šçµ‚äº†")

            #ã‚»ãƒ«3================================================
            # brand_targetãŒDataFrameã§ã€'Brand'ãŒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
            for brand_column in temp_brand_data.columns:
                print(f"\n--- {brand_column} ã®å‡¦ç† ---")

                for index, value in temp_brand_data[brand_column].items():
                    if value == "ç„¡ã—" or pd.isna(value):
                        continue  # "ç„¡ã—"ã‚„ NaN ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

                    if value in [15, 30, 60, 120, 240]:  # valueãŒç§’æ•°ã¨ã—ã¦æœ‰åŠ¹ã‹ç¢ºèª
                        program_code, date = index  # è¤‡åˆã‚­ãƒ¼ã‹ã‚‰ program_code ã¨ date ã‚’å–ã‚Šå‡ºã™
                        
                        print(program_code)

                        # ç•ªçµ„ã®ã‚³ã‚¹ãƒˆã¨ç§’æ•°ã‚’å–å¾—
                        program_cost = temp_program_data.loc[(program_code, date), 'Cost/30']
                        program_seconds = temp_program_data.loc[(program_code, date), 'P_seconds']

                        # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç§’æ•°ã‚’æ¸›ã‚‰ã™
                        brand_seconds = value  # temp_brand_dataã®å€¤ãŒãã®ã¾ã¾ç§’æ•°ã¨ä»®å®š
                        program_seconds_remaining = program_seconds - brand_seconds  # æ®‹ã‚Šç§’æ•°ã‚’è¨ˆç®—

                        # ç•ªçµ„ã®ç§’æ•°ã‚’æ›´æ–°ã™ã‚‹ï¼ˆå¿…è¦ãªã‚‰temp_program_dataã«åæ˜ ï¼‰
                        temp_program_data.loc[(program_code, date), 'P_seconds'] = program_seconds_remaining

                        # ãƒ–ãƒ©ãƒ³ãƒ‰åã¨ä»Šå›ã®ç§’æ•°ã«åŸºã¥ã„ã¦ã‚³ã‚¹ãƒˆã‚’å–å¾—
                        brand_cost = allocated_brand_data.loc[brand_column, value]  # ãƒ–ãƒ©ãƒ³ãƒ‰åã¨ç§’æ•°ãŒä¸€è‡´ã™ã‚‹ã‚³ã‚¹ãƒˆã‚’å–å¾—
                        
                        # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç§’æ•°ã¨ã‚³ã‚¹ãƒˆã‚’å–å¾—
                        brand_seconds = value  # temp_brand_dataã®å€¤ãŒãã®ã¾ã¾ç§’æ•°ã¨ä»®å®š
                        allocated_cost = program_cost * (brand_seconds / 30)  # ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—

                        allocated_brand_data.at[brand_column, value] -= allocated_cost
                        new_cost = allocated_brand_data.loc[brand_column, value]

                        # è©¦è´ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ï¼ˆå¹´é½¢ãƒ»æ€§åˆ¥ï¼‰ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                        target_age_range = brand_target.loc[brand_column, ['Low', 'High']]  # å¹´é½¢ç¯„å›²ã‚’å–å¾—
                        target_gender = brand_target.loc[brand_column,'Gender']  # ä¾‹: 'Female'

                        if target_gender == 'MF':
                            # ã€ŒMFã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å ´åˆã€æ€§åˆ¥ã«é–¢ä¿‚ãªãã™ã¹ã¦ã®è¦–è´è€…ã‚’é¸æŠ
                            filtered_view_data = view_data[
                                (view_data['Age'] >= target_age_range[0]) & 
                                (view_data['Age'] <= target_age_range[1])
                            ]
                        else:
                            # æŒ‡å®šã•ã‚ŒãŸæ€§åˆ¥ã¨å¹´é½¢ç¯„å›²ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                            filtered_view_data = view_data[
                                (view_data['Age'] >= target_age_range[0]) & 
                                (view_data['Age'] <= target_age_range[1]) & 
                                (view_data['Gender'] == target_gender)
                            ]

                        # è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé‡è¤‡ã‚’é™¤ã„ãŸæ–°ã—ã„è¦–è´è€…ã®ã¿ï¼‰
                        past_viewer = brand_view_data[brand_column].copy()
                        brand_view_data[brand_column] |= filtered_view_data[program_code]
                        viewer_add = sum(brand_view_data[brand_column]) - sum(past_viewer)

                        # æƒ…å ±ã‚’è¡¨ç¤º
                        """
                        print(f"Brand: {brand_column}, ç§’æ•°: {value}")
                        print(f"å¯¾å¿œã™ã‚‹ã‚³ã‚¹ãƒˆ: {brand_cost}")
                        print(f"Program: {program_code}, Date: {date}")
                        print(f"Program Cost/30: {program_cost}, Program Seconds: {program_seconds}")
                        print(f"Brand Allocated Seconds: {brand_seconds}, Brand Allocated Cost: {allocated_cost}")
                        print(f"æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒ‰äºˆç®—: {new_cost}")
                        print(f"æ®‹ã‚Šç•ªçµ„ç§’æ•°: {program_seconds_remaining}")
                        print("-" * 50)
                        print(f"å…ƒã®è¦–è´ãƒ‡ãƒ¼ã‚¿: {sum(past_viewer)}")
                        print(f"æ–°è¦è¦–è´ãƒ‡ãƒ¼ã‚¿: {sum(brand_view_data[brand_column])}")
                        print(f"æ–°è¦ç²å¾—è¦–è´è€…: {viewer_add}")
                        print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(brand_view_data[brand_column])}")
                        """

                        # æ–°ã—ã„è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                        new_row = pd.DataFrame({
                            'Program_code': [program_code],
                            'Brand': [brand_column],
                            'Allocated_seconds': [brand_seconds],
                            'Allocated_cost': [allocated_cost],
                            'New_Viewers': [viewer_add]
                        })
                        
                        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ–°ã—ã„è¡Œã‚’è¿½åŠ ã™ã‚‹
                        allocated_program_data = pd.concat([allocated_program_data, new_row], ignore_index=True)
            #====================================================
           
            st.write("å¿…é ˆçµ‚äº†")

            #ã‚»ãƒ«4================================================
            pd.set_option('mode.chained_assignment', None)  # ãƒã‚§ãƒ¼ãƒ³ã•ã‚ŒãŸä»£å…¥ã®è­¦å‘Šã‚’ç„¡è¦–
            import warnings
            warnings.simplefilter(action='ignore', category=FutureWarning)


            # view_track DataFrameã®åˆæœŸåŒ–
            view_track = pd.DataFrame(columns=['Brand', 'Round', 'New_Viewers', 'Total_Viewers', 'Reach_Rate'])

            # åˆæœŸåŒ–
            seconds_priorities = sorted(brand_data.columns, reverse=True)
            round_number = 0  # ãƒ©ã‚¦ãƒ³ãƒ‰ã‚«ã‚¦ãƒ³ã‚¿
            all_brands_done = False  # å…¨ã¦ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã®å‰²ã‚Šä»˜ã‘ãŒçµ‚ã‚ã£ãŸã‹ã‚’ç¢ºèªã™ã‚‹ãƒ•ãƒ©ã‚°
            allocated_program_data = pd.DataFrame(columns=['Program_code', 'Brand', 'date', 'Allocated_seconds', 'Allocated_cost', 'New_Viewers'])

            # å‰²ã‚Šå½“ã¦æ¸ˆã¿ã®ç•ªçµ„ã‚³ãƒ¼ãƒ‰ã¨æ—¥ä»˜ã®çµ„ã¿åˆã‚ã›ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚»ãƒƒãƒˆ
            assigned_programs = set()

            # å‰²ã‚Šä»˜ã‘å¯èƒ½ãªãƒ–ãƒ©ãƒ³ãƒ‰ãŒã‚ã‚‹é™ã‚Šç¹°ã‚Šè¿”ã™ãƒ«ãƒ¼ãƒ—
            while not all_brands_done:
                print(f"\n--- ãƒ©ã‚¦ãƒ³ãƒ‰ {round_number} ---")
                
                all_brands_done = True  # ã™ã¹ã¦ã®ãƒ–ãƒ©ãƒ³ãƒ‰ãŒå®Œäº†ã—ãŸã‹ç¢ºèªã™ã‚‹ãŸã‚ã«ä¸€æ—¦Trueã«ã™ã‚‹

                # å„ãƒ–ãƒ©ãƒ³ãƒ‰ã”ã¨ã«å‰²ã‚Šå½“ã¦ã‚’è¡Œã†
                for brand in brand_names:
                    program_assigned = False  # ãƒ•ãƒ©ã‚°ã‚’åˆæœŸåŒ–
                    brand_new_viewers = 0  # ã“ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®æ–°è¦è¦–è´è€…æ•°ã‚’åˆæœŸåŒ–

                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ï¼ˆå¹´é½¢ãƒ»æ€§åˆ¥ï¼‰ã«åŸºã¥ã„ã¦è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã¿
                    target_age_range = brand_target.loc[brand, ['Low', 'High']]  # å¹´é½¢ç¯„å›²
                    target_gender = brand_target.loc[brand, 'Gender']  # æ€§åˆ¥

                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«ä¸€è‡´ã™ã‚‹è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
                    if target_gender == 'MF':
                        # ã€ŒMFã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å ´åˆã€æ€§åˆ¥ã«é–¢ä¿‚ãªãã™ã¹ã¦ã®è¦–è´è€…ã‚’é¸æŠ
                        filtered_view_data = view_data[
                            (view_data['Age'] >= target_age_range[0]) & 
                            (view_data['Age'] <= target_age_range[1])
                        ]
                    else:
                        # æŒ‡å®šã•ã‚ŒãŸæ€§åˆ¥ã¨å¹´é½¢ç¯„å›²ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                        filtered_view_data = view_data[
                            (view_data['Age'] >= target_age_range[0]) & 
                            (view_data['Age'] <= target_age_range[1]) & 
                            (view_data['Gender'] == target_gender)
                        ]

                    # å„ªå…ˆã™ã‚‹ç§’æ•°ã®é †ã«ãƒã‚§ãƒƒã‚¯
                    for seconds in seconds_priorities:
                        if program_assigned:  # ç•ªçµ„ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸå ´åˆã¯æ¬¡ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã«ç§»è¡Œ
                            break

                        brand_rest_cost = allocated_brand_data.at[brand, seconds]
                        program_cost_arr = temp_program_data['Cost/30'] * (seconds / 30)
                        program_seconds_arr = temp_program_data['P_seconds']

                        if (program_cost_arr > brand_rest_cost).all():
                            print(f"{brand}ã®{seconds}ã¯äºˆç®—ä¸Šé™ã«é”ã—ã¦ã„ã¾ã™ã€‚")
                            continue

                        if (program_seconds_arr < seconds).all():
                            print(f"{brand}ã®{seconds}ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ç•ªçµ„ç§’æ•°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                            continue

                        # ã‚‚ã—äºˆç®—ãŒæ®‹ã£ã¦ã„ã‚Œã°ç•ªçµ„ã‚’å‰²ã‚Šå½“ã¦ã‚‹
                        if allocated_brand_data.at[brand, seconds] > 0:
                            best_program = None
                            best_new_viewers = 0
                            best_allocated_seconds = 0
                            best_date = None

                            temp_df = pd.DataFrame()
                            past_viewer = brand_view_data[brand].copy()  # ã“ã“ã§ã‚³ãƒ”ãƒ¼ã‚’å–ã‚‹

                            # æœ€é©ãªç•ªçµ„ã‚’é¸ã¶ãŸã‚ã®å‡¦ç†
                            for index, value in temp_brand_data[brand].items():
                                program_code, date = index

                                # æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸç•ªçµ„ãƒ»æ—¥ä»˜ã®çµ„ã¿åˆã‚ã›ã‚’ãƒã‚§ãƒƒã‚¯
                                if (program_code, date, brand) in assigned_programs:
                                    print(f"{brand} ã«å¯¾ã—ã¦ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ  {program_code}, æ—¥ä»˜ {date} ã¯æ—¢ã«å‰²ã‚Šå½“ã¦æ¸ˆã¿ã§ã™ã€‚")
                                    continue

                                # "ç„¡ã—" ã¾ãŸã¯è¦–è´ãƒ‡ãƒ¼ã‚¿ãŒNaNã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                                if value == "ç„¡ã—" or not pd.isna(value):
                                    continue

                                # ç•ªçµ„ã®ã‚³ã‚¹ãƒˆã¨ç§’æ•°ã‚’å–å¾—
                                program_cost = temp_program_data.at[(program_code, date), 'Cost/30'] * (seconds / 30)
                                program_seconds = temp_program_data.at[(program_code, date), 'P_seconds']

                                # å‰²ã‚Šå½“ã¦å¯èƒ½ãªç§’æ•°ã‚’ç¢ºèª
                                if program_seconds < seconds:
                                    continue

                                # ã‚³ã‚¹ãƒˆç¢ºèª
                                if allocated_brand_data.at[brand, seconds] < program_cost:
                                    continue

                                # éå»ã®è¦–è´è€…æ•°ã‚’ä¿æŒã—ã€æ–°ãŸãªè¦–è´è€…æ•°ã‚’è¨ˆç®—
                                if program_code in filtered_view_data.columns:
                                    new_viewers = filtered_view_data[program_code]
                                    target_cost = new_viewers.sum() / program_cost

                                    # æ—¢å­˜ã®è¦–è´è€…ãƒ‡ãƒ¼ã‚¿ã¨çµåˆï¼ˆè¦–è´ã—ãŸäººã‚’1ã¨ã™ã‚‹å ´åˆï¼‰
                                    temp_brand_view_data = past_viewer | new_viewers
                                    viewer_add = temp_brand_view_data.sum() - past_viewer.sum()
                                    viewer_add_per_cost = viewer_add / program_cost
                                else:
                                    viewer_add = 0

                                if viewer_add <= 0:
                                    continue

                                # ç•ªçµ„ã‚’è¿½åŠ 
                                temp_data = pd.DataFrame({
                                    'program_code': [program_code],
                                    'date': [date],
                                    'viewer_add': [viewer_add],
                                    'viewer_add_per_cost': [viewer_add_per_cost],
                                    'target_cost': [target_cost]
                                })

                                temp_df = pd.concat([temp_df, temp_data], ignore_index=True)

                            # temp_dfã‹ã‚‰æœ€é©ãªç•ªçµ„ã‚’é¸ã¶
                            if not temp_df.empty:
                                if mode == "reach":
                                    # ãƒªãƒ¼ãƒãŒæœ€å¤§ã®ã‚‚ã®ã‚’é¸ã¶
                                    best_row = temp_df.loc[temp_df["viewer_add"].idxmax()]
                                    if best_row["viewer_add"] > 0:  # æ–°è¦è¦–è´è€…æ•°ãŒæ­£ã®å ´åˆã®ã¿å‰²ã‚Šä»˜ã‘
                                        best_program = best_row["program_code"]
                                        best_date = best_row["date"]
                                        best_new_viewers = best_row["viewer_add"]

                                elif mode == "reach_cost":
                                    # ãƒªãƒ¼ãƒå¢—åˆ†ã«å¯¾ã™ã‚‹ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒæœ€ã‚‚é«˜ã„ã‚‚ã®ã‚’é¸ã¶
                                    best_row = temp_df.loc[temp_df["viewer_add_per_cost"].idxmin()]
                                    if best_row["viewer_add"] > 0:  # æ–°è¦è¦–è´è€…æ•°ãŒæ­£ã®å ´åˆã®ã¿å‰²ã‚Šä»˜ã‘
                                        best_program = best_row["program_code"]
                                        best_date = best_row["date"]
                                        best_new_viewers = best_row["viewer_add"]

                                elif mode == "target_cost":
                                    # target_costãŒæœ€ã‚‚å°ã•ã„ã‚‚ã®ã‚’é¸ã¶ï¼ˆå¿…ãšå‰²ã‚Šä»˜ã‘ï¼‰
                                    best_row = temp_df.loc[temp_df["target_cost"].idxmin()]
                                    best_program = best_row["program_code"]
                                    best_date = best_row["date"]
                                    best_new_viewers = best_row["viewer_add"]
                                    print("tgã‚³ã‚¹ãƒˆã§é¸ã‚“ã§ã‚‹")

                            # æœ€é©ãªç•ªçµ„ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã®å‡¦ç†
                            if best_program and best_date is not None:
                                # å‰²ã‚Šå½“ã¦ãŸç•ªçµ„ã®å‡¦ç†ï¼ˆã‚³ã‚¹ãƒˆã®æ¸›ç®—ã‚„è¦–è´è€…ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ãªã©ï¼‰
                                best_program_cost = temp_program_data.at[(best_program, best_date), 'Cost/30'] * (seconds / 30)
                                allocated_brand_data.at[brand, seconds] -= best_program_cost
                                temp_program_data.at[(best_program, best_date), 'P_seconds'] -= seconds
                                new_viewers = filtered_view_data[best_program]  # è¦–è´ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
                                brand_view_data[brand] = past_viewer | new_viewers  # æ—¢å­˜ã®è¦–è´è€…ãƒ‡ãƒ¼ã‚¿ã¨çµåˆï¼ˆè¦–è´ã—ãŸäººã‚’1ã¨ã™ã‚‹å ´åˆï¼‰
                                total_viewers = brand_view_data[brand].sum()
                                sample_num = len(brand_view_data[brand_column])
                                view_rate = total_viewers / sample_num
                                
                                # å‰²ã‚Šå½“ã¦çµæœã‚’è¡¨ç¤º
                                print(f"æœ€é©ãªç•ªçµ„: {best_program} ã‚’ {brand} ã«å‰²ã‚Šå½“ã¦ã¾ã™ã€‚")
                                print(f"ç´¯è¨ˆåˆ°é”æ•°:{total_viewers}, æ–°è¦åˆ°é”æ•°: {best_new_viewers}, åˆ°é”ç‡: {view_rate}")
                                print(f"æ®‹ã‚Šäºˆç®—: {allocated_brand_data.at[brand, seconds]}, æ®‹ã‚Šç§’æ•°: {temp_program_data.at[(best_program, best_date), 'P_seconds']}")
                                print(f"æ›´æ–°å‰ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(past_viewer)}")
                                print(f"è¿½åŠ ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(past_viewer)}")
                                print(f"æ›´æ–°å¾Œã‚µãƒ³ãƒ—ãƒ«æ•°: {len(brand_view_data[brand_column])}")
                                
                                # æ–°ã—ã„è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                                new_row = pd.DataFrame({
                                    'Program_code': [best_program],
                                    'Brand': [brand],
                                    'date': [best_date],
                                    'Allocated_seconds': [seconds],
                                    'Allocated_cost': [best_program_cost],
                                    'New_Viewers': [best_new_viewers]
                                })

                                # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ–°ã—ã„è¡Œã‚’è¿½åŠ ã™ã‚‹
                                allocated_program_data = pd.concat([allocated_program_data, new_row], ignore_index=True)

                                # åŒã˜ç•ªçµ„ã€æ—¥ä»˜ã€ãƒ–ãƒ©ãƒ³ãƒ‰ã®çµ„ã¿åˆã‚ã›ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã«ã‚»ãƒƒãƒˆã«è¿½åŠ 
                                assigned_programs.add((best_program, best_date, brand))

                                # ãƒ–ãƒ©ãƒ³ãƒ‰ã”ã¨ã®æ–°è¦è¦–è´è€…æ•°ã‚’ç´¯ç©
                                brand_new_viewers += best_new_viewers

                                # å‰²ã‚Šå½“ã¦ãŒå®Œäº†ã—ãŸã®ã§ãƒ•ãƒ©ã‚°ã‚’Trueã«ã—ã€æ¬¡ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã«ç§»ã‚‹
                                program_assigned = True
                                all_brands_done = False  # å‰²ã‚Šå½“ã¦ãŒè¡Œã‚ã‚ŒãŸã‚‰æ¬¡ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã‚‚è¡Œã†

                                fin_data.at[(best_program, best_date), brand] = seconds
                                print("å‰²ã‚Šä»˜ã‘æˆåŠŸï¼")
                                break  # 1ãƒ©ã‚¦ãƒ³ãƒ‰ã§1ç•ªçµ„ã®ã¿å‰²ã‚Šå½“ã¦ã‚‹ã®ã§ã€æ¬¡ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã«ç§»ã‚‹
                            else:
                                print(f"{brand} ã® {seconds}ç§’æ ã§é©åˆ‡ãªç•ªçµ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¬¡ã®ç§’æ•°æ ã«ç§»è¡Œã—ã¾ã™ã€‚")

                    # ã“ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã®ãƒ©ã‚¦ãƒ³ãƒ‰çµ‚äº†æ™‚ã«ãƒªãƒ¼ãƒç‡ã‚’è¨ˆç®—
                    if program_assigned:
                        # view_trackã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        view_track = pd.concat([view_track, pd.DataFrame({
                            'Brand': [brand],
                            'Round': [round_number],
                            'New_Viewers': [brand_new_viewers],
                            'Total_Viewers': [total_viewers],
                            'Reach_Rate': [view_rate]
                        })], ignore_index=True)

                # å…¨ãƒ–ãƒ©ãƒ³ãƒ‰ã§ç•ªçµ„ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œãªã„å ´åˆã¯ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†
                if all_brands_done:
                    print("ã™ã¹ã¦ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã®å‰²ã‚Šå½“ã¦ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    break

                # ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ—
                round_number += 1

            # æœ€çµ‚å‰²ã‚Šå½“ã¦çµæœã‚’è¡¨ç¤º
            print("æœ€çµ‚å‰²ã‚Šå½“ã¦çµæœ:")
            print(allocated_program_data)

            # ãƒªãƒ¼ãƒç‡ã®è¿½è·¡çµæœã‚’è¡¨ç¤º
            print("ãƒªãƒ¼ãƒç‡ã®è¿½è·¡çµæœ:")
            print(view_track)

            #====================================================
           
            st.write("å‰²ã‚Šä»˜ã‘çµ‚äº†")

            #ã‚»ãƒ«5================================================
            # æœ€çµ‚çš„ãªè¦–è´ç‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆæœŸåŒ–
            fin_view_rate_list = pd.DataFrame(columns=['Brand', 'Total_Viewers', 'Reach_Rate'])

            # å„ãƒ–ãƒ©ãƒ³ãƒ‰ã®è¦–è´è€…æ•°ã¨ãƒªãƒ¼ãƒç‡ã‚’è¨ˆç®—
            for brand in brand_names:
                total_viewers = brand_view_data[brand].sum()  # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç·è¦–è´è€…æ•°
                sample_num = len(brand_view_data[brand])
                view_rate = (total_viewers / sample_num) if sample_num > 0 else 0  # ãƒªãƒ¼ãƒç‡ã®è¨ˆç®—
                print(f"{brand} ã‚µãƒ³ãƒ—ãƒ«ï¼š{sample_num}ãƒªãƒ¼ãƒ{total_viewers}")

                # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                fin_view_rate_list = pd.concat([fin_view_rate_list, pd.DataFrame({
                    'Brand': [brand],
                    'Total_Viewers': [total_viewers],
                    'Reach_Rate': [view_rate]
                })], ignore_index=True)

            # æœ€çµ‚çµæœã‚’è¡¨ç¤º
            print(fin_view_rate_list)
            #====================================================
           
            st.title("ãƒ‡ãƒ¼ã‚¿æˆå½¢çµ‚äº†")

            #ã‚»ãƒ«6================================================
            # Excelå‡ºåŠ›é–¢æ•°
            def create_excel_file():
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    fin_data.to_excel(writer, sheet_name='programÃ—brand', index=True)
                    allocated_program_data.to_excel(writer, sheet_name='allocated_program_data', index=True)
                    view_track.to_excel(writer, sheet_name='view_track', index=True)
                    fin_view_rate_list.to_excel(writer, sheet_name='fin_view_rate_list', index=True)
                    allocated_brand_data.to_excel(writer, sheet_name='allocated_brand_cost', index=True)
                output.seek(0)
                return output
            
            excel_file = create_excel_file()
            
            # Streamlitã‚¢ãƒ—ãƒªæœ¬ä½“
            st.title("Excelãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›")
            # ãƒœã‚¿ãƒ³ã§Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.download_button(
                label="Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=excel_file,
                file_name="output.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€éš›ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def tab_CausalImpact():
    show_card(
    """
    <h2>Causal Impact</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>åºƒå‘Šå‡ºç¨¿ãŒKPIã«ä¸ãˆãŸ <b>å› æœçš„å½±éŸ¿</b> ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚</li>
        <li>å‡ºç¨¿ãŒç„¡ã‹ã£ãŸå ´åˆï¼ˆã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆï¼‰ã®KPIæ¨ç§»ã‚’æ¨å®šã—ã€å®Ÿç¸¾ã¨ã®å·®åˆ†ï¼<b>ãƒªãƒ•ãƒˆåŠ¹æœ</b> ã‚’æŠŠæ¡ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li><b>TVCM / ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åŠ¹æœæ¤œè¨¼</b>ï¼ˆå‡ºç¨¿ã‚¨ãƒªã‚¢ vs éå‡ºç¨¿ã‚¨ãƒªã‚¢ï¼‰</li>
        <li><b>ä»‹å…¥æ—¥ä»¥é™ãŒ1ã«ãªã‚‹ãƒ•ãƒ©ã‚°</b> ã‚’ç”¨ã„ãŸå› æœæ¨å®š</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li>å¿…é ˆåˆ—ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼åã¯ä»»æ„ï¼‰
            <ul>
                <li><b>æ—¥ä»˜åˆ—</b>ï¼ˆä¾‹: date / Date / æ—¥ä»˜ï¼‰</li>
                <li><b>å‡ºç¨¿ãƒ•ãƒ©ã‚°</b>ï¼ˆ0=æœªå‡ºç¨¿ / 1=å‡ºç¨¿é–‹å§‹ä»¥é™ï¼‰</li>
                <li><b>å‡ºç¨¿ã‚¨ãƒªã‚¢KPIï¼ˆtreatedï¼‰</b></li>
                <li><b>éå‡ºç¨¿ã‚¨ãƒªã‚¢KPIï¼ˆcontrolï¼‰</b></li>
            </ul>
        </li>
        <li>ä¾‹ï¼š<code>date, flag, kpi_treated, kpi_control</code></li>
    </ul>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>

    <h4>â–  1. Actualï¼ˆå®Ÿç¸¾å€¤ï¼štreatedï¼‰</h4>
    <ul>
        <li>å‡ºç¨¿ã‚¨ãƒªã‚¢ã®å®Ÿæ¸¬ KPI</li>
    </ul>

    <h4>â–  2. Counterfactualï¼ˆåå®Ÿä»®æƒ³ã®äºˆæ¸¬å€¤ï¼‰</h4>
    <ul>
        <li>ã€Œã‚‚ã—å‡ºç¨¿ã—ã¦ã„ãªã‹ã£ãŸã‚‰ã€ã®æ¨å®šå€¤</li>
        <li>ä»‹å…¥å¾Œã¯å®Ÿç¸¾ã¨ä¹–é›¢ â†’ ã“ã®å·®ãŒåŠ¹æœ</li>
    </ul>

    <h4>â–  3. Point Effectï¼ˆç¬é–“åŠ¹æœï¼‰</h4>
    <ul>
        <li><b>å®Ÿç¸¾ âˆ’ ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆ</b> ã®æ—¥æ¬¡å·®åˆ†</li>
    </ul>

    <h4>â–  4. Cumulative Effectï¼ˆç´¯ç©åŠ¹æœï¼‰</h4>
    <ul>
        <li>ä»‹å…¥é–‹å§‹ä»¥é™ã®ãƒªãƒ•ãƒˆç´¯ç©</li>
        <li>ã€Œåºƒå‘Šã«ã‚ˆã£ã¦åˆè¨ˆã©ã‚Œã ã‘æŠ¼ã—ä¸Šã’ã‚‰ã‚ŒãŸã‹ã€</li>
    </ul>

    <h4>â–  5. Summaryï¼ˆã‚µãƒãƒªãƒ¼ï¼‰</h4>
    <ul>
        <li>å¹³å‡åŠ¹æœï¼ˆAV effectï¼‰</li>
        <li>åˆè¨ˆåŠ¹æœï¼ˆcumulative effectï¼‰</li>
        <li>ç›¸å¯¾åŠ¹æœ (%)</li>
        <li>çµ±è¨ˆçš„æœ‰æ„æ€§ï¼ˆp-valueï¼‰</li>
        <li>95% äºˆæ¸¬åŒºé–“ï¼ˆãƒ™ã‚¤ã‚ºCIï¼‰</li>
    </ul>

    <h4>â–  6. Reportï¼ˆè‡ªç„¶è¨€èªãƒ¬ãƒãƒ¼ãƒˆï¼‰</h4>
    <ul>
        <li>ãã®ã¾ã¾ãƒ¬ãƒãƒ¼ãƒˆã«è²¼ã‚Œã‚‹è§£é‡ˆæ–‡ã‚’è‡ªå‹•ç”Ÿæˆ</li>
    </ul>

    <h4>â–  7. Actual vs Counterfactual ã‚°ãƒ©ãƒ•</h4>
    <ul>
        <li>é’ï¼šå®Ÿç¸¾</li>
        <li>ã‚ªãƒ¬ãƒ³ã‚¸ï¼šåå®Ÿä»®æƒ³ã®æ¨å®šæ›²ç·š</li>
        <li>ç‚¹ç·šï¼šä»‹å…¥æ—¥</li>
        <li>å·®åˆ† = å› æœåŠ¹æœï¼ˆãƒªãƒ•ãƒˆï¼‰ã‚’å¯è¦–åŒ–</li>
    </ul>

    <h4>â–  8. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ CSV</h4>
    <ul>
        <li>actual_treatedï¼ˆå®Ÿç¸¾ï¼‰</li>
        <li>counterfactual_predï¼ˆåå®Ÿä»®æƒ³ï¼‰</li>
        <li>point_effectï¼ˆç¬é–“åŠ¹æœï¼‰</li>
        <li>cumulative_effectï¼ˆç´¯ç©åŠ¹æœï¼‰</li>
    </ul>
    """
    )

                # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/CausalImpact.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="CausalImpact.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


    if not _CAUSALIMPACT_OK:
        st.error("causalimpact ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚å…ˆã«ç’°å¢ƒã¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        return

    up = st.file_uploader("CausalImpactç”¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSV / XLSXï¼‰", type=["csv", "xlsx"], key="ci_file")
    if up is None:
        return

    # ------- èª­ã¿è¾¼ã¿ -------
    try:
        if up.name.lower().endswith(".xlsx"):
            df_raw = pd.read_excel(up)
        else:
            try:
                df_raw = pd.read_csv(up)
            except UnicodeDecodeError:
                up.seek(0); df_raw = pd.read_csv(up, encoding="shift-jis")
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    if df_raw.shape[1] < 4:
        st.error("å°‘ãªãã¨ã‚‚ 4 åˆ—ï¼ˆdate, flag, treated, controlï¼‰ãŒå¿…è¦ã§ã™ã€‚")
        return

    st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
    st.dataframe(df_raw.head())

    # ------- æ—¥ä»˜åˆ—ã®è‡ªå‹•æ¤œå‡º -------
    date_col = None
    for c in df_raw.columns:
        lc = str(c).lower()
        if "date" in lc or "æ—¥ä»˜" in lc:
            date_col = c; break
    if date_col is None:
        # å…ˆé ­åˆ—ãŒæ—¥ä»˜ã£ã½ã‘ã‚Œã°æ¡ç”¨
        c0 = df_raw.columns[0]
        if pd.to_datetime(df_raw[c0], errors="coerce").notna().mean() > 0.8:
            date_col = c0

    if date_col is None:
        st.error("æ—¥ä»˜åˆ—ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚`date`/`Date`/`æ—¥ä»˜` ç­‰ã®åˆ—ã‚’å«ã‚ã¦ãã ã•ã„ã€‚")
        return

    # åˆ—ã®ä¸¦ã³ã‚’ [date, flag, treated, control] ã«æƒãˆã‚‹ï¼ˆæ®‹ã‚Šã¯ç„¡è¦–ï¼‰
    other_cols = [c for c in df_raw.columns if c != date_col]
    if len(other_cols) < 3:
        st.error("flag / treated / control ã®3åˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return
    flag_col, treated_col, control_col = other_cols[:3]

    df = df_raw[[date_col, flag_col, treated_col, control_col]].copy()
    df.columns = ["date", "flag", "treated", "control"]

    # å‹æ•´å½¢
    df["date"] = pd.to_datetime(df["date"], errors="raise")
    try:
        df["flag"] = df["flag"].astype(int)
    except Exception:
        st.error("flag åˆ—ã¯ 0/1 ã®æ•°å€¤ã«ã—ã¦ãã ã•ã„ã€‚")
        return

    # ã‚½ãƒ¼ãƒˆï¼†æ¬ æå‡¦ç†
    df = df.sort_values("date").dropna(subset=["treated", "control", "flag"]).reset_index(drop=True)

    # ------- pre/post ã®è‡ªå‹•æ±ºå®šï¼ˆæœ€åˆã® 1 ä»¥é™ã‚’ postï¼‰ -------
    ones = df.index[df["flag"] == 1].to_list()
    if not ones:
        st.error("flag=1 ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä»‹å…¥æ—¥ä»¥é™ã‚’ 1 ã«ã—ã¦ãã ã•ã„ã€‚")
        return
    first_one_idx = ones[0]

    # é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæ¨å¥¨ï¼‰
    if (df.loc[:first_one_idx-1, "flag"] != 0).any() or (df.loc[first_one_idx:, "flag"] != 1).any():
        st.warning("flag ãŒã€å‰åŠ0â†’å¾ŒåŠ1ã®é€£ç¶šã€ã«ãªã£ã¦ã„ã¾ã›ã‚“ã€‚çµæœè§£é‡ˆã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚")

       # ------- pre/post ã®è‡ªå‹•æ±ºå®š -------
    ones = df.index[df["flag"] == 1].to_list()
    zeros = df.index[df["flag"] == 0].to_list()
    if not ones:
        st.error("flag=1ï¼ˆä»‹å…¥ä»¥é™ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    if not zeros:
        st.error("flag=0ï¼ˆä»‹å…¥å‰ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    first_one_idx = ones[0]
    if first_one_idx == 0:
        st.error("å…ˆé ­è¡ŒãŒ flag=1 ã§ã™ã€‚ä»‹å…¥å‰ï¼ˆflag=0ï¼‰ã‚’å«ã‚ã¦ãã ã•ã„ã€‚"); return

    if (df.loc[:first_one_idx-1, "flag"] != 0).any() or (df.loc[first_one_idx:, "flag"] != 1).any():
        st.warning("flag ãŒã€å‰åŠ0â†’å¾ŒåŠ1ã€ã®é€£ç¶šã«ãªã£ã¦ã„ã¾ã›ã‚“ã€‚çµæœã®è§£é‡ˆã«æ³¨æ„ã€‚")

    # ------- ãƒ‡ãƒ¼ã‚¿æ•´å½¢ -------
    ts = pd.DataFrame({
        "y":  df["treated"].astype(float).values,
        "x1": df["control"].astype(float).values
    }, index=df["date"])

    # ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã®åˆ†æ•£ãƒã‚§ãƒƒã‚¯ï¼ˆä»Šå›=0ï¼‰
    if ts["x1"].std() == 0:
        add_noise = st.checkbox("ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒä¸€å®šãªã®ã§å¾®å°ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹ï¼ˆæ¨å¥¨ï¼‰", value=True)
        if add_noise:
            import numpy as np
            ts["x1"] = ts["x1"] + 1e-6 * np.random.randn(len(ts))

    pre_period  = [ts.index[0], ts.index[first_one_idx-1]]
    post_period = [ts.index[first_one_idx], ts.index[-1]]

    # ------- å®Ÿè¡Œ -------
    try:
        ci = CausalImpact(ts, pre_period, post_period)
        if getattr(ci, "inferences", None) is None:
            ci.run()  # æ˜ç¤ºå®Ÿè¡Œ
    except Exception as e:
        st.error(f"CausalImpact å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    # æ¨å®šçµæœã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if getattr(ci, "inferences", None) is None or ci.inferences is None or ci.inferences.empty:
        st.error("æ¨å®šçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚pre/post è¡Œæ•°ã‚„ãƒ‡ãƒ¼ã‚¿åˆ†æ•£ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        st.write(f"pre è¡Œæ•°: {(ts.index <= pre_period[1]).sum()} / post è¡Œæ•°: {(ts.index >= post_period[0]).sum()}")
        st.stop()

    st.subheader("çµæœã‚µãƒãƒªãƒ¼")
    st.text(ci.summary())
    st.subheader("ãƒ¬ãƒãƒ¼ãƒˆ")
    st.text(ci.summary(output="report"))

    # inferences ã®ä¸­èº«ã‚’ç¢ºèª
    inf = ci.inferences.copy()
    st.write("inferences preview:", inf.head())

    # äºˆæ¸¬å€¤ã®åˆ—ã‚’æ¢ã™
    pred_col = None
    for c in ["predicted", "mean", "preds"]:
        if c in inf.columns:
            pred_col = c
            break

    if pred_col is None:
        st.error(f"äºˆæ¸¬å€¤ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ©ç”¨å¯èƒ½ãªåˆ—: {inf.columns.tolist()}")
        st.stop()

    # äºˆæ¸¬ç³»åˆ—ã‚’å…¨æœŸé–“ã¸æ‹¡å¼µï¼ˆpre=å®Ÿç¸¾, post=äºˆæ¸¬ï¼‰
    pred_full = ts["y"].copy()
    pred_full.loc[post_period[0]:] = inf[pred_col]

    out = pd.DataFrame({
        "actual_treated": ts["y"],
        "counterfactual_pred": pred_full,
    })
    if "point_effect" in inf.columns:
        out["point_effect"] = inf["point_effect"].reindex(ts.index)
    if "cum_effect" in inf.columns:
        out["cum_effect"] = inf["cum_effect"].reindex(ts.index)

    st.subheader("æ¨å®šãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå®Ÿç¸¾ãƒ»äºˆæ¸¬ãƒ»åŠ¹æœï¼‰")
    st.dataframe(out)

    st.download_button(
        "çµæœCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=out.to_csv(index=True).encode("utf-8"),
        file_name="causal_impact_result.csv",
        mime="text/csv"
    )

    # ã‚°ãƒ©ãƒ•ï¼ˆæ—¥ä»˜ã‚’æ¨ªè»¸ï¼‰
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(out.index, out["actual_treated"], label="Actual (treated)")
    ax.plot(out.index, out["counterfactual_pred"], label="Counterfactual (no-CM prediction)")
    ax.axvline(post_period[0], linestyle="--")
    ax.set_title("Actual vs Counterfactual (CausalImpact)")
    ax.set_xlabel("Date"); ax.set_ylabel("KPI"); ax.legend()
    st.pyplot(fig)

def tab_factor():
    show_card(
    """
    <h2>å› å­åˆ†æï¼ˆFactor Analysisï¼‰</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li>å¤šæ•°ã®è³ªå•é …ç›®ã‚„ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®ã‹ã‚‰ <b>æ½œåœ¨å› å­ï¼ˆä¾¡å€¤è¦³ãƒ»å¿ƒç†æ§‹é€ ï¼‰</b> ã‚’æŠ½å‡ºã—ã€ãƒ‡ãƒ¼ã‚¿ã®èƒŒå¾Œã«ã‚ã‚‹æ§‹é€ ã‚’ç†è§£ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>ãƒ–ãƒ©ãƒ³ãƒ‰ã‚¤ãƒ¡ãƒ¼ã‚¸èª¿æŸ»ã‚„ NPS èª¿æŸ»ã® <b>å¿ƒç†æ§‹é€ </b> ã‚’æŠŠæ¡ã—ãŸã„ã€‚</li>
        <li>å¤šæ•°ã®é …ç›®ã‚’å°‘æ•°ã®å› å­ã¸ã¾ã¨ã‚ã€<b>è§£é‡ˆã—ã‚„ã™ãã—ãŸã„</b>ã€‚</li>
        <li>ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‰ã«ã€ä¾¡å€¤è¦³ãƒ»æ…‹åº¦é …ç›®ã‚’ <b>å› å­ã‚¹ã‚³ã‚¢ã«åœ§ç¸®</b> ã—ãŸã„ã€‚</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li><b>æ•°å€¤åˆ—ã®ã¿ãŒå¯¾è±¡</b></li>
        <li>1åˆ—ç›®ã«IDã€2åˆ—ç›®ä»¥é™ã«ã€Œè©•ä¾¡é …ç›®ãƒ»ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®ã€ãªã©ã‚’ä¸¦ã¹ãŸå½¢å¼</li>
        <li>CSV / Excelï¼ˆA_å…¥åŠ›ã‚·ãƒ¼ãƒˆãŒã‚ã‚Œã°å„ªå…ˆï¼‰</li>
    </ul>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li><b>å› å­è² è·é‡</b>ï¼šã©ã®é …ç›®ãŒã©ã®å› å­ã«å¼·ãé–¢ã‚ã‚‹ã‹ï¼ˆè§£é‡ˆã®ä¸­å¿ƒï¼‰</li>
        <li><b>å› å­ã‚¹ã‚³ã‚¢</b>ï¼šå„ã‚µãƒ³ãƒ—ãƒ«ã®å› å­ç©ºé–“ã§ã®ä½ç½®</li>
        <li><b>å›ºæœ‰å€¤ãƒ»å¯„ä¸ç‡</b>ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ å¯èƒ½ï¼‰</li>
        <li><b>å› å­æ•°ã¯ä»»æ„é¸æŠï¼ˆ1ã€œ10ï¼‰</b></li>
    </ul>
    """
    )
    # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/ä¸»æˆåˆ†ORå› å­åˆ†æ.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="ä¸»æˆåˆ†ORå› å­åˆ†æ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # === ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ===
    up = st.file_uploader("CSV / XLSX ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv","xlsx"])
    if up is None:
        return

    try:
        if up.name.lower().endswith(".xlsx"):
            df = pd.read_excel(up)
        else:
            df = pd.read_csv(up)
    except:
        st.error("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
        return

    st.write("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
    st.dataframe(df.head())

    # === 1åˆ—ç›®ã‚’IDã€2åˆ—ç›®ä»¥é™ã‚’èª¬æ˜å¤‰æ•°ã¨ã—ã¦ä½¿ç”¨ ===
    ID = df.iloc[:, 0]              # ä½¿ã‚ãªã„ãŒä¿æŒã—ã¦ãŠã
    X_raw = df.iloc[:, 1:].copy()

    # æ•°å€¤åˆ—ã®ã¿ä½¿ç”¨
    X = X_raw.select_dtypes(include=[np.number])
    drop_cols = [c for c in X_raw.columns if c not in X.columns]
    if drop_cols:
        st.warning(f"éæ•°å€¤åˆ—ã‚’é™¤å¤–ã—ã¾ã—ãŸ: {', '.join(drop_cols)}")

    if X.shape[1] == 0:
        st.error("å› å­åˆ†æã«ã¯æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return

    # æ¬ æå€¤ã®å‡¦ç†
    na_opt = st.radio("æ¬ æå€¤ã®æ‰±ã„", ["è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰", "åˆ—å¹³å‡ã§è£œå®Œ"], index=0, horizontal=True)
    if na_opt == "è¡Œã”ã¨ã«å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰":
        X = X.dropna()
    else:
        X = X.fillna(X.mean())

    # === å› å­æ•° ===
    n_factor = st.slider("æŠ½å‡ºã™ã‚‹å› å­æ•°", 1, min(10, X.shape[1]), 2)

    # === å› å­åˆ†æå®Ÿè¡Œ ===
    from sklearn.decomposition import FactorAnalysis

    fa = FactorAnalysis(n_components=n_factor)
    F = fa.fit_transform(X)   # å› å­ã‚¹ã‚³ã‚¢
    loadings = pd.DataFrame(
        fa.components_.T,
        index=X.columns,
        columns=[f"Factor{i+1}" for i in range(n_factor)]
    )

    # === çµæœã®è¡¨ç¤º ===
    st.subheader("å› å­è² è·é‡ï¼ˆFactor Loadingsï¼‰")
    st.dataframe(loadings.style.format("{:.3f}"))

    score_df = pd.DataFrame(F, columns=[f"Factor{i+1}" for i in range(n_factor)])
    st.subheader("å› å­ã‚¹ã‚³ã‚¢ï¼ˆFactor Scoresï¼‰")
    st.dataframe(score_df.head())

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.download_button("å› å­è² è·é‡ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=loadings.to_csv().encode("utf-8-sig"),
                    file_name="factor_loadings.csv",
                    mime="text/csv")

    st.download_button("å› å­ã‚¹ã‚³ã‚¢ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=score_df.to_csv().encode("utf-8-sig"),
                    file_name="factor_scores.csv",
                    mime="text/csv")

def tab_ca():
    show_card(
    """
    <h2>ã‚³ãƒ¬ã‚¹ãƒãƒ³ãƒ‡ãƒ³ã‚¹åˆ†æï¼ˆCorrespondence Analysisï¼‰</h2>

    <h3>ç›®çš„</h3>
    <ul>
        <li><b>ã‚«ãƒ†ã‚´ãƒª Ã— ã‚«ãƒ†ã‚´ãƒªã®å¯¾å¿œé–¢ä¿‚</b> ã‚’2æ¬¡å…ƒãƒãƒƒãƒ—ã¨ã—ã¦å¯è¦–åŒ–ã—ã€  
            ã©ã®å±æ€§ãŒã©ã®ã‚«ãƒ†ã‚´ãƒªã«è¿‘ã„ã‹ã‚’æŠŠæ¡ã™ã‚‹ã€‚</li>
    </ul>

    <h3>ä½¿ç”¨ã‚±ãƒ¼ã‚¹</h3>
    <ul>
        <li>ãƒ–ãƒ©ãƒ³ãƒ‰ Ã— ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ¯ãƒ¼ãƒ‰ ã® <b>ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ãƒãƒƒãƒ—</b></li>
        <li>å±æ€§ Ã— è³¼å…¥ç†ç”±ã€åº—èˆ— Ã— åˆ©ç”¨ç†ç”± ãªã©ã®é–¢ä¿‚æ•´ç†</li>
        <li>ã‚¯ãƒ­ã‚¹é›†è¨ˆè¡¨ã‚’ <b>è¦–è¦šçš„ã«ç†è§£</b> ã—ãŸã„å ´åˆ</li>
    </ul>

    <h3>inputãƒ‡ãƒ¼ã‚¿</h3>
    <ul>
        <li><b>è¡Œï¼š</b>ãƒ–ãƒ©ãƒ³ãƒ‰ / å±æ€§</li>
        <li><b>åˆ—ï¼š</b>ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ¯ãƒ¼ãƒ‰ / è³¼è²·ç†ç”±</li>
        <li><b>ã‚¯ãƒ­ã‚¹é›†è¨ˆå½¢å¼</b>ï¼ˆCSV / Excelï¼‰</li>
        <li>1åˆ—ç›®ã¯ indexï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰åãªã©ï¼‰</li>
    </ul>

    <h3>ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆèª¬æ˜</h3>
    <ul>
        <li><b>è¡Œãƒ—ãƒ­ãƒƒãƒˆåº§æ¨™</b>ï¼šãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»å±æ€§ã®å¸ƒç½®</li>
        <li><b>åˆ—ãƒ—ãƒ­ãƒƒãƒˆåº§æ¨™</b>ï¼šã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ¯ãƒ¼ãƒ‰ãƒ»ç†ç”±ã®å¸ƒç½®</li>
        <li><b>CAãƒãƒƒãƒ—ï¼ˆå¯¾å¿œåˆ†æãƒ—ãƒ­ãƒƒãƒˆï¼‰</b>ï¼šè¡Œåˆ—é–“ã®è·é›¢ã‚’è¦–è¦šåŒ–</li>
    </ul>
    """
    )
        # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/ã‚³ãƒ¬ã‚¹ãƒãƒ³ãƒ‡ãƒ³ã‚¹åˆ†æ.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="ã‚³ãƒ¬ã‚¹ãƒãƒ³ãƒ‡ãƒ³ã‚¹åˆ†æ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # === ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ===
    up = st.file_uploader("ã‚¯ãƒ­ã‚¹é›†è¨ˆè¡¨ï¼ˆCSV / XLSXï¼‰", type=["csv","xlsx"])
    if up is None:
        return

    try:
        if up.name.lower().endswith(".xlsx"):
            df = pd.read_excel(up, index_col=0)
        else:
            df = pd.read_csv(up, index_col=0)
    except:
        st.error("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
        return

    st.write("å…¥åŠ›è¡¨ï¼š")
    st.dataframe(df)

    # === CA å®Ÿè¡Œ ===
    try:
        import prince
    except:
        st.error("ãƒ©ã‚¤ãƒ–ãƒ©ãƒª 'prince' ãŒã‚ã‚Šã¾ã›ã‚“ã€‚`pip install prince` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return

    ca = prince.CA(n_components=2)
    ca = ca.fit(df)

    row_coords = ca.row_coordinates(df)
    col_coords = ca.column_coordinates(df)

    st.subheader("è¡Œï¼ˆRowï¼‰åº§æ¨™")
    st.dataframe(row_coords)

    st.subheader("åˆ—ï¼ˆColumnï¼‰åº§æ¨™")
    st.dataframe(col_coords)

    # === ãƒ—ãƒ­ãƒƒãƒˆ ===
    fig, ax = plt.subplots(figsize=(7,7))

    # è¡Œ
    ax.scatter(row_coords[0], row_coords[1], label="Rows")
    for i, txt in enumerate(row_coords.index):
        ax.text(row_coords.iloc[i, 0], row_coords.iloc[i, 1], txt)

    # åˆ—
    ax.scatter(col_coords[0], col_coords[1], marker="x", label="Columns")
    for i, txt in enumerate(col_coords.index):
        ax.text(col_coords.iloc[i, 0], col_coords.iloc[i, 1], txt)

    ax.axhline(0, color="gray", linewidth=0.5)
    ax.axvline(0, color="gray", linewidth=0.5)
    ax.set_title("Correspondence Analysis Map")
    ax.legend()

    st.pyplot(fig)


def tab_curve():
    latex_png = latex_to_png_base64(
        r"y = \frac{K}{1 + a\left(\frac{x}{10^{d_x}}\right)^b}\,10^{d_y}"
    )

    show_card(f"""
    <h2>Curveæ•°å¼äºˆæ¸¬</h2>

    <h3>ãƒ¢ãƒ‡ãƒ«ã®æ•°å¼</h3>
    <div style="text-align:center;">
        <img src="data:image/png;base64,{latex_png}" style="width:80%; max-width:600px;">
    </div>

    <ul>
        <li>ã€Œd_xã€ã€Œd_yã€ã¯æ¡èª¿æ•´ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
        <li>a, b, K, d_x, d_y ã‚’ä¸Šè¨˜å¼ã«ä»£å…¥ã—ã¦ãƒ¢ãƒ‡ãƒ«å®Œæˆ</li>
        <li><b>RÂ²ï¼ˆæ±ºå®šä¿‚æ•°ï¼‰</b>ï¼š1ã«è¿‘ã„ã»ã©ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ãŒé«˜ã„</li>
    </ul>
    """)

            # ã“ã“ã§ Python å´ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with open("app/Curveæ•°å¼äºˆæ¸¬.xlsx", "rb") as f:
        logistic_file = f.read()

    st.download_button(
        label="ğŸ“¥ å…¥åŠ›ã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=logistic_file,
        file_name="Curveæ•°å¼äºˆæ¸¬.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


    uploaded_file = st.file_uploader("Curveæ•°å¼äºˆæ¸¬ç”¨inputãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv", "xlsx"])

    if uploaded_file is not None:
        try:
            st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«:")
            if uploaded_file.type == "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet":
                bytes_data = uploaded_file.read()
                xl = pd.ExcelFile(BytesIO(bytes_data))
                # ã‚·ãƒ¼ãƒˆåãŒ "A_å…¥åŠ›" ã®å ´åˆã®ã¿èª­ã¿è¾¼ã‚€
                if "A_å…¥åŠ›" in xl.sheet_names:
                    df = pd.read_excel(xl, sheet_name="A_å…¥åŠ›")
                    st.write(df)
                else:
                    st.warning("æŒ‡å®šã•ã‚ŒãŸã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
                df = pd.read_csv(stringio, encoding="shift-jis")
                st.write(df)

            num = int(df.shape[1] / 2)
            for i in range(num):
                df_temp = df.iloc[:, [i * 2, i * 2 + 1]]
                df_temp.dropna()

            st.write(df)  # ä¸€æ—¦èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®NaNã‚’å‰Šé™¤ã—ã¦è¡¨ç¤º

            name_list = []
            a_list = []
            b_list = []
            K_list = []
            R_list = []
            d_x_list = []
            d_y_list = []

            max_fev = 100000000
            df2 = pd.DataFrame()

            for i in range(num):
                df_temp = df.iloc[:, [i * 2, i * 2 + 1]]
                df_temp = df_temp.dropna()

                x_observed = df_temp.iloc[:, 0]
                y = df_temp.iloc[:, 1]

                # èª¬æ˜å¤‰æ•°ã¨ç›®çš„å¤‰æ•°ã®æ¡æ•°ã‚’è¨ˆç®—ã™ã‚‹
                max_num = max(x_observed)
                s_x = str(max_num)
                if '.' in s_x:
                    s_x_i, s_x_d = s_x.split('.')
                else:
                    s_x_i = s_x
                    s_x_d = '0'
                d_x = float(len(s_x_i))

                max_num = max(y)
                s_y = str(max_num)
                s_y_i, s_y_d = s_y.split('.')
                d_y = float(len(s_y_i))

                x_observed = x_observed / 10 ** d_x
                y = y / 10 ** d_y
                max_num = max(y) * 10

                bounds = ((0, -5, 0), (100, 0, max_num))
                # bounds = ((0,-3,0),(10000000,0,50000))

                name = df.columns.values[i * 2]
                param, pcov = curve_fit(func_fit, x_observed, y, bounds=bounds, maxfev=max_fev)
                fit_y = func_fit(x_observed, param[0], param[1], param[2])
                df2[name + "_x"] = x_observed * 10 ** d_x
                df2[name + "_y"] = y * 10 ** d_y
                df2[name + "_fit"] = fit_y * 10 ** d_y
                R2 = r2_score(fit_y, y)

                name_list.append(name)
                a_list.append(param[0])
                b_list.append(param[1])
                K_list.append(param[2])
                d_x_list.append(d_x)
                d_y_list.append(d_y)
                R_list.append(R2)

            df_param = pd.DataFrame({"name": name_list, "a": a_list, "b": b_list, "max_value": K_list,
                                     "d_x": d_x_list, "d_y": d_y_list, "R2": R_list})
            st.write(df_param)  # ä¸€æ—¦èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®NaNã‚’å‰Šé™¤ã—ãŸã‚ˆ
            download(df_param)

            # ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•è¡¨ç¤º
            selected_name = st.selectbox("ã‚°ãƒ©ãƒ•åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã—ã¦ãã ã•ã„", df_param['name'].unique())
            if selected_name:
                plt.figure(figsize=(10, 6))
                plt.scatter(df2[selected_name + "_x"], df2[selected_name + "_y"], label="Data")
                plt.plot(df2[selected_name + "_x"], df2[selected_name + "_fit"], 'r-', label="Fit")
                plt.xlabel("X")
                plt.ylabel("Y")
                plt.title(f"Fit for {selected_name}")
                plt.legend()
                st.pyplot(plt)

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€éš›ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


#tab_TIMEç”¨ã®åˆæœŸåŒ–ã€å®Ÿè¡Œã«é–¢ã‚ã‚‹é–¢æ•°==========================
def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–"""
    defaults = {
        "current_step": "ãƒ¢ãƒ¼ãƒ‰é¸æŠ",  # åˆæœŸã‚¹ãƒ†ãƒƒãƒ—
        "uploaded_config_file": None,  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸæ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«
        "uploaded_view_file": None, #ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè¦–è´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
        "processed_data": None,  # å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        "allocated_cost_data": None,  # æ®‹ã‚³ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        "allocated_program_data": None,  # å‰²ã‚Šä»˜ã‘ãƒ­ã‚°
        "mode": "",  # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
        "step_status": {
            "ãƒ¢ãƒ¼ãƒ‰é¸æŠ": True,  # æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’True
            "æ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰": False,
            "Viewãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰": False,
            "å®Ÿè¡Œ": False,
        },
        # ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ï¼ˆä¾‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ï¼‰ã¯ã“ã“ã§ä¿æŒ
        "user_info": st.session_state.get("user_info", None),  # ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’ä¿æŒ
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def reset_app():
    """ç‰¹å®šã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆé …ç›®ã®ã¿ã‚’ãƒªã‚»ãƒƒãƒˆ"""
    keys_to_reset = [
        "current_step", 
        "uploaded_config_file", 
        "uploaded_view_file",
        "processed_data", 
        "allocated_cost_data", 
        "allocated_program_data", 
        "mode", 
        "step_status",
    ]
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]
    initialize_session_state()  # å†åˆæœŸåŒ–

def display_mode_selection():
    """ãƒ¢ãƒ¼ãƒ‰é¸æŠç”»é¢"""
    if st.session_state["step_status"]["ãƒ¢ãƒ¼ãƒ‰é¸æŠ"]:
        st.header("ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
        options = ["", "reach_cost", "reach", "target_cost"]  # ç©ºæ¬„ã‚’è¿½åŠ 
        st.session_state["mode"] = st.selectbox("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„", options)
        
        if st.session_state["mode"] == "":
            st.warning("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„")
        else:
            st.write(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰: {st.session_state['mode']}")
            if st.button("æ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¸", key="to_upload"):
                st.session_state["current_step"] = "æ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
                st.session_state["step_status"]["æ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"] = True

def display_config_file_upload():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»é¢"""
    if st.session_state["step_status"]["æ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]:
        st.header("æ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        if st.session_state["uploaded_config_file"] is None:
            uploaded_config_file = st.file_uploader("æ¡ä»¶Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx"])
            if uploaded_config_file is not None:
                st.session_state["uploaded_config_file"] = uploaded_config_file
        else:
            st.write("æ—¢ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸæ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚")
            st.write(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿æ¡ä»¶ãƒ•ã‚¡ã‚¤ãƒ«: {st.session_state['uploaded_config_file'].name}")

        if st.session_state["uploaded_config_file"] is not None:
            if st.button("Viewãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¸", key="to_execute_config"):
                st.session_state["current_step"] = "Viewãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
                st.session_state["step_status"]["Viewãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"] = True

def display_view_file_upload():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»é¢"""
    if st.session_state["step_status"]["Viewãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]:
        st.header("Viewãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        if st.session_state["uploaded_view_file"] is None:
            uploaded_view_file = st.file_uploader("CSV Viewãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv"])
            if uploaded_view_file is not None:
                st.session_state["uploaded_view_file"] = uploaded_view_file
        else:
            st.write("æ—¢ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸViewãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚")
            st.write(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿Viewãƒ•ã‚¡ã‚¤ãƒ«: {st.session_state['uploaded_view_file'].name}")

        if st.session_state["uploaded_view_file"] is not None:
            if st.button("æ¬¡ã¸", key="to_execute_view"):
                st.session_state["current_step"] = "å®Ÿè¡Œ"
                st.session_state["step_status"]["å®Ÿè¡Œ"] = True


def display_execution():
    """å®Ÿè¡Œç”»é¢"""
    if st.session_state["step_status"]["å®Ÿè¡Œ"]:
        st.header("æœ€é©åŒ–ã®å®Ÿè¡Œ")
        st.write(f"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ¼ãƒ‰: {st.session_state['mode']}")

        # config_fileã¨view_fileãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿å‡¦ç†ã‚’å®Ÿè¡Œ
        if st.session_state["processed_data"] is None and st.session_state["uploaded_config_file"] is not None and st.session_state["uploaded_view_file"] is not None:
            st.write("å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...")

            # configãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆExcelï¼‰ã‚’èª­ã¿è¾¼ã‚€
            bytes_data_config = st.session_state["uploaded_config_file"].read()  # æ­£ã—ãèª­ã¿è¾¼ã‚€
            config_data = pd.read_excel(BytesIO(bytes_data_config), sheet_name=None)

            # å„ã‚·ãƒ¼ãƒˆã‚’å–å¾—
            limit_data = config_data['A_Limit'].set_index(['Program_code', 'date'])
            brand_data = config_data['B_Brand'].set_index('Brand')
            target_data = config_data['D_Target'].set_index('Brand')

            # viewãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSVï¼‰ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
            bytes_data_view = st.session_state["uploaded_view_file"].read()  # æ­£ã—ãèª­ã¿è¾¼ã‚€
            view_data = pd.read_csv(BytesIO(bytes_data_view))

            # å¿…è¦ãªå‡¦ç†ã‚’è¡Œã†ï¼ˆä¾‹: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®šï¼‰
            view_data = view_data.set_index('Sample')

            # ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
            st.write("A_Limit ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
            st.dataframe(limit_data.head())
            st.write("B_Brand ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
            st.dataframe(brand_data.head())
            st.write("D_Target ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
            st.dataframe(target_data.head())
            st.write("C_View ã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿")
            st.dataframe(view_data.head())

            # ã€Œç„¡ã—ã€ã¨ã„ã†å€¤ã‚’ç©ºç™½ã«ç½®ãæ›ãˆã€å¿…é ˆç•ªçµ„ãƒ‡ãƒ¼ã‚¿ã¨é™¤å¤–ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            exc_data = limit_data.copy()
            must_data = limit_data.copy()

            values_to_replace_exc = [15, 30, 60, 120, 240]
            values_to_replace_must = ["ç„¡ã—"]
            exc_data.replace(values_to_replace_exc, '', inplace=True)  # é™¤å¤–ã®0-1ãƒ‡ãƒ¼ã‚¿
            must_data.replace(values_to_replace_must, '', inplace=True)  # å¿…é ˆç•ªçµ„ã®å‰²ã‚ŠæŒ¯ã‚Šç§’æ•°ãƒ‡ãƒ¼ã‚¿

            # ãƒ–ãƒ©ãƒ³ãƒ‰åã®ãƒªã‚¹ãƒˆã‚’å–å¾—
            brand_names = brand_data.index.tolist()
            #ãƒ–ãƒ©ãƒ³ãƒ‰ã®å‰²ã‚Šä»˜ã‘æƒ…å ±ãŒå…¥ã£ã¦ã‚‹
            temp_brand_data = limit_data.copy()
            temp_brand_data = temp_brand_data.drop(columns=[col for col in limit_data.columns if 'Cost/30' in col])
            temp_brand_data = temp_brand_data.drop(columns=[col for col in limit_data.columns if 'P_seconds' in col])
            temp_brand_data = temp_brand_data.drop(columns=[col for col in limit_data.columns if 'Program' in col])

            #ç•ªçµ„ã®ã‚³ã‚¹ãƒˆã¨ç§’æ•°
            temp_program_data = limit_data[['Cost/30', 'P_seconds']]

            # å„ãƒ–ãƒ©ãƒ³ãƒ‰ã®å½“åˆã®äºˆç®—ã‚’ä¿å­˜
            allocated_brand_data = brand_data.copy()  # å‰²ã‚Šä»˜ã‘ã«ä½¿ã†ãƒ–ãƒ©ãƒ³ãƒ‰ã”ã¨ã®äºˆç®—
            initial_brand_budget = allocated_brand_data.copy()  # å‰²ã‚Šä»˜ã‘å‰ã®åˆæœŸäºˆç®—
            used_brand_budget = pd.DataFrame(0, index=brand_names, columns=[120, 60, 30, 15])  # å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸäºˆç®—ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

            # è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹è¾æ›¸ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«åŸºã¥ãé•·ã•ã‚’è¨­å®šï¼‰
            brand_view_data = {}
            # target_dataãŒDataFrameã§ã‚ã‚‹ã“ã¨ã‚’ä»®å®š
            brand_target = target_data

            for brand_column in brand_names:
                # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹´é½¢ç¯„å›²ã¨æ€§åˆ¥ã‚’å–å¾—
                target_age_range = brand_target.loc[brand_column, ['Low', 'High']]  # å¹´é½¢ç¯„å›²
                target_gender = brand_target.loc[brand_column, 'Gender']  # æ€§åˆ¥

                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«ä¸€è‡´ã™ã‚‹è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã¿
                if target_gender == 'MF':
                    # ã€ŒMFã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å ´åˆã€æ€§åˆ¥ã«é–¢ä¿‚ãªãã™ã¹ã¦ã®è¦–è´è€…ã‚’é¸æŠ
                    filtered_view_data = view_data[
                        (view_data['Age'] >= target_age_range[0]) & 
                        (view_data['Age'] <= target_age_range[1])
                    ]
                else:
                    # æŒ‡å®šã•ã‚ŒãŸæ€§åˆ¥ã¨å¹´é½¢ç¯„å›²ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                    filtered_view_data = view_data[
                        (view_data['Age'] >= target_age_range[0]) & 
                        (view_data['Age'] <= target_age_range[1]) & 
                        (view_data['Gender'] == target_gender)
                    ]
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«ä¸€è‡´ã™ã‚‹è¦–è´ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é•·ã•ã‚’å–å¾—
                filtered_index = filtered_view_data.index
                print(len(filtered_index))
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«åŸºã¥ã„ã¦è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
                brand_view_data[brand_column] = pd.Series([False] * len(filtered_index), index=filtered_index)


            # å‰²ã‚Šå½“ã¦çµæœã‚’è¨˜éŒ²ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            allocated_program_data = pd.DataFrame(columns=['Program_code', 'Brand', 'Allocated_seconds', 'Allocated_cost', 'New_Viewers','Total_Viewers','Potential','Reach_Rate','Round'])

            #ã‚¢ãƒ­ã‚±ã®ã—ãŸå¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ 
            fin_data = limit_data.copy()
            #====================================================

            st.write("è¨­å®šçµ‚äº†")

            #ã‚»ãƒ«3================================================
            # brand_targetãŒDataFrameã§ã€'Brand'ãŒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
            # ç©ºã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆã“ã®ã‚¨ãƒªã‚¢ãŒãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢ã«ãªã‚Šã¾ã™ï¼‰
            log_config_placeholder = st.empty()
            # åˆæœŸã®ãƒ­ã‚°å†…å®¹
            log_config = ""
            for brand_column in temp_brand_data.columns:
                print(f"\n--- {brand_column} ã®å‡¦ç† ---")

                for index, value in temp_brand_data[brand_column].items():
                    if value == "ç„¡ã—" or pd.isna(value):
                        continue  # "ç„¡ã—"ã‚„ NaN ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

                    if value in [15, 30, 60, 120, 240]:  # valueãŒç§’æ•°ã¨ã—ã¦æœ‰åŠ¹ã‹ç¢ºèª
                        program_code, date = index  # è¤‡åˆã‚­ãƒ¼ã‹ã‚‰ program_code ã¨ date ã‚’å–ã‚Šå‡ºã™
                        
                        print(program_code)

                        # ç•ªçµ„ã®ã‚³ã‚¹ãƒˆã¨ç§’æ•°ã‚’å–å¾—
                        program_cost = temp_program_data.loc[(program_code, date), 'Cost/30']
                        program_seconds = temp_program_data.loc[(program_code, date), 'P_seconds']

                        # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç§’æ•°ã‚’æ¸›ã‚‰ã™
                        brand_seconds = value  # temp_brand_dataã®å€¤ãŒãã®ã¾ã¾ç§’æ•°ã¨ä»®å®š
                        program_seconds_remaining = program_seconds - brand_seconds  # æ®‹ã‚Šç§’æ•°ã‚’è¨ˆç®—

                        # ç•ªçµ„ã®ç§’æ•°ã‚’æ›´æ–°ã™ã‚‹ï¼ˆå¿…è¦ãªã‚‰temp_program_dataã«åæ˜ ï¼‰
                        temp_program_data.loc[(program_code, date), 'P_seconds'] = program_seconds_remaining

                        # ãƒ–ãƒ©ãƒ³ãƒ‰åã¨ä»Šå›ã®ç§’æ•°ã«åŸºã¥ã„ã¦ã‚³ã‚¹ãƒˆã‚’å–å¾—
                        brand_cost = allocated_brand_data.loc[brand_column, value]  # ãƒ–ãƒ©ãƒ³ãƒ‰åã¨ç§’æ•°ãŒä¸€è‡´ã™ã‚‹ã‚³ã‚¹ãƒˆã‚’å–å¾—
                        
                        # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç§’æ•°ã¨ã‚³ã‚¹ãƒˆã‚’å–å¾—
                        brand_seconds = value  # temp_brand_dataã®å€¤ãŒãã®ã¾ã¾ç§’æ•°ã¨ä»®å®š
                        allocated_cost = program_cost * (brand_seconds / 30)  # ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—

                        # 1. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹ç¢ºèª
                        print(allocated_brand_data.index)  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç¢ºèª
                        print(brand_column, value)  # ä½¿ç”¨ã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚‚ç¢ºèª

                        # 2. ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèªã—ã€å¿…è¦ãªã‚‰å¤‰æ›
                        if not isinstance(allocated_cost, (int, float)):
                            allocated_cost = float(allocated_cost)
                        
                        # ãƒ–ãƒ©ãƒ³ãƒ‰ã®äºˆç®—ã‚’æ¸›ã‚‰ã™
                        allocated_brand_data.at[brand_column, value] -= allocated_cost
                        new_cost = allocated_brand_data.loc[brand_column, value]

                        # è©¦è´ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ï¼ˆå¹´é½¢ãƒ»æ€§åˆ¥ï¼‰ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                        target_age_range = brand_target.loc[brand_column, ['Low', 'High']]  # å¹´é½¢ç¯„å›²ã‚’å–å¾—
                        target_gender = brand_target.loc[brand_column,'Gender']  # ä¾‹: 'Female'

                        if target_gender == 'MF':
                            # ã€ŒMFã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å ´åˆã€æ€§åˆ¥ã«é–¢ä¿‚ãªãã™ã¹ã¦ã®è¦–è´è€…ã‚’é¸æŠ
                            filtered_view_data = view_data[
                                (view_data['Age'] >= target_age_range[0]) & 
                                (view_data['Age'] <= target_age_range[1])
                            ]
                        else:
                            # æŒ‡å®šã•ã‚ŒãŸæ€§åˆ¥ã¨å¹´é½¢ç¯„å›²ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                            filtered_view_data = view_data[
                                (view_data['Age'] >= target_age_range[0]) & 
                                (view_data['Age'] <= target_age_range[1]) & 
                                (view_data['Gender'] == target_gender)
                            ]

                        # è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé‡è¤‡ã‚’é™¤ã„ãŸæ–°ã—ã„è¦–è´è€…ã®ã¿ï¼‰
                        past_viewer = brand_view_data[brand_column].copy()
                        brand_view_data[brand_column] |= filtered_view_data[program_code]
                        viewer_add = sum(brand_view_data[brand_column]) - sum(past_viewer)
                        Reach_rate = brand_view_data[brand_column] / len(brand_view_data[brand_column])

                        log_config += f"====================================================================================="
                        log_config += f"{brand_column}ã®{value}ç§’ã‚’{program_code}:{date}ã«{program_cost}å††ã§å‰²ã‚Šä»˜ã‘\n"
                        log_config += f"{brand_column}ã®{value}ç§’ã®å…ƒäºˆç®—{brand_cost}ã‹ã‚‰æ®‹ã‚Šäºˆç®—{new_cost}ã¸\n"
                        log_config += f"{brand_column}ã®ãƒªãƒ¼ãƒæ•°ã¯{sum(past_viewer)}ã‹ã‚‰{sum(brand_view_data[brand_column])}ã¸\n"

                        # ãƒ­ã‚°è¡¨ç¤ºã‚’æ›´æ–°
                        log_config_placeholder.text_area("å¿…é ˆç•ªçµ„å‡¦ç†ãƒ­ã‚°", log_config, height=300)

                        print(f"Brand: {brand_column}, ç§’æ•°: {value}")
                        print(f"å¯¾å¿œã™ã‚‹ã‚³ã‚¹ãƒˆ: {brand_cost}")
                        print(f"Program: {program_code}, Date: {date}")
                        print(f"Program Cost/30: {program_cost}, Program Seconds: {program_seconds}")
                        print(f"Brand Allocated Seconds: {brand_seconds}, Brand Allocated Cost: {allocated_cost}")
                        print(f"æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒ‰äºˆç®—: {new_cost}")
                        print(f"æ®‹ã‚Šç•ªçµ„ç§’æ•°: {program_seconds_remaining}")
                        print("-" * 50)
                        print(f"å…ƒã®è¦–è´ãƒ‡ãƒ¼ã‚¿: {sum(past_viewer)}")
                        print(f"æ–°è¦è¦–è´ãƒ‡ãƒ¼ã‚¿: {sum(brand_view_data[brand_column])}")
                        print(f"æ–°è¦ç²å¾—è¦–è´è€…: {viewer_add}")
                        print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(brand_view_data[brand_column])}")


                        # æ–°ã—ã„è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                        new_row = pd.DataFrame({
                            'Program_code': [program_code],
                            'Brand': [brand_column],
                            'Allocated_seconds': [brand_seconds],
                            'Allocated_cost': [allocated_cost],
                            'New_Viewers': [viewer_add],
                            'Total_Viewers': [brand_view_data[brand_column]],
                            'Potential': [len(brand_view_data[brand_column])],
                            'Reach_Rate': [Reach_rate],
                            'Round':[None]
                        })

                        #'Program_code', 'Brand', 'Allocated_seconds', 'Allocated_cost', 'New_Viewers','Total_Viewers','Potential','Reach_Rate','Round'])
                        
                        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ–°ã—ã„è¡Œã‚’è¿½åŠ ã™ã‚‹
                        allocated_program_data = pd.concat([allocated_program_data, new_row], ignore_index=True)
            #====================================================
        
            st.write("å¿…é ˆçµ‚äº†")

            #ã‚»ãƒ«4================================================
            pd.set_option('mode.chained_assignment', None)  # ãƒã‚§ãƒ¼ãƒ³ã•ã‚ŒãŸä»£å…¥ã®è­¦å‘Šã‚’ç„¡è¦–
            import warnings
            warnings.simplefilter(action='ignore', category=FutureWarning)


            # view_track DataFrameã®åˆæœŸåŒ–
            view_track = pd.DataFrame(columns=['Brand', 'Round', 'New_Viewers', 'Total_Viewers', 'Reach_Rate'])

            # åˆæœŸåŒ–
            seconds_priorities = sorted(brand_data.columns, reverse=True)
            round_number = 0  # ãƒ©ã‚¦ãƒ³ãƒ‰ã‚«ã‚¦ãƒ³ã‚¿
            all_brands_done = False  # å…¨ã¦ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã®å‰²ã‚Šä»˜ã‘ãŒçµ‚ã‚ã£ãŸã‹ã‚’ç¢ºèªã™ã‚‹ãƒ•ãƒ©ã‚°
            allocated_program_data = pd.DataFrame(columns=['Program_code', 'Brand', 'date', 'Allocated_seconds', 'Allocated_cost', 'New_Viewers'])

            # å‰²ã‚Šå½“ã¦æ¸ˆã¿ã®ç•ªçµ„ã‚³ãƒ¼ãƒ‰ã¨æ—¥ä»˜ã®çµ„ã¿åˆã‚ã›ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚»ãƒƒãƒˆ
            assigned_programs = set()

            log_opt_placeholder = st.empty()
            # åˆæœŸã®ãƒ­ã‚°å†…å®¹
            log_opt = ""
            # å‰²ã‚Šä»˜ã‘å¯èƒ½ãªãƒ–ãƒ©ãƒ³ãƒ‰ãŒã‚ã‚‹é™ã‚Šç¹°ã‚Šè¿”ã™ãƒ«ãƒ¼ãƒ—
            while not all_brands_done:
                print(f"\n--- ãƒ©ã‚¦ãƒ³ãƒ‰ {round_number} ---")
                
                all_brands_done = True  # ã™ã¹ã¦ã®ãƒ–ãƒ©ãƒ³ãƒ‰ãŒå®Œäº†ã—ãŸã‹ç¢ºèªã™ã‚‹ãŸã‚ã«ä¸€æ—¦Trueã«ã™ã‚‹

                # å„ãƒ–ãƒ©ãƒ³ãƒ‰ã”ã¨ã«å‰²ã‚Šå½“ã¦ã‚’è¡Œã†
                for brand in brand_names:
                    program_assigned = False  # ãƒ•ãƒ©ã‚°ã‚’åˆæœŸåŒ–
                    brand_new_viewers = 0  # ã“ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®æ–°è¦è¦–è´è€…æ•°ã‚’åˆæœŸåŒ–

                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ï¼ˆå¹´é½¢ãƒ»æ€§åˆ¥ï¼‰ã«åŸºã¥ã„ã¦è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã¿
                    target_age_range = brand_target.loc[brand, ['Low', 'High']]  # å¹´é½¢ç¯„å›²
                    target_gender = brand_target.loc[brand, 'Gender']  # æ€§åˆ¥

                    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«ä¸€è‡´ã™ã‚‹è¦–è´ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
                    if target_gender == 'MF':
                        # ã€ŒMFã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å ´åˆã€æ€§åˆ¥ã«é–¢ä¿‚ãªãã™ã¹ã¦ã®è¦–è´è€…ã‚’é¸æŠ
                        filtered_view_data = view_data[
                            (view_data['Age'] >= target_age_range[0]) & 
                            (view_data['Age'] <= target_age_range[1])
                        ]
                    else:
                        # æŒ‡å®šã•ã‚ŒãŸæ€§åˆ¥ã¨å¹´é½¢ç¯„å›²ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã¿
                        filtered_view_data = view_data[
                            (view_data['Age'] >= target_age_range[0]) & 
                            (view_data['Age'] <= target_age_range[1]) & 
                            (view_data['Gender'] == target_gender)
                        ]

                    # å„ªå…ˆã™ã‚‹ç§’æ•°ã®é †ã«ãƒã‚§ãƒƒã‚¯
                    for seconds in seconds_priorities:
                        if program_assigned:  # ç•ªçµ„ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸå ´åˆã¯æ¬¡ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã«ç§»è¡Œ
                            break

                        brand_rest_cost = allocated_brand_data.at[brand, seconds]
                        program_cost_arr = temp_program_data['Cost/30'] * (seconds / 30)
                        program_seconds_arr = temp_program_data['P_seconds']

                        if (program_cost_arr > brand_rest_cost).all():
                            print(f"{brand}ã®{seconds}ã¯äºˆç®—ä¸Šé™ã«é”ã—ã¦ã„ã¾ã™ã€‚")
                            continue

                        if (program_seconds_arr < seconds).all():
                            print(f"{brand}ã®{seconds}ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ç•ªçµ„ç§’æ•°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                            continue

                        # ã‚‚ã—äºˆç®—ãŒæ®‹ã£ã¦ã„ã‚Œã°ç•ªçµ„ã‚’å‰²ã‚Šå½“ã¦ã‚‹
                        if allocated_brand_data.at[brand, seconds] > 0:
                            best_program = None
                            best_new_viewers = 0
                            best_allocated_seconds = 0
                            best_date = None

                            temp_df = pd.DataFrame()
                            past_viewer = brand_view_data[brand].copy()  # ã“ã“ã§ã‚³ãƒ”ãƒ¼ã‚’å–ã‚‹

                            # æœ€é©ãªç•ªçµ„ã‚’é¸ã¶ãŸã‚ã®å‡¦ç†
                            for index, value in temp_brand_data[brand].items():
                                program_code, date = index

                                # æ—¢ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸç•ªçµ„ãƒ»æ—¥ä»˜ã®çµ„ã¿åˆã‚ã›ã‚’ãƒã‚§ãƒƒã‚¯
                                if (program_code, date, brand) in assigned_programs:
                                    print(f"{brand} ã«å¯¾ã—ã¦ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ  {program_code}, æ—¥ä»˜ {date} ã¯æ—¢ã«å‰²ã‚Šå½“ã¦æ¸ˆã¿ã§ã™ã€‚")
                                    continue

                                # "ç„¡ã—" ã¾ãŸã¯è¦–è´ãƒ‡ãƒ¼ã‚¿ãŒNaNã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                                if value == "ç„¡ã—" or not pd.isna(value):
                                    continue

                                # ç•ªçµ„ã®ã‚³ã‚¹ãƒˆã¨ç§’æ•°ã‚’å–å¾—
                                program_cost = temp_program_data.at[(program_code, date), 'Cost/30'] * (seconds / 30)
                                program_seconds = temp_program_data.at[(program_code, date), 'P_seconds']

                                # å‰²ã‚Šå½“ã¦å¯èƒ½ãªç§’æ•°ã‚’ç¢ºèª
                                if program_seconds < seconds:
                                    continue

                                # ã‚³ã‚¹ãƒˆç¢ºèª
                                if allocated_brand_data.at[brand, seconds] < program_cost:
                                    continue

                                # éå»ã®è¦–è´è€…æ•°ã‚’ä¿æŒã—ã€æ–°ãŸãªè¦–è´è€…æ•°ã‚’è¨ˆç®—
                                if program_code in filtered_view_data.columns:
                                    new_viewers = filtered_view_data[program_code]
                                    target_cost = new_viewers.sum() / program_cost

                                    # æ—¢å­˜ã®è¦–è´è€…ãƒ‡ãƒ¼ã‚¿ã¨çµåˆï¼ˆè¦–è´ã—ãŸäººã‚’1ã¨ã™ã‚‹å ´åˆï¼‰
                                    temp_brand_view_data = past_viewer | new_viewers
                                    viewer_add = temp_brand_view_data.sum() - past_viewer.sum()
                                    viewer_add_per_cost = viewer_add / program_cost
                                else:
                                    viewer_add = 0

                                #if viewer_add <= 0:
                                    #continue

                                #æ–°ã—ã„viewrãŒå¢—ãˆãªã„ã¨tempdfã«è¿½åŠ ã•ã‚Œã¦ãªã„ã‹ã‚‰å¢—ãˆãªã„ã‚“ã 

                                # ç•ªçµ„ã‚’è¿½åŠ 
                                temp_data = pd.DataFrame({
                                    'program_code': [program_code],
                                    'date': [date],
                                    'viewer_add': [viewer_add],
                                    'viewer_add_per_cost': [viewer_add_per_cost],
                                    'target_cost': [target_cost]
                                })

                                temp_df = pd.concat([temp_df, temp_data], ignore_index=True)

                            mode = str(st.session_state["mode"])
                            print(mode)

                            # temp_dfã‹ã‚‰æœ€é©ãªç•ªçµ„ã‚’é¸ã¶
                            if not temp_df.empty:
                                print("ãˆã¸")
                                if mode == "reach":
                                    print("ãƒªãƒ¼ãƒã«ãªã£ã¦ã‚‹")
                                    # ãƒªãƒ¼ãƒãŒæœ€å¤§ã®ã‚‚ã®ã‚’é¸ã¶
                                    best_row = temp_df.loc[temp_df["viewer_add"].idxmax()]
                                    if best_row["viewer_add"] > 0:  # æ–°è¦è¦–è´è€…æ•°ãŒæ­£ã®å ´åˆã®ã¿å‰²ã‚Šä»˜ã‘
                                        best_program = best_row["program_code"]
                                        best_date = best_row["date"]
                                        best_new_viewers = best_row["viewer_add"]

                                elif mode == "reach_cost":
                                    print("best")
                                    # ãƒªãƒ¼ãƒå¢—åˆ†ã«å¯¾ã™ã‚‹ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒæœ€ã‚‚é«˜ã„ã‚‚ã®ã‚’é¸ã¶
                                    best_row = temp_df.loc[temp_df["viewer_add_per_cost"].idxmin()]
                                    if best_row["viewer_add"] > 0:  # æ–°è¦è¦–è´è€…æ•°ãŒæ­£ã®å ´åˆã®ã¿å‰²ã‚Šä»˜ã‘
                                        best_program = best_row["program_code"]
                                        best_date = best_row["date"]
                                        best_new_viewers = best_row["viewer_add"]

                                elif mode == "target_cost":
                                    print("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚³ã‚¹ãƒˆã‚’é¸æŠã§ãã¦ã‚‹")
                                    # target_costãŒæœ€ã‚‚å°ã•ã„ã‚‚ã®ã‚’é¸ã¶ï¼ˆå¿…ãšå‰²ã‚Šä»˜ã‘ï¼‰
                                    best_row = temp_df.loc[temp_df["target_cost"].idxmin()]
                                    best_program = best_row["program_code"]
                                    best_date = best_row["date"]
                                    best_new_viewers = best_row["viewer_add"]
                                    print(best_program)

                            print("ã“ã“ã˜ã‚ƒãªã„")

                            # æœ€é©ãªç•ªçµ„ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã®å‡¦ç†
                            if best_program and best_date is not None:
                                # å‰²ã‚Šå½“ã¦ãŸç•ªçµ„ã®å‡¦ç†ï¼ˆã‚³ã‚¹ãƒˆã®æ¸›ç®—ã‚„è¦–è´è€…ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ãªã©ï¼‰
                                best_program_cost = temp_program_data.at[(best_program, best_date), 'Cost/30'] * (seconds / 30)
                                old_cost = allocated_brand_data.at[brand, seconds]
                                allocated_brand_data.at[brand, seconds] -= best_program_cost
                                temp_program_data.at[(best_program, best_date), 'P_seconds'] -= seconds
                                new_viewers = filtered_view_data[best_program]  # è¦–è´ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
                                brand_view_data[brand] = past_viewer | new_viewers  # æ—¢å­˜ã®è¦–è´è€…ãƒ‡ãƒ¼ã‚¿ã¨çµåˆï¼ˆè¦–è´ã—ãŸäººã‚’1ã¨ã™ã‚‹å ´åˆï¼‰
                                total_viewers = brand_view_data[brand].sum()
                                sample_num = len(brand_view_data[brand_column])
                                view_rate = total_viewers / sample_num
                                
                                # å‰²ã‚Šå½“ã¦çµæœã‚’è¡¨ç¤º
                                print(f"æœ€é©ãªç•ªçµ„: {best_program} ã‚’ {brand} ã«å‰²ã‚Šå½“ã¦ã¾ã™ã€‚")
                                print(f"ç´¯è¨ˆåˆ°é”æ•°:{total_viewers}, æ–°è¦åˆ°é”æ•°: {best_new_viewers}, åˆ°é”ç‡: {view_rate}")
                                print(f"æ®‹ã‚Šäºˆç®—: {allocated_brand_data.at[brand, seconds]}, æ®‹ã‚Šç§’æ•°: {temp_program_data.at[(best_program, best_date), 'P_seconds']}")
                                print(f"æ›´æ–°å‰ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(past_viewer)}")
                                print(f"è¿½åŠ ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(past_viewer)}")
                                print(f"æ›´æ–°å¾Œã‚µãƒ³ãƒ—ãƒ«æ•°: {len(brand_view_data[brand_column])}")

                                log_opt += f"================================================================================"
                                log_opt += f"{brand}ã®{seconds}ç§’ã‚’{best_program}:{best_date}ã«{best_program_cost}å††ã§å‰²ã‚Šä»˜ã‘\n"
                                log_opt += f"{brand}ã®{seconds}ç§’ã®å…ƒäºˆç®—{old_cost}ã‹ã‚‰æ®‹ã‚Šäºˆç®—{allocated_brand_data.at[brand, seconds]}ã¸\n"
                                log_opt += f"{brand}ã®ãƒªãƒ¼ãƒæ•°ã¯{sum(past_viewer)}ã‹ã‚‰{total_viewers}ã¸\n"
                                # ãƒ­ã‚°è¡¨ç¤ºã‚’æ›´æ–°
                                log_opt_placeholder.text_area("æœ€é©ç•ªçµ„å‡¦ç†ãƒ­ã‚°", log_opt, height=300)
                                
                                # æ–°ã—ã„è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                                new_row = pd.DataFrame({
                                    'Program_code': [best_program],
                                    'Brand': [brand],
                                    'date': [best_date],
                                    'Allocated_seconds': [seconds],
                                    'Allocated_cost': [best_program_cost],
                                    'New_Viewers': [best_new_viewers],
                                    'Total_Viewers': [total_viewers],
                                    'Potential': [sample_num],
                                    'Reach_Rate': [view_rate],
                                    'Round':[round_number]
                                })

                                # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ–°ã—ã„è¡Œã‚’è¿½åŠ ã™ã‚‹
                                allocated_program_data = pd.concat([allocated_program_data, new_row], ignore_index=True)

                                # åŒã˜ç•ªçµ„ã€æ—¥ä»˜ã€ãƒ–ãƒ©ãƒ³ãƒ‰ã®çµ„ã¿åˆã‚ã›ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã«ã‚»ãƒƒãƒˆã«è¿½åŠ 
                                assigned_programs.add((best_program, best_date, brand))

                                # ãƒ–ãƒ©ãƒ³ãƒ‰ã”ã¨ã®æ–°è¦è¦–è´è€…æ•°ã‚’ç´¯ç©
                                brand_new_viewers += best_new_viewers

                                # å‰²ã‚Šå½“ã¦ãŒå®Œäº†ã—ãŸã®ã§ãƒ•ãƒ©ã‚°ã‚’Trueã«ã—ã€æ¬¡ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã«ç§»ã‚‹
                                program_assigned = True
                                all_brands_done = False  # å‰²ã‚Šå½“ã¦ãŒè¡Œã‚ã‚ŒãŸã‚‰æ¬¡ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã‚‚è¡Œã†

                                fin_data.at[(best_program, best_date), brand] = seconds
                                print("å‰²ã‚Šä»˜ã‘æˆåŠŸï¼")
                                break  # 1ãƒ©ã‚¦ãƒ³ãƒ‰ã§1ç•ªçµ„ã®ã¿å‰²ã‚Šå½“ã¦ã‚‹ã®ã§ã€æ¬¡ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã«ç§»ã‚‹
                            else:
                                print(f"{brand} ã® {seconds}ç§’æ ã§é©åˆ‡ãªç•ªçµ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¬¡ã®ç§’æ•°æ ã«ç§»è¡Œã—ã¾ã™ã€‚")

                    # ã“ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã®ãƒ©ã‚¦ãƒ³ãƒ‰çµ‚äº†æ™‚ã«ãƒªãƒ¼ãƒç‡ã‚’è¨ˆç®—
                    if program_assigned:
                        # view_trackã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        view_track = pd.concat([view_track, pd.DataFrame({
                            'Brand': [brand],
                            'Round': [round_number],
                            'New_Viewers': [brand_new_viewers],
                            'Total_Viewers': [total_viewers],
                            'Reach_Rate': [view_rate]
                        })], ignore_index=True)

                # å…¨ãƒ–ãƒ©ãƒ³ãƒ‰ã§ç•ªçµ„ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œãªã„å ´åˆã¯ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†
                if all_brands_done:
                    print("ã™ã¹ã¦ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã®å‰²ã‚Šå½“ã¦ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    break

                # ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ—
                round_number += 1

            # æœ€çµ‚å‰²ã‚Šå½“ã¦çµæœã‚’è¡¨ç¤º
            print("æœ€çµ‚å‰²ã‚Šå½“ã¦çµæœ:")
            print(allocated_program_data)

            # ãƒªãƒ¼ãƒç‡ã®è¿½è·¡çµæœã‚’è¡¨ç¤º
            print("ãƒªãƒ¼ãƒç‡ã®è¿½è·¡çµæœ:")
            print(view_track)

            #====================================================
        
            st.write("å‰²ã‚Šä»˜ã‘çµ‚äº†")

            #ã‚»ãƒ«5================================================
            # æœ€çµ‚çš„ãªè¦–è´ç‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆæœŸåŒ–
            fin_view_rate_list = pd.DataFrame(columns=['Brand', 'Total_Viewers', 'Reach_Rate'])

            # å„ãƒ–ãƒ©ãƒ³ãƒ‰ã®è¦–è´è€…æ•°ã¨ãƒªãƒ¼ãƒç‡ã‚’è¨ˆç®—
            for brand in brand_names:
                total_viewers = brand_view_data[brand].sum()  # ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç·è¦–è´è€…æ•°
                sample_num = len(brand_view_data[brand])
                view_rate = (total_viewers / sample_num) if sample_num > 0 else 0  # ãƒªãƒ¼ãƒç‡ã®è¨ˆç®—
                print(f"{brand} ã‚µãƒ³ãƒ—ãƒ«ï¼š{sample_num}ãƒªãƒ¼ãƒ{total_viewers}")

                # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                fin_view_rate_list = pd.concat([fin_view_rate_list, pd.DataFrame({
                    'Brand': [brand],
                    'Total_Viewers': [total_viewers],
                    'Reach_Rate': [view_rate]
                })], ignore_index=True)

            # æœ€çµ‚çµæœã‚’è¡¨ç¤º
            st.write(fin_view_rate_list)
            #====================================================

            st.session_state["processed_data"] = fin_data #ç´ æã‚’å‰²ã‚Šä»˜ã‘ãŸçŠ¶æ…‹ã®ãƒ‡ãƒ¼ã‚¿
            st.session_state["allocated_cost_data"] = allocated_brand_data #ãƒ–ãƒ©ãƒ³ãƒ‰ã®æ®‹ã‚³ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            st.session_state["allocated_program_data"] = allocated_program_data #å‰²ã‚Šä»˜ã‘ã®ãƒ­ã‚°

        # çµæœã‚’è¡¨ç¤º
        if st.session_state["processed_data"] is not None:
            st.write("å‰²ã‚Šä»˜ã‘çµæœ:")
            st.write(st.session_state["processed_data"])
            st.write("ãƒ–ãƒ©ãƒ³ãƒ‰æ®‹äºˆç®—:")
            st.write(st.session_state["allocated_cost_data"])
            st.write("å‰²ã‚Šä»˜ã‘ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿:")
            st.write(st.session_state["allocated_program_data"])

def tab_time():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    initialize_session_state()

    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("ãƒªã‚»ãƒƒãƒˆ", key="reset"):
        reset_app()

    # å„ã‚¹ãƒ†ãƒƒãƒ—ã®ç”»é¢ã‚’è¡¨ç¤ºï¼ˆéå»ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚‚æ®‹ã™ï¼‰
    display_mode_selection()
    display_config_file_upload()
    display_view_file_upload()
    display_execution()



#Streamlitã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
def main():
    if login():
        tabs = st.sidebar.radio(
            "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
            [
                "ä¸»æˆåˆ†åˆ†æ",
                "å› å­åˆ†æ",
                "ã‚³ãƒ¬ã‚¹ãƒãƒ³ãƒ‡ãƒ³ã‚¹åˆ†æ",
                "å…±åˆ†æ•£æ§‹é€ åˆ†æï¼ˆSEMï¼‰",
                "Logisticå›å¸°",
                "é †åºLogisticå›å¸°",
                "é‡å›å¸°ï¼ˆè‡ªå‹•é¸æŠï¼‰",
                "MMMï¼ˆè»½é‡ç‰ˆï¼‰",
                "STLåˆ†è§£",  
                "TIMEæœ€é©åŒ–",
                "Causal Impact",
                "Curveæ•°å¼äºˆæ¸¬",
            ]
        )

        # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³
        if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
            st.session_state["logged_in"] = False
            st.session_state["user"] = None

            # rerun
            st.rerun()

        if tabs == "ä¸»æˆåˆ†åˆ†æ":
            tab_PCA()
        elif tabs == "å› å­åˆ†æ":
            tab_factor()
        elif tabs == "ã‚³ãƒ¬ã‚¹ãƒãƒ³ãƒ‡ãƒ³ã‚¹åˆ†æ":
            tab_ca()
        elif tabs == "å…±åˆ†æ•£æ§‹é€ åˆ†æï¼ˆSEMï¼‰":
            tab_SEM()
        elif tabs == "Logisticå›å¸°":
            tab_Logistic()
        elif tabs == "é †åºLogisticå›å¸°":
            tab_LogisticNum()
        elif tabs == "é‡å›å¸°ï¼ˆè‡ªå‹•é¸æŠï¼‰":
            tab_MultipleRegression()   
        elif tabs == "MMMï¼ˆè»½é‡ç‰ˆï¼‰":
            tab_MMM()
        elif tabs == "STLåˆ†è§£":
            tab_STL()
        elif tabs == "TIMEæœ€é©åŒ–":
            tab_time()
        elif tabs == "Causal Impact":
            tab_CausalImpact()
        elif tabs == "Curveæ•°å¼äºˆæ¸¬":
            tab_curve()


#å®Ÿè¡Œã‚³ãƒ¼ãƒ‰
if __name__ == "__main__":
    main()